<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维人</title>
  
  
  <link href="https://www.langxw.com/atom.xml" rel="self"/>
  
  <link href="https://www.langxw.com/"/>
  <updated>2021-06-04T11:33:32.239Z</updated>
  <id>https://www.langxw.com/</id>
  
  <author>
    <name>运维人</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker添加http代理</title>
    <link href="https://www.langxw.com/2021/06/04/Docker%E6%B7%BB%E5%8A%A0http%E4%BB%A3%E7%90%86/"/>
    <id>https://www.langxw.com/2021/06/04/Docker%E6%B7%BB%E5%8A%A0http%E4%BB%A3%E7%90%86/</id>
    <published>2021-06-04T11:32:02.000Z</published>
    <updated>2021-06-04T11:33:32.239Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>当docker在拉取国外的镜像，并且没有国内加速源的资源，速度很慢，甚至访问不到，比如安装k8s的时候。这时候就需要添加http、https代理，来进行下载加速。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><ul><li>**Ubuntu16.04 + Docker 20.10.6 **</li><li><strong>适用于Debian/Ubuntu，RedHat/CentOS系统。修改配置后，会持续生效，其中的设置将覆盖docker.service中的选项</strong></li></ul><h2 id="三、步骤"><a href="#三、步骤" class="headerlink" title="三、步骤"></a>三、步骤</h2><h3 id="1、创建目录"><a href="#1、创建目录" class="headerlink" title="1、创建目录"></a>1、创建目录</h3><pre><code class="bash">mkdir -p /etc/systemd/system/docker.service.d</code></pre><h3 id="2、添加网络代理配置文件"><a href="#2、添加网络代理配置文件" class="headerlink" title="2、添加网络代理配置文件"></a>2、添加网络代理配置文件</h3><pre><code class="bash">cat &gt;&gt; a &lt;&lt; EOF[Service]Environment=&quot;HTTP_PROXY=http://proxy-addr:proxy-port/&quot; &quot;HTTPS_PROXY=http://proxy-addr:proxy-port/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker.io,yanzhe919.mirror.aliyuncs.com,99nkhzdo.mirror.aliyuncs.com,*.aliyuncs.com,*.mirror.aliyuncs.com,registry.docker-cn.com,hub.c.163.com,hub-auth.c.163.com,&quot;EOF</code></pre><p>proxy-addr为代理IP或域名；proxy-port为代理端口；NO_PROXY后面接不需要代理的仓库的域名或者IP，以英文逗号结尾。</p><p><strong>注意：如果使用privoxy将http代理转换为socks5代理，这里porxy-addr和port就要写privoxy的IP和端口，比如127.0.0.1:8118</strong></p><h3 id="3、重载配置并重启docker服务"><a href="#3、重载配置并重启docker服务" class="headerlink" title="3、重载配置并重启docker服务"></a>3、重载配置并重启docker服务</h3><pre><code class="bash">systemctl daemon-reloadsystemctl restart docker</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;当docker在拉取国外的镜像，并且没有国内加速源的资源，速度很慢，甚至访问不到，比如安装k8s的时候。这时候就需要添加ht</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="http代理" scheme="https://www.langxw.com/tags/http%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>使用Privoxy将http代理转换成socks5代理</title>
    <link href="https://www.langxw.com/2021/06/04/%E4%BD%BF%E7%94%A8Privoxy%E5%B0%86http%E4%BB%A3%E7%90%86%E8%BD%AC%E6%8D%A2%E6%88%90socks5%E4%BB%A3%E7%90%86/"/>
    <id>https://www.langxw.com/2021/06/04/%E4%BD%BF%E7%94%A8Privoxy%E5%B0%86http%E4%BB%A3%E7%90%86%E8%BD%AC%E6%8D%A2%E6%88%90socks5%E4%BB%A3%E7%90%86/</id>
    <published>2021-06-04T11:00:16.000Z</published>
    <updated>2021-06-04T11:07:54.375Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>在工作电脑上（Win10系统）安装了SSR客户端，实现了浏览器的科学上网。但是呢，使用命令行（无论是cmd还是Shell）从github上拉取代码、拉取Docker镜像，依然很慢，有时候还会连接超时，被墙，很是苦恼。</p><p>最典型的场景，在使用kubeadm工具安装k8s的时候，拉取的都是google的镜像，由于被墙，压根访问不通。你当然可以指定使用阿里云镜像库，但是其他插件的安装，比如存储插件rook、网络插件weave，还是要访问被墙的镜像库，就会下载不到 ，很烦。</p><p>最一劳永逸的办法就是，搞通网络，让Shell终端或者Docker pull可以使用sockts5代理访问被墙的资源。</p><h2 id="二、思路"><a href="#二、思路" class="headerlink" title="二、思路"></a>二、思路</h2><ul><li><p>我工作电脑本地存在SSR客户端，可以翻墙，使用的是socks5协议。</p></li><li><p>一般cmd、shell、docker pull、git clone等命使用的都是http协议，可以配置http代理。</p></li><li><p>故考虑将http代理转换成socks5代理，这样命令行就能翻墙了。</p></li></ul><p>具体流程图如下：</p><pre class="mermaid">graph LR    Cmd -->|http代理| Privoxy --> |Socks5代理|SSR客户端 --> SSR服务端</pre><h2 id="三、解决办法"><a href="#三、解决办法" class="headerlink" title="三、解决办法"></a>三、解决办法</h2><h3 id="1、实验环境"><a href="#1、实验环境" class="headerlink" title="1、实验环境"></a>1、实验环境</h3><p><strong>Ubuntu16.04 + Privoxy 3.0.24 + Win10 SSR客户端</strong></p><h3 id="2、安装privoxy"><a href="#2、安装privoxy" class="headerlink" title="2、安装privoxy"></a>2、安装privoxy</h3><pre><code class="bash">sudo apt-get install privoxy</code></pre><h3 id="3、修改配置"><a href="#3、修改配置" class="headerlink" title="3、修改配置"></a>3、修改配置</h3><p>打开配置文件<code>vim  /etc/privoxy/config</code>，修改如下两处：</p><pre><code class="shell"># 如果想让其他主机使用这个代理转换，可以监听0.0.0.0listen-address  127.0.0.1:8118# 这里填写局域网内SSR客户端的IP和端口，端口默认1080。# 如果SSR客户端是在本地就写127.0.0.1:1080forward-socks5   /               192.168.101.79:1080 .</code></pre><h3 id="4、启动privoxy服务"><a href="#4、启动privoxy服务" class="headerlink" title="4、启动privoxy服务"></a>4、启动privoxy服务</h3><pre><code class="bash">sudo  service  privoxy start</code></pre><h3 id="5、设置http和https的全局代理"><a href="#5、设置http和https的全局代理" class="headerlink" title="5、设置http和https的全局代理"></a>5、设置http和https的全局代理</h3><pre><code class="bash">export http_proxy=&#39;http://127.0.0.1:8118&#39;export https_proxy=&#39;http://127.0.0.1:8118&#39;</code></pre><p><strong>注意：不建议将这个代理的环境变量写入profile文件，只建议在需要的时候在当前shell窗口写入这个变量即可。</strong></p><h3 id="6、测试"><a href="#6、测试" class="headerlink" title="6、测试"></a>6、测试</h3><p>使用wget或者curl命令访google.com，返回正常页面内容即成功。</p><pre><code class="bash">wget www.google.com curl www.google.com</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;在工作电脑上（Win10系统）安装了SSR客户端，实现了浏览器的科学上网。但是呢，使用命令行（无论是cmd还是Shell）从</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="翻墙" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/%E7%BF%BB%E5%A2%99/"/>
    
    
    <category term="privoxy" scheme="https://www.langxw.com/tags/privoxy/"/>
    
  </entry>
  
  <entry>
    <title>一键重命名钉钉接收到的文件</title>
    <link href="https://www.langxw.com/2021/05/28/%E4%B8%80%E9%94%AE%E9%87%8D%E5%91%BD%E5%90%8D%E9%92%89%E9%92%89%E6%8E%A5%E6%94%B6%E5%88%B0%E7%9A%84%E6%96%87%E4%BB%B6/"/>
    <id>https://www.langxw.com/2021/05/28/%E4%B8%80%E9%94%AE%E9%87%8D%E5%91%BD%E5%90%8D%E9%92%89%E9%92%89%E6%8E%A5%E6%94%B6%E5%88%B0%E7%9A%84%E6%96%87%E4%BB%B6/</id>
    <published>2021-05-28T09:21:30.000Z</published>
    <updated>2021-05-28T09:23:35.847Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>由于某些原因，公司的程序只能手动发版，开发本地打包好后通过钉钉发送给运维。但是钉钉接收到名字一样的文件后，会自动重命名，加上括号和数字，比如apollo-1.0.RELEASE(2).jar，这样你就需要手动处理掉后面的括号和数字。</p><p>手动太麻烦，索性就用python来实现自动重名，并将python代码打包成exe程序，后将exe程序固定在任务栏。这样鼠标点一下任务栏图标，就可以实现一键重命名阿里云接收到的文件，Nice。</p><h2 id="二、代码实现"><a href="#二、代码实现" class="headerlink" title="二、代码实现"></a>二、代码实现</h2><pre><code class="ptyhon">import osimport redownload_dir = &#39;C:\\Users\\Thinkpad\\Downloads&#39;file_dic = &#123;&#125;# 重命名最新的一个文件，去掉文件名的括号和数字# apollo-1.0.RELEASE(2).jar --&gt; apollo-1.0.RELEASE.jar# downloads文件夹就一个文件怎么处理。文件夹为空，就先就报错吧。# 如果有downloads下有文件夹，也会报错，需要调用os.rmdir()来处理。def delete_other_files():    files = os.listdir(download_dir)    for file in files:        mtime = os.stat(os.path.join(download_dir, file)).st_mtime        file_dic[mtime] = file    time_list = list(file_dic.keys())    max_time = max(time_list)    if len(file_dic) &gt; 1:        time_list.remove(max_time)        for time in time_list:            os.remove(os.path.join(download_dir, file_dic[time]))    return file_dic[max_time]# 如果只有一个正常的文件，不做替换，def rename_file(file):    new_name = re.sub(r&#39;\(\d+\)&#39;, &#39;&#39;, file)    os.chdir(download_dir)    os.rename(file, new_name)if __name__ == &#39;__main__&#39;:    file_name = delete_other_files()    # file_name = &#39;dist.zip&#39;    rename_file(file_name)</code></pre><h2 id="三、将Python代码打包成exe文件"><a href="#三、将Python代码打包成exe文件" class="headerlink" title="三、将Python代码打包成exe文件"></a>三、将Python代码打包成exe文件</h2><p>这里使用pyinstaller模块，具体命令为：</p><pre><code class="shell">pyinstaller -F -c main.py</code></pre><p>将Python打包成exe文件的具体介绍见另一篇文章：<a href="https://www.langxw.com/2021/04/14/Python%E5%88%B6%E4%BD%9CExce%E6%8A%A5%E8%A1%A8%E5%B9%B6%E6%89%93%E5%8C%85/">Python制作Exce报表并打包</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;由于某些原因，公司的程序只能手动发版，开发本地打包好后通过钉钉发送给运维。但是钉钉接收到名字一样的文件后，会自动重命名，加上</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Python脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Python%E8%84%9A%E6%9C%AC/"/>
    
    
    <category term="python" scheme="https://www.langxw.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>命令行查看SSL证书的有效期和组织</title>
    <link href="https://www.langxw.com/2021/05/19/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9F%A5%E7%9C%8BSSL%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F%E5%92%8C%E7%BB%84%E7%BB%87/"/>
    <id>https://www.langxw.com/2021/05/19/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9F%A5%E7%9C%8BSSL%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F%E5%92%8C%E7%BB%84%E7%BB%87/</id>
    <published>2021-05-19T06:24:19.000Z</published>
    <updated>2021-05-19T06:25:48.390Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>生产某个SSL证书要到期需要更换，生产环境又特别复杂：多证书+证书名字不明确（ssl.pem），不敢随意更换，只能先核对好组织名字和到期时间后，再进行更换。</p><h2 id="二、解决办法"><a href="#二、解决办法" class="headerlink" title="二、解决办法"></a>二、解决办法</h2><h3 id="1、全盘搜索证书"><a href="#1、全盘搜索证书" class="headerlink" title="1、全盘搜索证书"></a>1、全盘搜索证书</h3><p><code>sudo find / -name &#39;*.key&#39;</code></p><h3 id="2、确认Nginx配置的证书"><a href="#2、确认Nginx配置的证书" class="headerlink" title="2、确认Nginx配置的证书"></a>2、确认Nginx配置的证书</h3><p><code>grep pem /etc/nginx/conf.d/default.conf</code></p><h3 id="3、查看证书的组织"><a href="#3、查看证书的组织" class="headerlink" title="3、查看证书的组织"></a>3、查看证书的组织</h3><p><code>openssl x509 -in ssl.pem -noout -text|grep &#39;CN&#39;</code></p><h3 id="4、查看证书的到期时间"><a href="#4、查看证书的到期时间" class="headerlink" title="4、查看证书的到期时间"></a>4、查看证书的到期时间</h3><p><code>openssl x509 -in ssl.pem -noout -dates</code></p><h3 id="5、批量查看证书到期时间"><a href="#5、批量查看证书到期时间" class="headerlink" title="5、批量查看证书到期时间"></a>5、批量查看证书到期时间</h3><p><code>ls  /ssl/ |grep -e &#39;pem$&#39;| xargs -I &#123;&#125; openssl x509 -in &#123;&#125; -noout -dates</code></p><p>xargs的参数-I 用来指定一个替换字符串{}，表示字符串{}会被前面的输出替换掉</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;生产某个SSL证书要到期需要更换，生产环境又特别复杂：多证书+证书名字不明确（ssl.pem），不敢随意更换，只能先核对好组</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="命令行" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/%E5%91%BD%E4%BB%A4%E8%A1%8C/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>命令行获取公网IP地址</title>
    <link href="https://www.langxw.com/2021/05/19/%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%8E%B7%E5%8F%96%E5%85%AC%E7%BD%91IP%E5%9C%B0%E5%9D%80/"/>
    <id>https://www.langxw.com/2021/05/19/%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%8E%B7%E5%8F%96%E5%85%AC%E7%BD%91IP%E5%9C%B0%E5%9D%80/</id>
    <published>2021-05-19T06:22:20.000Z</published>
    <updated>2021-05-19T06:23:50.291Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、直接获取"><a href="#1、直接获取" class="headerlink" title="1、直接获取"></a>1、直接获取</h3><p><code>curl ip.sb</code></p><h3 id="2、获取Json格式"><a href="#2、获取Json格式" class="headerlink" title="2、获取Json格式"></a>2、获取Json格式</h3><p><code>curl https://api.ip.sb/jsonip </code></p><h3 id="3、获取地址位置信息Json"><a href="#3、获取地址位置信息Json" class="headerlink" title="3、获取地址位置信息Json"></a>3、获取地址位置信息Json</h3><p><code>curl https://api.ip.sb/geoip</code></p><h3 id="4、加上回调地址"><a href="#4、加上回调地址" class="headerlink" title="4、加上回调地址"></a>4、加上回调地址</h3><p><code>curl https://api.ip.sb/jsonip?callback=myip</code> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1、直接获取&quot;&gt;&lt;a href=&quot;#1、直接获取&quot; class=&quot;headerlink&quot; title=&quot;1、直接获取&quot;&gt;&lt;/a&gt;1、直接获取&lt;/h3&gt;&lt;p&gt;&lt;code&gt;curl ip.sb&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;2、获取Json格式&quot;&gt;&lt;a hre</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="命令行" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/%E5%91%BD%E4%BB%A4%E8%A1%8C/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>Nginx反向代理时端口丢失的解决</title>
    <link href="https://www.langxw.com/2021/05/19/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E7%AB%AF%E5%8F%A3%E4%B8%A2%E5%A4%B1%E7%9A%84%E8%A7%A3%E5%86%B3/"/>
    <id>https://www.langxw.com/2021/05/19/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E7%AB%AF%E5%8F%A3%E4%B8%A2%E5%A4%B1%E7%9A%84%E8%A7%A3%E5%86%B3/</id>
    <published>2021-05-19T06:20:11.000Z</published>
    <updated>2021-05-19T06:21:53.151Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>nginx有时候并不像apache那样智能，对于redirect location的处理尤为惨淡，几乎只能用户手工处理非标准端口的问题。</p><p>比如，因为种种原因，nginx并不能监听在80端口，或者外部通过NAT方式将请求丢给nginx，外部地址并不是标准http(s)端口（非80和443端口），此时nginx并不能美好的处理这些重定向。发生重定向的时候会丢失端口。</p><p>例如：Nginx监听非80端口，访问欢迎页面时应该是重定向到登录页面，在这个重定向的过程中端口丢失了。</p><h2 id="二、解决办法"><a href="#二、解决办法" class="headerlink" title="二、解决办法"></a>二、解决办法</h2><p>一般是在将反向代理配置在location中，以匹配不同代理规则的需要。</p><p>经实践，以下办法都可以实现，三选一即可，优先选择1，再者选择2。</p><pre><code class="shell">1、 proxy_set_header Host $host:$server_port; （跟版本有关系，我的失效）2、 proxy_set_header Host $http_host;（跟版本有关系，我的失效）3、 proxy_set_header Host $host:11011;（直接强制注入端口号，亲测有效）</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;nginx有时候并不像apache那样智能，对于redirect location的处理尤为惨淡，几乎只能用户手工处理非标准</summary>
      
    
    
    
    <category term="中间件" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="Nginx" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Nginx/"/>
    
    
    <category term="nginx" scheme="https://www.langxw.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Python制作Exce报表并打包</title>
    <link href="https://www.langxw.com/2021/04/14/Python%E5%88%B6%E4%BD%9CExce%E6%8A%A5%E8%A1%A8%E5%B9%B6%E6%89%93%E5%8C%85/"/>
    <id>https://www.langxw.com/2021/04/14/Python%E5%88%B6%E4%BD%9CExce%E6%8A%A5%E8%A1%A8%E5%B9%B6%E6%89%93%E5%8C%85/</id>
    <published>2021-04-14T07:25:45.000Z</published>
    <updated>2021-04-14T07:43:48.322Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>在公司报表系统没有出来之前，每日运营数据的需求由运维或者DBA查数据库手动拉取，徒增工作量。</p><p>故考虑做一个exe文件，让产品童鞋点一下就自动生成一个包含昨日的数据的Excel表格，省心省力。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><p><strong>Win10 + Pycharm + Python3.7 + pymysql + openpyxl + pyinstaller</strong></p><p>说明：</p><ol><li>因为办公环境是windows，如果是Linux、Mac则可以设置定时任务来自动跑Python脚本</li><li>openpyxl模块，用来处理excel文档，操作简单，功能强大</li><li>pyinstaller模块，可以将python脚本打包成exe程序，还可以加密除入口函数外的pyhon脚本。</li></ol><h2 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h2><pre><code class="python">import pymysqlimport timefrom openpyxl import Workbook# MySQL查询函数def query_db(sql):    conn = pymysql.connect(host=&#39;1.1.1.1&#39;,                           port=3306,                           user=&#39;test_ro&#39;,                           password=&#39;$uT%8ono&#39;,                           db=&#39;test&#39;,                           cursorclass=pymysql.cursors.DictCursor                           )    with conn.cursor() as cursor:        # 为了避免SQL注入，生产环境这里不要直接传入SQL，要带参数的拼接形式        cursor.execute(sql)        result = cursor.fetchall()    conn.close()    return result# 处理多个SQL查询语句，并将结果拼接成包含多个字典的列表def handle_result():    # 获得昨天的日期    yesterday_time = time.localtime(time.time()-86400)    yesterday = time.strftime(&#39;%Y-%m-%d&#39;, yesterday_time)    res_list = [&#123;&#39;日期&#39;: &#39;&#123;&#125;&#39;.format(yesterday)&#125;, ]    sql_list = [        &quot;SELECT COUNT(*) AS &#39;累计进件总笔数&#39; FROM ( SELECT COUNT(*) FROM test_apply_account WHERE apply_date &lt; &#39;&#123;&#125; 23:59:59&#39; GROUP BY cert_no) A&quot;.format(yesterday),        &quot;SELECT count(*) AS &#39;当日进件总笔数&#39; FROM (SELECT count(*) FROM test_apply_account WHERE apply_date BETWEEN &#39;&#123;&#125; 00:00:00&#39; AND &#39;&#123;&#125; 23:59:59&#39; GROUP BY cert_no) A&quot;.format(yesterday, yesterday),        &quot;SELECT  count(*) as &#39;当日授信总笔数数&#39; FROM test_credit_apply WHERE credit_date BETWEEN &#39;&#123;&#125; 00:00:00&#39; AND &#39;&#123;&#125; 23:59:59&#39;&quot;.format(yesterday, yesterday),        &quot;SELECT count(*) as &#39;当日授信通过笔数&#39; FROM test_credit_apply WHERE credit_date BETWEEN &#39;&#123;&#125; 00:00:00&#39; AND &#39;&#123;&#125; 23:59:59&#39; AND credit_status=&#39;SUCCESS&#39;&quot;.format(yesterday, yesterday),    ]    for sql in sql_list:        res = query_db(sql)        res_list += res    return res_list# 将拼接好的数据写入excel，以新建excel表格的形式def write_excel(data):    wb = Workbook()    wb.create_sheet(&#39;XX每日数据&#39;, 0)    sheet = wb.active    i = 1    for item in data:        sheet.cell(row=1, column=i, value=list(item.keys())[0])        sheet.cell(row=2, column=i, value=list(item.values())[0])        i += 1    wb.save(&#39;xx_everyday.xlsx&#39;)if __name__ == &#39;__main__&#39;:    res_list = handle_result()    write_excel(res_list)</code></pre><h2 id="四、将python脚本打包成exe文件"><a href="#四、将python脚本打包成exe文件" class="headerlink" title="四、将python脚本打包成exe文件"></a>四、将python脚本打包成exe文件</h2><p>这里使用pyinstaller模块，具体命令为：</p><pre><code class="shell">pyinstaller -F -c --key 123456 main.py</code></pre><p>参数解释：</p><ol><li>-F 打包成单个exe文件，相反的参数为-D</li><li>-c 显示cmd控制台，相反的参数为-w</li><li>–key 密钥，加密打包，但是只对引入的库文件进行加密，所以建议main.py中只写入口函数，其他的函数进行引用</li><li>这样的加密基本安全，要想完全反编译，没点水平很难做到。</li></ol><p><strong>注意：pyinstaller 加密需要tinyaes包，tinyaes又依赖于Microsoft Visual C++，C++也要安装Win10 SDK。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;在公司报表系统没有出来之前，每日运营数据的需求由运维或者DBA查数据库手动拉取，徒增工作量。&lt;/p&gt;
&lt;p&gt;故考虑做一个ex</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Python脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Python%E8%84%9A%E6%9C%AC/"/>
    
    
    <category term="python" scheme="https://www.langxw.com/tags/python/"/>
    
    <category term="mysql" scheme="https://www.langxw.com/tags/mysql/"/>
    
    <category term="excel" scheme="https://www.langxw.com/tags/excel/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb小版本热升级</title>
    <link href="https://www.langxw.com/2021/04/14/Mongodb%E5%B0%8F%E7%89%88%E6%9C%AC%E7%83%AD%E5%8D%87%E7%BA%A7/"/>
    <id>https://www.langxw.com/2021/04/14/Mongodb%E5%B0%8F%E7%89%88%E6%9C%AC%E7%83%AD%E5%8D%87%E7%BA%A7/</id>
    <published>2021-04-14T02:10:43.000Z</published>
    <updated>2021-04-14T02:11:44.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>我司一个系统中用到mongodb 3.2.1版本，但是漏扫软件扫出来有重大漏洞，需要打补丁（升级版本）。</p><p>部署3.2的最后一个版本3.2.22后，经扫描没有漏洞，同时业务系统也支持3.2.22版本，决定采用mongodb 3.2.22版本。</p><p><strong>环境：Centos 7.6 + rpm包方式安装的mongo 3.2.1</strong></p><h2 id="二、热升级"><a href="#二、热升级" class="headerlink" title="二、热升级"></a>二、热升级</h2><p><strong>注意：热升级仅支持小版本的升级，跨大版本的升级，请严格按照停机备份还原的方法来。</strong></p><pre><code class="shell">rpm -Fvh mongodb-org-server-3.2.22-1.el7.x86_64.rpm    --nodepsrpm -Fvh mongodb-org-tools-3.2.22-1.el7.x86_64.rpm    --nodepsrpm -Fvh mongodb-org-mongos-3.2.22-1.el7.x86_64.rpm    --nodepsrpm -Fvh mongodb-org-shell-3.2.22-1.el7.x86_64.rpm    --nodepsrpm -Fvh mongodb-org-3.2.22-1.el7.x86_64.rpm --nodepssystemctl daemon-reload</code></pre><h2 id="三、验证"><a href="#三、验证" class="headerlink" title="三、验证"></a>三、验证</h2><ul><li>运维使用客户端或命令行，进行一些版本或数据查询的验证</li><li>主要还是要观察业务是否可用</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;我司一个系统中用到mongodb 3.2.1版本，但是漏扫软件扫出来有重大漏洞，需要打补丁（升级版本）。&lt;/p&gt;
&lt;p&gt;部署</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>基于SSH服务的SFTP应用</title>
    <link href="https://www.langxw.com/2021/04/13/%E5%9F%BA%E4%BA%8ESSH%E6%9C%8D%E5%8A%A1%E7%9A%84SFTP%E5%BA%94%E7%94%A8/"/>
    <id>https://www.langxw.com/2021/04/13/%E5%9F%BA%E4%BA%8ESSH%E6%9C%8D%E5%8A%A1%E7%9A%84SFTP%E5%BA%94%E7%94%A8/</id>
    <published>2021-04-13T12:48:55.000Z</published>
    <updated>2021-04-13T12:50:14.357Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、需求"><a href="#一、需求" class="headerlink" title="一、需求"></a>一、需求</h2><p>初创公司，资源和资金有限，无法搭建日志系统。</p><p>系统上线初期，开发人员需要经常查看生产日志来定位bug，且不能给予开发人员生产服务器的权限。</p><p>需要一个简单、安全、轻量级、不耗费资源的方法来满足查看日志的需求。</p><h2 id="二、方案"><a href="#二、方案" class="headerlink" title="二、方案"></a>二、方案</h2><p>经过调研，使用<strong>基于SSH服务的SFTP和Mount挂载本机目录</strong>的方法，可以满足需求。</p><p>此方法，可以进行严格的权限控制：只读、不能访问其他目录、不能登录服务器。</p><h2 id="三、实施步骤"><a href="#三、实施步骤" class="headerlink" title="三、实施步骤"></a>三、实施步骤</h2><h3 id="1、新建用做SFTP的用户"><a href="#1、新建用做SFTP的用户" class="headerlink" title="1、新建用做SFTP的用户"></a>1、新建用做SFTP的用户</h3><pre><code class="shell">groupadd log_ro -g 2000useradd log_ro -u 2000 -g 2000 -d /home/log_ro -s /sbin/nologin</code></pre><ul><li>如果服务器是使用密码的登录的，就需要设置log_ro用户的密码<code>passwd log_ro</code></li><li>如果是使用密钥登录的，就要为log_ro做密钥登录的相关配置，和ssh登录一样</li><li>-s /sbin/nologin 控制其不能登录服务器</li></ul><h3 id="2、控制权限"><a href="#2、控制权限" class="headerlink" title="2、控制权限"></a>2、控制权限</h3><p>对SFTP用户，做不能切换目录和只读的权限控制。</p><p>注意：只读是针对SFTP的home目录的，对于日志的只读权限，由日志本身的权限属性进行控制。</p><pre><code class="shell">chown root:log_ro /home/log_rochmod 755 /home/log_ro</code></pre><h3 id="3、修改sshd配置"><a href="#3、修改sshd配置" class="headerlink" title="3、修改sshd配置"></a>3、修改sshd配置</h3><pre><code class="shell">sed -i &quot;s/Subsystem/#Subsystem/g&quot; /etc/ssh/sshd_config</code></pre><pre><code class="shell">cat &gt;&gt; /etc/ssh/sshd_config &lt;&lt; EOF# sftp for read log    Subsystem sftp internal-sftpUsePAM yesMatch User log_ro    ChrootDirectory /home/log_ro/    ForceCommand internal-sftp    AllowTcpForwarding no    X11Forwarding noEOF    </code></pre><p>在配置文件中， User指定了sftp的用户，ChrootDirectory指定了sftp登录后的根目录。</p><p>注意：</p><ul><li>根目录本身所属必须是root，属组为sftp用户的属组，权限最小为755。意味着log_ro本身是不能在/home/log_ro中建立新文件、文件夹或者修改文件的。</li><li>虽然ftp用户对于登录后的根目录没有写权限，但是我们可以用root新建一个文件夹，比如叫upload，然后把这个文件夹所属改为log_ro，这样ftp用户就对/home/log_ro/upload拥有完全的写权限了。上传文件不要放到根目录而是放到upload下面。</li></ul><h3 id="4、重启sshd"><a href="#4、重启sshd" class="headerlink" title="4、重启sshd"></a>4、重启sshd</h3><p>关掉Selinux：<code>setenforce 0</code>，重启sshd服务<code>systemctl restart sshd</code></p><h3 id="5、使用mount挂载日志文件"><a href="#5、使用mount挂载日志文件" class="headerlink" title="5、使用mount挂载日志文件"></a>5、使用mount挂载日志文件</h3><p><strong>因为软连接在ftp中不能生效，又因为硬链接不能链接目录，所以采用mount挂载本机文件系统的方法实现软连接。</strong></p><pre><code class="shell">mkdir fps_logschown log_ro.log_ro fps_logsmount --bind /data/app/fps/logs fps_logs</code></pre><h3 id="6、验证"><a href="#6、验证" class="headerlink" title="6、验证"></a>6、验证</h3><p>使用ftp客户端来验证对于ftp用户权限的控制。</p><h2 id="四、其他"><a href="#四、其他" class="headerlink" title="四、其他"></a>四、其他</h2><p>最后介绍一下，如果不使用家目录作为sftp的根目录，使用其他目录的方法。</p><p>但是有一个原则还是要遵守，就是sftp所在的根目录，和其所有的上级目录，所属必须是root，不然就会碰到sftp连接马上被关闭的情况。</p><p>比如我们想要登录后的根目录为/data/haha/abc</p><p>/data/haha/abc 应该为root:zhongan 755</p><p>/data/haha/       应该为root:root         755</p><p>/data                 应该为root:root         755</p><p>如果想要上传文件，应该建立/data/haha/abc/upload文件夹，所属zhongan:zhongan , 755，然后上传文件的目标路径为/upload</p><p>然后修改/etc/ssh/sshd_config ,修改ChrootDirectory后面的目录为/data/haha/abc/</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、需求&quot;&gt;&lt;a href=&quot;#一、需求&quot; class=&quot;headerlink&quot; title=&quot;一、需求&quot;&gt;&lt;/a&gt;一、需求&lt;/h2&gt;&lt;p&gt;初创公司，资源和资金有限，无法搭建日志系统。&lt;/p&gt;
&lt;p&gt;系统上线初期，开发人员需要经常查看生产日志来定位bug，且不能给</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="FTP" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/FTP/"/>
    
    
    <category term="FTP" scheme="https://www.langxw.com/tags/FTP/"/>
    
    <category term="SFTP" scheme="https://www.langxw.com/tags/SFTP/"/>
    
  </entry>
  
  <entry>
    <title>日志系统的选型</title>
    <link href="https://www.langxw.com/2021/04/13/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%89%E5%9E%8B/"/>
    <id>https://www.langxw.com/2021/04/13/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%89%E5%9E%8B/</id>
    <published>2021-04-13T11:36:34.000Z</published>
    <updated>2021-04-13T11:47:18.922Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、需求"><a href="#一、需求" class="headerlink" title="一、需求"></a>一、需求</h2><p>简单、安全、轻量级、不耗费资源、最好能时时查看日志（需求不大）。</p><h2 id="二、选型"><a href="#二、选型" class="headerlink" title="二、选型"></a>二、选型</h2><table><thead><tr><th>方法</th><th>工具</th></tr></thead><tbody><tr><td>日志系统</td><td>Rsyslog，Fluented，ELK，Loki、Logio、SLS</td></tr><tr><td>定时同步</td><td>Scp、Rsync</td></tr><tr><td>文件共享</td><td>SFTP、VSFTP、NFS共享、NAS</td></tr><tr><td>可视化</td><td>Jenkins + Ansible + Shell Or Python Web</td></tr></tbody></table><h2 id="三、分析"><a href="#三、分析" class="headerlink" title="三、分析"></a>三、分析</h2><h3 id="1、日志系统"><a href="#1、日志系统" class="headerlink" title="1、日志系统"></a>1、日志系统</h3><ol><li>如果是中大型系统，不缺资源，不缺经费，那么就可以采用开源的日志系统或者采用阿里云SLS日志系统。</li><li>可以根据日志规模，应用规模来进行选型，简单的就用Rsyslog、Logio，复杂的就用Fluented、ELK、LoKi。</li><li>如果使用的是云主机而且不差钱，可以使用阿里云日志系统SLS，还是很好用的，功能也很强大。</li></ol><h3 id="2、定时同步"><a href="#2、定时同步" class="headerlink" title="2、定时同步"></a>2、定时同步</h3><ol><li>如果对实时性要求不高，我们可以Scp或者Rsync脚本定时远程同步，问题就在于间隔时间的确定和来自不同机器的名字相同的文件的区分。</li><li>可以在每台日志服务器上搭建rsync服务端，进行推送，但如果日志分散的话，需要安装多个服务端，不建议。</li></ol><h3 id="3、文件共享"><a href="#3、文件共享" class="headerlink" title="3、文件共享"></a>3、文件共享</h3><ol><li>可以使用NFS或者NAS，将一块磁盘挂载到所有机器上，然后使用软连接来访问不同的日志。</li><li>还可以使用基于SSH服务端的SFTP服务，进行权限控制后，将日志目录挂载到用户目录进行日志的下载。</li></ol><h3 id="4、可视化"><a href="#4、可视化" class="headerlink" title="4、可视化"></a>4、可视化</h3><p>可视化web界面可以使用Jenkins+Ansible+Shell来实现，也可以自己写Python网页来实现，具体实现有待研究。</p><h2 id="四、结论"><a href="#四、结论" class="headerlink" title="四、结论"></a>四、结论</h2><p>作为一个初创公司的小型系统，由于资源缺乏，日志查询需求不是频繁，也不太需要查看实时日志，故采用<strong>SFTP + mount</strong>的形式来满足开发查询日志的需求。不额外安装软件，不占用系统资源，配置简单，就很Nice。</p><h2 id="五、注意"><a href="#五、注意" class="headerlink" title="五、注意"></a>五、注意</h2><ol><li>硬链接不能跨分区，硬连接不能链接目录，只能链接文件。</li><li>FTP不支持软连接。</li><li>Mount可以挂载本机的文件目录。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、需求&quot;&gt;&lt;a href=&quot;#一、需求&quot; class=&quot;headerlink&quot; title=&quot;一、需求&quot;&gt;&lt;/a&gt;一、需求&lt;/h2&gt;&lt;p&gt;简单、安全、轻量级、不耗费资源、最好能时时查看日志（需求不大）。&lt;/p&gt;
&lt;h2 id=&quot;二、选型&quot;&gt;&lt;a href=&quot;#二</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="FTP" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/FTP/"/>
    
    
    <category term="FTP" scheme="https://www.langxw.com/tags/FTP/"/>
    
    <category term="日志系统" scheme="https://www.langxw.com/tags/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb复制集建议奇数个节点的原因</title>
    <link href="https://www.langxw.com/2021/03/12/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E5%BB%BA%E8%AE%AE%E5%A5%87%E6%95%B0%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E5%8E%9F%E5%9B%A0/"/>
    <id>https://www.langxw.com/2021/03/12/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E5%BB%BA%E8%AE%AE%E5%A5%87%E6%95%B0%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E5%8E%9F%E5%9B%A0/</id>
    <published>2021-03-12T14:58:06.000Z</published>
    <updated>2021-03-16T12:21:15.271Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、官方建议"><a href="#一、官方建议" class="headerlink" title="一、官方建议"></a>一、官方建议</h2><p><strong>奇数个就不用带仲裁节点了，偶数个要带一个仲裁节点。</strong></p><h2 id="二、原因分析"><a href="#二、原因分析" class="headerlink" title="二、原因分析"></a>二、原因分析</h2><ol><li><p>防止网络阻隔；防止脑列，导致选举失败。两个IDC机房网络中断，或者两个机柜网络中断。</p></li><li><p>存活数（参与选举数）大与50%，集群才能正常工作的原则，说明了偶数个节点基本就是浪费资源（除了多个一个可读的副本）</p></li></ol><h2 id="三、三节点复制集带仲裁节点与不带的优劣"><a href="#三、三节点复制集带仲裁节点与不带的优劣" class="headerlink" title="三、三节点复制集带仲裁节点与不带的优劣"></a>三、三节点复制集带仲裁节点与不带的优劣</h2><ul><li>带仲裁节点，仲裁节点占用资源小，可节省资源。</li><li>不带，多一个可读副本集，分散读的压力。多一个数据备份。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、官方建议&quot;&gt;&lt;a href=&quot;#一、官方建议&quot; class=&quot;headerlink&quot; title=&quot;一、官方建议&quot;&gt;&lt;/a&gt;一、官方建议&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;奇数个就不用带仲裁节点了，偶数个要带一个仲裁节点。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb分片集群部署</title>
    <link href="https://www.langxw.com/2021/03/12/Mongodb%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://www.langxw.com/2021/03/12/Mongodb%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</id>
    <published>2021-03-12T12:52:20.000Z</published>
    <updated>2021-04-13T12:57:21.957Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、架构"><a href="#一、架构" class="headerlink" title="一、架构"></a>一、架构</h2><h3 id="1、Mongodb分片集群配置"><a href="#1、Mongodb分片集群配置" class="headerlink" title="1、Mongodb分片集群配置"></a>1、Mongodb分片集群配置</h3><p>按照尽量节省资源的原则，不交叉部署的原则：</p><table><thead><tr><th>作用</th><th>配置</th><th>数量</th></tr></thead><tbody><tr><td>分片1-主、分片1-副</td><td>8C16G300GSSD</td><td>2</td></tr><tr><td>分片1-仲裁节点</td><td>4C8G100GSSD</td><td>1</td></tr><tr><td>分片2-主、分片2-副</td><td>8C16G300GSSD</td><td>2</td></tr><tr><td>分片2-仲裁节点</td><td>4C8G100GSSD</td><td>1</td></tr><tr><td>config服务复制集（1主2副）</td><td>4C8G100GSSD</td><td>3</td></tr><tr><td>mongos路由</td><td>2C4G40GSSD</td><td>3</td></tr></tbody></table><h3 id="2、说明"><a href="#2、说明" class="headerlink" title="2、说明"></a>2、说明</h3><p>MongoDB分片集群，英文名称为： Sharded Cluster。旨在通过横向扩展，来提高数据吞吐性能、增大数据存储量。</p><p>分片集群由三个组件：“mongos”, “config server”, “shard” 组成。<br><img src="https://img-blog.csdnimg.cn/20190416151746484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW5iZWliZWk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><ul><li><p>mongos:数据库请求路由。负责接收所有客户端应用程序的连接查询请求，并将请求路由到集群内部对应的分片上。”mongos”可以有1个或多个。</p><p>本身不保存数据，在启动时从配置服务器加载集群信息，开启mongos进程需要知道配置服务器的地址，指定configdb选项。</p></li><li><p>config server: 配置服务器。是一个独立的mongod进程，保存集群和分片的元数据，即各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动配置服务器，指定configsvr选项。不需要太多的空间和资源，配置服务器的1KB空间相当于真是数据的200MB。保存的只是数据的分布表。当服务不可用，则变成只读，无法分块、迁移数据。</p></li><li><p>shard: 分片存储。将数据分片存储在多个服务器上。有点类似关系数据库”分区表”的概念，只不过分区表是将数据分散存储在多个文件中，而sharding将数据分散存储在多个服务器上。一个集群可以有一个或多个分片。</p></li><li><p>每个分片都必须是副本集，“config server” 必须是副本集！</p></li></ul><h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><ul><li><p>操作系统：Centos6.5</p></li><li><p>Mongodb版本：3.2.1 RPM包</p><pre><code class="bash">mongodb-org-server-3.2.1-1.el7.x86_64.rpmmongodb-org-tools-3.2.1-1.el7.x86_64.rpmmongodb-org-mongos-3.2.1-1.el7.x86_64.rpmmongodb-org-shell-3.2.1-1.el7.x86_64.rpmmongodb-org-3.2.1-1.el7.x86_64.rpm</code></pre></li><li><p>主机规划：mongos（3个）+ config server 副本集（1主2从） + 分片（2个，每个分片由1主1从1仲裁组成），一共12台主机：</p><table><thead><tr><th>主机编号</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>1</td><td>192.168.1.1</td><td>Mongos-1</td></tr><tr><td>2</td><td>192.168.1.2</td><td>Mongos-2</td></tr><tr><td>3</td><td>192.168.1.3</td><td>Mongos-3</td></tr><tr><td>4</td><td>192.168.1.11</td><td>Config-1</td></tr><tr><td>5</td><td>192.168.1.12</td><td>Config-2</td></tr><tr><td>6</td><td>192.168.1.13</td><td>Config-3</td></tr><tr><td>7</td><td>192.168.1.21</td><td>Shard1-Primary</td></tr><tr><td>8</td><td>192.168.1.22</td><td>Shard1-Secondary</td></tr><tr><td>9</td><td>192.168.1.23</td><td>Shard1-Arbiter</td></tr><tr><td>10</td><td>192.168.1.31</td><td>Shard2-Primary</td></tr><tr><td>11</td><td>192.168.1.32</td><td>Shard2-Secondary</td></tr><tr><td>12</td><td>192.168.1.33</td><td>Shard2-Arbiter</td></tr></tbody></table></li></ul><p><strong>注意：所有主机的hostname最好不要相同，以免影响mongos信息在config服务数据库中的存储。</strong></p><h2 id="三、分片集群搭建"><a href="#三、分片集群搭建" class="headerlink" title="三、分片集群搭建"></a>三、分片集群搭建</h2><h3 id="1、搭建步骤"><a href="#1、搭建步骤" class="headerlink" title="1、搭建步骤"></a>1、搭建步骤</h3><p>分片集群各组件搭建顺序如下，不能错：</p><ol><li>ConfigServer –&gt; 2.Shard集群 –&gt; 3.Mongos</li></ol><p><strong>启动顺序也是这样</strong></p><h3 id="2、所有主机预备操作"><a href="#2、所有主机预备操作" class="headerlink" title="2、所有主机预备操作"></a>2、所有主机预备操作</h3><h4 id="2-1、修改Linux主机能创建的文件数量限制"><a href="#2-1、修改Linux主机能创建的文件数量限制" class="headerlink" title="2.1、修改Linux主机能创建的文件数量限制"></a>2.1、修改Linux主机能创建的文件数量限制</h4><pre><code class="bash">echo &quot;ulimit -c unlimited&quot; &gt;&gt; /etc/profile &amp;&amp; source /etc/profilecat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF* soft nofile 262140* hard nofile 262140root soft nofile 262140root hard nofile 262140* soft core unlimited* hard core unlimitedroot soft core unlimitedroot hard core unlimitedEOFecho &quot;session  required  pam_limits.so&quot;&gt;&gt; /etc/pam.d/login</code></pre><h4 id="2-2、使用RPM包安装mongodb"><a href="#2-2、使用RPM包安装mongodb" class="headerlink" title="2.2、使用RPM包安装mongodb"></a>2.2、使用RPM包安装mongodb</h4><pre><code class="bash">rpm -ivh mongodb-org-server-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-tools-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-mongos-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-shell-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-3.2.1-1.el7.x86_64.rpm</code></pre><h4 id="2-3、修改监听IP"><a href="#2-3、修改监听IP" class="headerlink" title="2.3、修改监听IP"></a>2.3、修改监听IP</h4><pre><code class="bash">sed -i &quot;s/bindIp: 127.0.0.1/bindIp: 0.0.0.0/g&quot; /etc/mongod.conf</code></pre><h4 id="2-4、清空防火墙"><a href="#2-4、清空防火墙" class="headerlink" title="2.4、清空防火墙"></a>2.4、清空防火墙</h4><pre><code class="bash">iptables -Fsystemctl stop firewalldsystemctl disable firewalld</code></pre><p><strong>或者，在防火墙添加相应的放通策略，也可以</strong></p><h3 id="3、搭建Config-Server集群"><a href="#3、搭建Config-Server集群" class="headerlink" title="3、搭建Config-Server集群"></a>3、搭建Config-Server集群</h3><p>ConfigServer是一个副本集集群，一主两从，按照搭建副本集的方式搭建即可。</p><h4 id="3-1、修改Congfig-Server配置文件"><a href="#3-1、修改Congfig-Server配置文件" class="headerlink" title="3.1、修改Congfig-Server配置文件"></a>3.1、修改Congfig-Server配置文件</h4><p>三台主机配置相同，依次执行如下命令：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 2048  replSetName: mars-configsharding:  clusterRole: configsvrEOF</code></pre><p><strong>注意：集群角色必须是configsvr</strong></p><h4 id="3-2、启动Mongod"><a href="#3-2、启动Mongod" class="headerlink" title="3.2、启动Mongod"></a>3.2、启动Mongod</h4><p>三台主机依次启动mongod程序</p><pre><code class="bash">systemctl start mongod   </code></pre><h4 id="3-3、初始化config-server副本集"><a href="#3-3、初始化config-server副本集" class="headerlink" title="3.3、初始化config-server副本集"></a>3.3、初始化config-server副本集</h4><p>三台主机随便挑一台，敲<code>mongo</code>进入mongo shell，执行如下命令：</p><pre><code class="bash">rs.initiate( &#123;    _id: &quot;mars-config&quot;,    configsvr: true,    members: [        &#123; _id: 0, host: &quot;192.168.0.11:27017&quot;&#125;,        &#123; _id: 1, host: &quot;192.168.0.12:27017&quot;&#125;,        &#123; _id: 2, host: &quot;192.168.0.13:27017&quot;&#125;    ]&#125; )</code></pre><p><strong>注意：id为集群名称，configsvr为true。</strong></p><h4 id="3-4-验证"><a href="#3-4-验证" class="headerlink" title="3.4 验证"></a>3.4 验证</h4><pre><code class="bash">rs.status()</code></pre><h3 id="3、搭建Shard分片复制集集群"><a href="#3、搭建Shard分片复制集集群" class="headerlink" title="3、搭建Shard分片复制集集群"></a>3、搭建Shard分片复制集集群</h3><p>此处我们采用2个Shard分片，每个分片是一个主-从-仲裁的三节点复制集。两个分片配置过程一致。</p><h4 id="3-1、分片1"><a href="#3-1、分片1" class="headerlink" title="3.1、分片1"></a>3.1、分片1</h4><h5 id="3-1-1、修改配置文件"><a href="#3-1-1、修改配置文件" class="headerlink" title="3.1.1、修改配置文件"></a>3.1.1、修改配置文件</h5><p>三台主机配置相同，依次执行如下shell命令：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 2048  replSetName: mars-shard1sharding:  clusterRole: shardsvrEOF</code></pre><p><strong>注意：集群名字为shard1，要和分片2区分开。集群角色为shardsvr。</strong></p><h5 id="3-1-2、启动mongod"><a href="#3-1-2、启动mongod" class="headerlink" title="3.1.2、启动mongod"></a>3.1.2、启动mongod</h5><pre><code class="shell">systemctl start mongod</code></pre><h5 id="3-1-3、初始化Shard1副本集"><a href="#3-1-3、初始化Shard1副本集" class="headerlink" title="3.1.3、初始化Shard1副本集"></a>3.1.3、初始化Shard1副本集</h5><p>三台主机随便挑一台，敲<code>mongo</code>进入mongo shell，执行如下命令：</p><pre><code class="shell">rs.initiate( &#123;    _id: &quot;mars-shard1&quot;,    members: [        &#123; _id: 0, host: &quot;192.168.0.21:27017&quot;&#125;,        &#123; _id: 1, host: &quot;192.168.0.22:27017&quot;&#125;,        &#123; _id: 2, host: &quot;192.168.0.23:27017&quot;, arbiterOnly: true&#125;    ]&#125; )</code></pre><p><strong>注意：id为配置文件中的集群名称。</strong></p><h5 id="3-1-4、验证"><a href="#3-1-4、验证" class="headerlink" title="3.1.4、验证"></a>3.1.4、验证</h5><pre><code class="shell">rs.status()</code></pre><h4 id="3-2、分片2"><a href="#3-2、分片2" class="headerlink" title="3.2、分片2"></a>3.2、分片2</h4><h5 id="3-2-1、修改配置文件"><a href="#3-2-1、修改配置文件" class="headerlink" title="3.2.1、修改配置文件"></a>3.2.1、修改配置文件</h5><p>三台主机配置相同，依次执行如下shell命令：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 2048  replSetName: mars-shard2sharding:  clusterRole: shardsvrEOF</code></pre><p><strong>注意：集群名字为shard2，要和分片1区分开。集群角色为shardsvr。</strong></p><h5 id="3-2-2、启动mongod"><a href="#3-2-2、启动mongod" class="headerlink" title="3.2.2、启动mongod"></a>3.2.2、启动mongod</h5><pre><code class="shell">systemctl start mongod</code></pre><h5 id="3-2-3、初始化Shard1副本集"><a href="#3-2-3、初始化Shard1副本集" class="headerlink" title="3.2.3、初始化Shard1副本集"></a>3.2.3、初始化Shard1副本集</h5><p>三台主机随便挑一台，敲<code>mongo</code>进入mongo shell，执行如下命令：</p><pre><code class="shell">rs.initiate( &#123;    _id: &quot;mars-shard1&quot;,    members: [        &#123; _id: 0, host: &quot;192.168.0.31:27017&quot;&#125;,        &#123; _id: 1, host: &quot;192.168.0.32:27017&quot;&#125;,        &#123; _id: 2, host: &quot;192.168.0.33:27017&quot;, arbiterOnly: true&#125;    ]&#125; )</code></pre><p><strong>注意：id为配置文件中的集群名称。</strong></p><p><strong>我这里把第三台主机设为仲裁主机，是为了节省硬件资源，节约成本。如果不在乎这点成本，可以去掉上面arbiterOnly的配置。</strong></p><h5 id="3-2-4、验证"><a href="#3-2-4、验证" class="headerlink" title="3.2.4、验证"></a>3.2.4、验证</h5><pre><code class="shell">rs.status()</code></pre><h3 id="4、搭建mongos路由"><a href="#4、搭建mongos路由" class="headerlink" title="4、搭建mongos路由"></a>4、搭建mongos路由</h3><p>mongos可以为1个，也可以为多个，可以根据需要横向扩展，这里采用3个。</p><p><strong>mongos的主机名hostname必须要保持不同，如果相同，config的数据库中就只会保存一个mongos信息，从而造成active mongos数量永远是1。</strong></p><h4 id="4-1、修改配置文件"><a href="#4-1、修改配置文件" class="headerlink" title="4.1、修改配置文件"></a>4.1、修改配置文件</h4><p>mongos的配置文件为mongos.conf，如果不存在就采用如下方式新建，三台主机依次执行：</p><pre><code class="bash">cat &gt;&gt; /etc/mongos.conf &lt;&lt; EOFsystemLog:  destination: file  logAppend: true  path: /var/log/mongodb/mongod.log# how the process runsprocessManagement:  fork: true  # fork and run in background  pidFilePath: /var/run/mongodb/mongos.pid  # location of pidfile# network interfacesnet:  port: 27017sharding:  configDB: mars-config/192.168.0.11:27017, 192.168.0.12:27017, 192.168.0.13:27017EOF</code></pre><p><strong>注意：configDB为config-server集群的IP和端口，不要填错。</strong></p><h4 id="4-2、启动mongos"><a href="#4-2、启动mongos" class="headerlink" title="4.2、启动mongos"></a>4.2、启动mongos</h4><p>已mongod用户启动mongos，三台主机依次执行：</p><pre><code class="bash">sudo -u mongod mongos -f /etc/mongos.conf</code></pre><h4 id="4-3、添加分片"><a href="#4-3、添加分片" class="headerlink" title="4.3、添加分片"></a>4.3、添加分片</h4><p>连接任意一个mongos，在任意一台主机上执行<code>mongo</code>，添加分片信息：</p><pre><code class="bash">use adminsh.addShard(&quot;mars-shard1/192.168.0.21:27017,192.168.0.22:27017,192.168.0.23:27017&quot;)sh.addShard(&quot;mars-shard2/192.168.0.31:27017,192.168.0.32:27017,192.168.0.33:27017&quot;)</code></pre><h4 id="4-4、验证"><a href="#4-4、验证" class="headerlink" title="4.4、验证"></a>4.4、验证</h4><pre><code class="bash">sh.status()</code></pre><p><img src="https://img-blog.csdnimg.cn/201904161718322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW5iZWliZWk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>至此，一个基本的Shard分片集群已经搭建完毕。</strong></p><h3 id="5、使用分片"><a href="#5、使用分片" class="headerlink" title="5、使用分片"></a>5、使用分片</h3><p>使用分片的基本步骤是：1.开启数据库分片–&gt; 2.开启集合分片</p><p>对数据库分片是对集合分片的先决条件。</p><h4 id="5-1、开启数据库分片"><a href="#5-1、开启数据库分片" class="headerlink" title="5.1、开启数据库分片"></a>5.1、开启数据库分片</h4><p>以testdb数据库为例，在一台mongos上，进入mongoshell，执行：</p><pre><code class="shell">sh.enableSharding(&quot;testdb&quot;)</code></pre><h4 id="5-2、开始集合分片"><a href="#5-2、开始集合分片" class="headerlink" title="5.2、开始集合分片"></a>5.2、开始集合分片</h4><p>已testdb.coll1集合为例：</p><pre><code>sh.shardCollection(&quot;testdb.coll1&quot;, &#123;&quot;name&quot; : &quot;hashed&quot;&#125;)</code></pre><p>说明：</p><ul><li>第一个参数为集合的完整namespace名称，此例集合为testdb.coll1。</li><li>第二个参数为片键，指定根据哪个字段进行分片，此例对name字段进行hash分片。</li></ul><h4 id="5-3、插入数据验证分片"><a href="#5-3、插入数据验证分片" class="headerlink" title="5.3、插入数据验证分片"></a>5.3、插入数据验证分片</h4><p>插入测试数据</p><pre><code class="bash">use testdbfor (var i = 1; i &lt;= 100000; i++)&#123;  db.coll1.insert(&#123;&quot;id&quot; : i, &quot;name&quot; : &quot;name&quot; + i&#125;);&#125;</code></pre><p>验证是否分片</p><pre><code class="bash">sh.status()</code></pre><p><img src="https://img-blog.csdnimg.cn/20190416174828762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW5iZWliZWk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="6、添加集群认证"><a href="#6、添加集群认证" class="headerlink" title="6、添加集群认证"></a>6、添加集群认证</h3><p>上文已经成功创建一个分片集群，并验证数据分片可用。但在部署生产环境时，还需添加认证，用以保障集群安全性。<br>认证分两种：</p><ul><li><p>集群内部认证 (Internal Authentication)<br>用于集群内的各个组件(mongos, config server, shard)之间相互访问认证，也就是所有的mongos进程和mongod进程之间相互访问认证。<br>内部认证通过keyfile密钥文件实现，即所有的monogs/mongod公用同一个keyfile文件来相互认证。如果集群外随便来一个”mongod”进程，如果没有相同的keyfile，想加入集群，是不可能的。</p></li><li><p>外部用户访问集群所需的用户认证 (User Access Controls)<br>用于外部客户端访问mongos时，所需的用户认证。</p></li></ul><h4 id="6-1、生成并分发密钥文件Keyfile"><a href="#6-1、生成并分发密钥文件Keyfile" class="headerlink" title="6.1、生成并分发密钥文件Keyfile"></a>6.1、生成并分发密钥文件Keyfile</h4><p>在第一台主机上执行</p><pre><code class="bash">openssl rand -base64 756 &gt; /var/lib/mongo/keyFilechmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><p>其他所有主机复制第一台生成的keyFile文件(通过lszrz 或者 scp 或者 ftp)，并执行以下命令：</p><pre><code>cp keyFile /var/lib/mongo/chmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><h4 id="6-2、添加用户"><a href="#6-2、添加用户" class="headerlink" title="6.2、添加用户"></a>6.2、添加用户</h4><p>连接到任意一台mongos上，添加超级管理员用户：</p><pre><code class="bash">use admindb.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;xxx@1111&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;]&#125;)</code></pre><p>添加客户端用户：</p><pre><code class="bash">use test_dbdb.createUser(&#123;user: &quot;test_rw&quot;,pwd: &quot;xxx#111&quot;,roles: [&#123; role: &quot;dbOwner&quot;, db: &quot;test_db&quot;&#125;]&#125;)</code></pre><p>在”mongos”上添加用户，用户信息实际保存在”config server”上，”mongos”本身不存储任何数据，包括用户信息。</p><p>然而，”mongos”上创建的用户，是不会自动添加到”shard”分片服务器上的。<br>为了以后方便维护shard分片服务器，分别登录到每个分片服务器的”primary”节点，添加管理员用户：</p><pre><code class="bash">use admindb.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;xxx@1111&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;]&#125;)</code></pre><h4 id="6-3、开启认证"><a href="#6-3、开启认证" class="headerlink" title="6.3、开启认证"></a>6.3、开启认证</h4><h5 id="6-3-1、为所有mongod程序添加认证参数"><a href="#6-3-1、为所有mongod程序添加认证参数" class="headerlink" title="6.3.1、为所有mongod程序添加认证参数"></a>6.3.1、为所有mongod程序添加认证参数</h5><p>所有mongod程序包括，config-server主机3台，分片集群6台。</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFsecurity:  authorization: enabled  keyFile: /var/lib/mongo/keyFileEOF</code></pre><h5 id="6-3-2、为所有mongos程序添加认证参数"><a href="#6-3-2、为所有mongos程序添加认证参数" class="headerlink" title="6.3.2、为所有mongos程序添加认证参数"></a>6.3.2、为所有mongos程序添加认证参数</h5><p>在三台mongos主机上执行：</p><pre><code class="bash">cat &gt;&gt; /etc/mongos.conf &lt;&lt; EOFsecurity:  keyFile: /var/lib/mongo/keyFileEOF</code></pre><h5 id="6-3-3、停止集群内所有mongos和mongod程序"><a href="#6-3-3、停止集群内所有mongos和mongod程序" class="headerlink" title="6.3.3、停止集群内所有mongos和mongod程序"></a>6.3.3、停止集群内所有mongos和mongod程序</h5><p>mongos程序使用<code>kill -9 pid</code>停止，mongod程序使用<code>systemctl stop mongod</code>停止。</p><h5 id="6-3-4、按顺序启动所有程序"><a href="#6-3-4、按顺序启动所有程序" class="headerlink" title="6.3.4、按顺序启动所有程序"></a>6.3.4、按顺序启动所有程序</h5><ol><li>config-server -&gt; 2. shard集群 -&gt; 3. mongos</li></ol><h5 id="6-3-5、验证用户访问"><a href="#6-3-5、验证用户访问" class="headerlink" title="6.3.5、验证用户访问"></a>6.3.5、验证用户访问</h5><p>通过连接任意一个mongos，验证管理员用户和客户端用户的访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、架构&quot;&gt;&lt;a href=&quot;#一、架构&quot; class=&quot;headerlink&quot; title=&quot;一、架构&quot;&gt;&lt;/a&gt;一、架构&lt;/h2&gt;&lt;h3 id=&quot;1、Mongodb分片集群配置&quot;&gt;&lt;a href=&quot;#1、Mongodb分片集群配置&quot; class=&quot;header</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb复制集集群搭建</title>
    <link href="https://www.langxw.com/2021/03/03/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://www.langxw.com/2021/03/03/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2021-03-03T11:37:16.000Z</published>
    <updated>2021-03-16T12:12:07.733Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、环境说明"><a href="#一、环境说明" class="headerlink" title="一、环境说明"></a>一、环境说明</h2><ol><li><p>操作系统：Centos7.6</p></li><li><p>Mongodb 3.2.1 的rpm包</p><pre><code class="bash">mongodb-org-server-3.2.1-1.el7.x86_64.rpmmongodb-org-tools-3.2.1-1.el7.x86_64.rpmmongodb-org-mongos-3.2.1-1.el7.x86_64.rpmmongodb-org-shell-3.2.1-1.el7.x86_64.rpmmongodb-org-3.2.1-1.el7.x86_64.rpm</code></pre></li><li><p>集群模式：Replica Set，一个主节点两个从节点，没有仲裁节点</p><table><thead><tr><th>节点</th><th>IP</th></tr></thead><tbody><tr><td>primary</td><td>172.16.20.29</td></tr><tr><td>secondary</td><td>172.16.20.30</td></tr><tr><td>secondary</td><td>172.16.20.31</td></tr></tbody></table><h2 id="二、离线安装"><a href="#二、离线安装" class="headerlink" title="二、离线安装"></a>二、离线安装</h2><h3 id="1、关闭防火墙"><a href="#1、关闭防火墙" class="headerlink" title="1、关闭防火墙"></a>1、关闭防火墙</h3><p>关闭三台机器的防火墙：</p><pre><code class="bash">systemctl stop firewalld.servicesystemctl disable firewalld.service</code></pre><p>注意：如果后面端口还是不通，可以考虑是否是Selinux的影响。</p><h3 id="2、离线安装mongodb"><a href="#2、离线安装mongodb" class="headerlink" title="2、离线安装mongodb"></a>2、离线安装mongodb</h3><p>在三台机器上依次执行安装mongodb的脚本：<code>bash mongo_install.sh</code></p><p>具体脚本信息如下：</p><pre><code class="bash">#!/bin/bashrpm -ivh mongodb-org-server-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-tools-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-mongos-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-shell-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-3.2.1-1.el7.x86_64.rpmsystemctl start mongodEXCODE=$?if [ &quot;$EXCODE&quot; == &quot;0&quot; ]; then    echo &#39;-------------------------------------&#39;    echo &#39;Mongo install Sucess!&#39;    echo &#39;-------------------------------------&#39;fisystemctl status mongod</code></pre><p><strong>注意：因我司机房环境特殊，无法连通外网，故使用rpm包形式进行安装。同时也解决了tar包启动中要创建用户、注册为服务、设置开机启动的繁琐事项。如果可以访问外网，也可以使用yum在线安装。</strong></p></li></ol><h2 id="三、集群配置"><a href="#三、集群配置" class="headerlink" title="三、集群配置"></a>三、集群配置</h2><h3 id="1、生成密钥文件"><a href="#1、生成密钥文件" class="headerlink" title="1、生成密钥文件"></a>1、生成密钥文件</h3><p>第一台主机上执行：</p><pre><code class="bash">openssl rand -base64 756 &gt; /var/lib/mongo/keyFilechmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><p>其他两台主机复制第一台生成的keyFile文件(通过lszrz 或者 scp 或者 ftp)，并执行以下命令：</p><pre><code class="bash">cp keyFile /var/lib/mongo/chmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><h3 id="2、修改监听，配置集群名称"><a href="#2、修改监听，配置集群名称" class="headerlink" title="2、修改监听，配置集群名称"></a>2、修改监听，配置集群名称</h3><p><strong>三台机器依次做如下操作</strong></p><h4 id="1）修改监听："><a href="#1）修改监听：" class="headerlink" title="1）修改监听："></a>1）修改监听：</h4><p><code>sed -i &quot;s/bindIp: 127.0.0.1/bindIp: 0.0.0.0/g&quot; /etc/mongod.conf </code></p><h4 id="2）配置集群名称："><a href="#2）配置集群名称：" class="headerlink" title="2）配置集群名称："></a>2）配置集群名称：</h4><pre><code class="bassh">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 1024   replSetName: marsEOF</code></pre><p><strong>右上角bash复制代码存在bug，会去除缩进。请尽量使用鼠标右键复制。</strong></p><h4 id="3）重启"><a href="#3）重启" class="headerlink" title="3）重启"></a>3）重启</h4><p>三台机器依次重启服务：</p><p><code>systemctl restart mongod</code></p><h3 id="3、初始化集群"><a href="#3、初始化集群" class="headerlink" title="3、初始化集群"></a>3、初始化集群</h3><p>在第一台主机上，执行<code>mongo</code>命令，进入mongo shell：</p><pre><code class="bash">use admin# 设置集群配置（根据具体情况修改IP和端口）config = &#123;_id:&quot;mars&quot;,members:[&#123;_id:0,host:&#39;172.16.20.29:27017&#39;,priority :100&#125;,&#123;_id:1,host:&#39;172.16.20.30:27017&#39;,priority:100&#125;,&#123;_id:2,host:&#39;172.16.20.31:27017&#39;,priority:100&#125;]&#125;# 初始化集群rs.initiate(config)# 查看集群状态rs.status()</code></pre><h2 id="二、认证配置"><a href="#二、认证配置" class="headerlink" title="二、认证配置"></a>二、认证配置</h2><h3 id="1、创建用户"><a href="#1、创建用户" class="headerlink" title="1、创建用户"></a>1、创建用户</h3><p><strong>在第一台机器上</strong></p><p>在mongo shell中输入：</p><p><strong>创建管理员账户：</strong></p><p><code>db.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;xxxxxx&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;]&#125;)</code></p><p><strong>创建客户端账户:</strong></p><p><code>db.createUser(&#123;user: &quot;用于客户端用户名&quot;,pwd: &quot;用于客户端密码&quot;,roles: [ &quot;readWriteAnyDatabase&quot;]&#125;)</code></p><p><strong>退出mongo shell：</strong><code>exit</code></p><h3 id="2、开启认证"><a href="#2、开启认证" class="headerlink" title="2、开启认证"></a>2、开启认证</h3><p><strong>在所有三台机器上</strong></p><p>在shell终端中输入：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFsecurity:  authorization: enabled  keyFile: /var/lib/mongo/keyFileEOF</code></pre><h3 id="3、重启"><a href="#3、重启" class="headerlink" title="3、重启"></a>3、重启</h3><p>全部三个几点，一次重启</p><p><code>systemctl restart mongod</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、环境说明&quot;&gt;&lt;a href=&quot;#一、环境说明&quot; class=&quot;headerlink&quot; title=&quot;一、环境说明&quot;&gt;&lt;/a&gt;一、环境说明&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;操作系统：Centos7.6&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mongodb 3.2.1</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>ss免费账号</title>
    <link href="https://www.langxw.com/2021/02/22/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/"/>
    <id>https://www.langxw.com/2021/02/22/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/</id>
    <published>2021-02-22T07:38:35.000Z</published>
    <updated>2021-03-16T11:58:37.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、免费账号"><a href="#一、免费账号" class="headerlink" title="一、免费账号"></a>一、免费账号</h2><p><a href="https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7">免费账号连接：https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7</a></p><p><strong>账号可能会失效，失效后请到以上页面获取新的账号。</strong></p><h2 id="二、自由上网"><a href="#二、自由上网" class="headerlink" title="二、自由上网"></a>二、自由上网</h2><p><a href="https://github.com/Alvin9999/new-pac/wiki">自由上网：https://github.com/Alvin9999/new-pac/wiki</a></p><h2 id="三、注意事项"><a href="#三、注意事项" class="headerlink" title="三、注意事项"></a>三、注意事项</h2><ol><li>本资源仅供用于学习和交流,请遵循相关法律法规,本资源不代表本站立场,并禁止以下行为</li><li>不得使用 BT，eMule，迅雷，FlashGet，Tor 等 P2P 工具下载非法和国家禁止的互联网信息内容</li><li>不得用于“注册机/发贴机/垃圾邮件/群发外链/黑帽SEO/网络攻击/网络诈骗”等用途</li><li>不得下载或传播侵犯知识产权相关内容</li><li>不得发布任何非法、威胁、诽谤、反动、淫秽、色情信息或其它违法信息</li><li>不得利用本系统可能存在漏洞以各种形式为自己及他人牟利</li><li>不散布电子邮件广告、垃圾邮件（SPAM）：不利用本平台提供的服务散发大量不受欢迎的或者未经请求的电子邮件、电子广告或包含反动、色情等有害信息的电子邮件</li><li>不利用本平台提供的服务上传、下载、发布如下信息或者内容，不为他人发布该等信息提供任何便利</li><li>违反国家规定的政治宣传或新闻信息</li><li>涉及国家秘密或安全的信息</li><li>封建迷信或淫秽、色情、下流的信息或教唆犯罪的信息</li><li>违反国家民族和宗教政策的信息</li><li>妨碍互联网运行安全的信息</li><li>侵害他人合法权益的信息或其他有损于社会秩序、社会治安、公共道德的信息或内容</li><li>其他违反法律法规、部门规章或国家政策的内容</li><li>不进行任何破坏或试图破坏网络安全的行为（包括钓鱼，黑客，网络诈骗等）</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、免费账号&quot;&gt;&lt;a href=&quot;#一、免费账号&quot; class=&quot;headerlink&quot; title=&quot;一、免费账号&quot;&gt;&lt;/a&gt;一、免费账号&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/Alvin9999/new-pac/wiki/ss%</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="翻墙" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/%E7%BF%BB%E5%A2%99/"/>
    
    
    <category term="shadowsocks" scheme="https://www.langxw.com/tags/shadowsocks/"/>
    
  </entry>
  
  <entry>
    <title>DockerHub加速</title>
    <link href="https://www.langxw.com/2021/02/02/DockerHub%E5%8A%A0%E9%80%9F/"/>
    <id>https://www.langxw.com/2021/02/02/DockerHub%E5%8A%A0%E9%80%9F/</id>
    <published>2021-02-02T02:34:29.000Z</published>
    <updated>2021-02-02T02:35:58.143Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p>　　今天学习Flask，书上建议用Docker，那我就安装了DockerToolBox（WIN10系统只能用toolbox）。其中从docker hub拉取ubuntu镜像时</p><p>docker pull xxxx，网速简直是龟速。想到中国的长城防火墙，再想到毕竟是国外的网站，瞬间心灰意冷，想诅骂作者搞了个那么大个镜像在Docker Hub。</p><p>　　按以往的经验，对于国外网站或者源，我们都喜欢更换国内源、使用代理VPN、使用加速器，来解决访问不了或者访问慢的问题。</p><p><strong>环境：WIN 10  ；Docker 17</strong></p><h2 id="二、解决办法："><a href="#二、解决办法：" class="headerlink" title="二、解决办法："></a>二、解决办法：</h2><p>　　<strong>Docker加速器 DaoCloud</strong></p><p>　　DaoCloud 加速器 是广受欢迎的 Docker 工具，解决了国内用户访问 Docker Hub 缓慢的问题。DaoCloud 加速器结合国内的 CDN 服务与协议层优化，成倍的提升了下载速度。</p><p>　　<a href="https://www.daocloud.io/">https://www.daocloud.io/</a> 注册并登陆，在dashboard右上角有一个火箭图标，他就是加速器。点开后获得加速地址：<a href="http://xxxx.m.daocloud.io.(请注意自己的宿主机操作系统,不要选错加速地址)/">http://xxxx.m.daocloud.io。（请注意自己的宿主机操作系统，不要选错加速地址）</a></p><p>　　下面就是将加速地址加入docker的配置文件里，重启docker即可。</p><p>　　我用的是Docker Toolbox，启动Docker Quickstart Terminal，然后按如下步骤操作：</p><pre><code class="bash">docker-machine ssh defaultsudo sed -i &quot;s|EXTRA_ARGS=&#39;|EXTRA_ARGS=&#39;--registry-mirror=加速地址 |g&quot; /var/lib/boot2docker/profileexitdocker-machine restart default </code></pre><p>之后就可以飞速的下载Docker镜像了，O(∩_∩)O哈哈~。</p><p>　　不同的操作系统，不同的docker版本，使用docker加速器配置方法不同，具体请参考官方文档。</p><p>　　<strong>或者使用，阿里云加速器</strong></p><h2 id="三、附件："><a href="#三、附件：" class="headerlink" title="三、附件："></a>三、附件：</h2><p>1、<a href="http://guide.daocloud.io/dcs/daocloud-9153151.html">Docker 加速器官方文档</a></p><p>2、Docker加速器简介：</p><p>Docker加速器是 DaoCloud 推出的 Docker Hub Mirror 服务的官方名称。</p><p>Docker加速器提供Docker Registry（Docker Hub）在中国的镜像代理服务，为中国用户在国内服务器上缓存诸多镜像。</p><p>当用户的Docker设定了–registry-mirror参数后，用户的Docker拉取镜像时，首先去Docker加速器中查找镜像，若命中则说明该镜像已经在Docker加速器中缓存，用户直接从Docker加速器中下载。</p><p>若没有命中，则说该镜像还没有被缓存，那么Docker加速器首先会被驱使去Docker Hub中下载该镜像，并进行缓存，最终让用户从Docker加速器中下载该镜像。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;　　今天学习Flask，书上建议用Docker，那我就安装了DockerToolBox（WIN10系统只能用tool</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="加速器" scheme="https://www.langxw.com/tags/%E5%8A%A0%E9%80%9F%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker修改默认时区</title>
    <link href="https://www.langxw.com/2021/02/02/Docker%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E6%97%B6%E5%8C%BA/"/>
    <id>https://www.langxw.com/2021/02/02/Docker%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E6%97%B6%E5%8C%BA/</id>
    <published>2021-02-02T02:32:07.000Z</published>
    <updated>2021-02-02T02:43:52.169Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p><strong>Docker Hub中的镜像默认都是0时区，而我们在东八区，差8小时，会导致我们看日志不能准确定位时间，这是很要命的。</strong></p><h2 id="二、解决办法："><a href="#二、解决办法：" class="headerlink" title="二、解决办法："></a>二、解决办法：</h2><h3 id="1、环境变量方式："><a href="#1、环境变量方式：" class="headerlink" title="1、环境变量方式："></a>1、环境变量方式：</h3><ol><li><p>docker run 启动时加入环境变量：<code>docker run -e &quot;TZ=Asia/Shanghai&quot;</code></p></li><li><p>docker-compose 方式启动时，加入 </p><pre><code class="bash">environment: - TZ=Asia/Shanghai</code></pre><h3 id="2、重新制作镜像方式："><a href="#2、重新制作镜像方式：" class="headerlink" title="2、重新制作镜像方式："></a>2、重新制作镜像方式：</h3></li></ol><p>如果你是基于某个官方Image来制作自己的镜像，比如Alpine。那么你可以在Dockerfile中，加入:</p><pre><code class="bash">RUN apk --no-cache add tzdata  &amp;&amp; \  ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \  echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Docker Hub中的镜像默认都是0时区，而我们在东八区，差8小时，会导致我们看日志不能准确定位时</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="timezone" scheme="https://www.langxw.com/tags/timezone/"/>
    
  </entry>
  
  <entry>
    <title>ELK-Docker化安装</title>
    <link href="https://www.langxw.com/2021/02/02/ELK-Docker%E5%8C%96%E5%AE%89%E8%A3%85/"/>
    <id>https://www.langxw.com/2021/02/02/ELK-Docker%E5%8C%96%E5%AE%89%E8%A3%85/</id>
    <published>2021-02-02T02:28:20.000Z</published>
    <updated>2021-02-02T02:31:38.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、环境："><a href="#一、环境：" class="headerlink" title="一、环境："></a>一、环境：</h2><p><strong>Ubuntu18.04 + Docker 18.09 + ELK Docker Image 7.1</strong> </p><h2 id="二、安装部署："><a href="#二、安装部署：" class="headerlink" title="二、安装部署："></a>二、安装部署：</h2><h3 id="1、Docker"><a href="#1、Docker" class="headerlink" title="1、Docker"></a>1、Docker</h3><pre><code class="bash">curl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.shsudo usermod -aG docker $(whoami)sudo systemctl start dockersudo systemctl status docker</code></pre><h3 id="2、Elasticsearch"><a href="#2、Elasticsearch" class="headerlink" title="2、Elasticsearch"></a>2、Elasticsearch</h3><pre><code class="bash">docker pull docker.elastic.co/elasticsearch/elasticsearch:7.1.0sudo apt install docker-composesudo bash -c &quot;echo &#39;vm.max_map_count=262144&#39; &gt;&gt; /etc/sysctl.conf&quot;sudo sysctl -psudo mkdir -p /data/elasticsearch/datasudo vim docker-compose.ymlsudo chown -R yimi.yimi  elasticsearch/sudo docker-compose up -ddocker ps -acurl http://127.0.0.1:9200/_cat/healthdocker-compose down -v</code></pre><h3 id="3、Kibana"><a href="#3、Kibana" class="headerlink" title="3、Kibana"></a>3、Kibana</h3><pre><code class="bash">docker pull docker.elastic.co/kibana/kibana:7.1.0sudo mkdir /data/kibanasudo vim docker-compose.ymlsudo docker-compose  up -ddocker logs kibana </code></pre><h3 id="4、Logstash"><a href="#4、Logstash" class="headerlink" title="4、Logstash"></a>4、Logstash</h3><pre><code>docker pull docker.elastic.co/logstash/logstash:7.1.0docker run -it --rm docker.elastic.co/logstash/logstash:7.1.0 -e &#39;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125; &#125;&#39;sudo mkdir /data/logstash/sudo chown -R yimi.yimi logstash/docker run -d -p 5044:5044 --name logstash --network elasticsearch_esnet \-v /data/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \-v /data/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml \docker.elastic.co/logstash/logstash:7.1.0</code></pre><h3 id="5、Filebeat"><a href="#5、Filebeat" class="headerlink" title="5、Filebeat"></a>5、Filebeat</h3><h4 id="1）非Docker模式："><a href="#1）非Docker模式：" class="headerlink" title="1）非Docker模式："></a>1）非Docker模式：</h4><pre><code class="bash"># 1.edit config with logstash # 2.Index setup filebeat setup --template -E output.logstash.enabled=false -E &#39;output.elasticsearch.hosts=[&quot;http://10.15.1.27:9200&quot;]&#39;# 3.kibana setupfilebeat setup -e \  -E output.logstash.enabled=false \  -E output.elasticsearch.hosts=[&#39;http://10.15.1.27:9200&#39;] \  -E setup.kibana.host=http://10.15.1.27:5601  # 4.startup filebeat:sudo service filebeat start</code></pre><p>####2）Docker模式：</p><pre><code class="bash">docker run \docker.elastic.co/beats/filebeat:7.1.1 \setup -E setup.kibana.host=kibana:5601 \-E output.elasticsearch.hosts=[&quot;elasticsearch:9200&quot;]docker run docker.elastic.co/beats/filebeat:7.1.1 setup \--network elasticsearch_esnet --template -E output.logstash.enabled=false \-E &#39;output.elasticsearch.hosts=[&quot;es01:9200&quot;]&#39;docker run --net=&quot;host&quot; docker.elastic.co/beats/filebeat:7.1.1 setup -e \  -E output.logstash.enabled=false \  -E output.elasticsearch.hosts=[&#39;localhost:9200&#39;] \  -E output.elasticsearch.username=filebeat_internal \  -E output.elasticsearch.password=YOUR_PASSWORD \  -E setup.kibana.host=localhost:5601</code></pre><h3 id="6、X-PACK"><a href="#6、X-PACK" class="headerlink" title="6、X-PACK"></a>6、X-PACK</h3><p>x-pack是elasticsearch的一个扩展包，将安全，警告，监视，图形和报告功能捆绑在一个易于安装的软件包中。 </p><p>因为x-pack是收费的，所以试用期只有一个月。长期使用就必须根据官网文档说得来，也是给我们后门，一年一年的续期。</p><p><strong>如果要认证，建议用Nginx做反向代理+认证</strong></p><h2 id="三、ELK-使用步骤："><a href="#三、ELK-使用步骤：" class="headerlink" title="三、ELK 使用步骤："></a>三、ELK 使用步骤：</h2><p>Spring Boot 日志输出到指定目录，Filebeat 进行采集，Logstash 进行过滤，Elasticsearch 进行存储，Kibana 进行展示。</p><p>Filebeat 示例配置（<code>vi /etc/filebeat/filebeat.yml</code>）：</p><pre><code class="yaml">filebeat.prospectors:- input_type: log  paths:    - /var/log/spring-boot-log4j2/*.log  document_type: &quot;spring-boot-log4j2&quot; # 定义写入 ES 时的 _type 值  multiline:    #pattern: &#39;^\s*(\d&#123;4&#125;|\d&#123;2&#125;)\-(\d&#123;2&#125;|[a-zA-Z]&#123;3&#125;)\-(\d&#123;2&#125;|\d&#123;4&#125;)&#39;   # 指定匹配的表达式（匹配以 2017-11-15 08:04:23:889 时间格式开头的字符串）    pattern: &#39;^\s*(&quot;&#123;)&#39;                         # 指定匹配的表达式（匹配以 &quot;&#123; 开头的字符串）    negate: true                                # 是否匹配到    match: after                                # 合并到上一行的末尾    max_lines: 1000                             # 最大的行数    timeout: 30s                                # 如果在规定的时候没有新的日志事件就不等待后面的日志  fields:    logsource: node1    logtype: spring-boot-log4j2- input_type: log  paths:    - /var/log/messages    #- /var/log/*.log  document_type: &quot;syslog&quot; # 定义写入 ES 时的 _type 值  fields:    logsource: node1    logtype: syslog#output.elasticsearch:  #hosts: [&quot;node1:9200&quot;]output.logstash:  hosts: [&quot;node1:10515&quot;]</code></pre><p>上面的配置需要注意几点：</p><ul><li><code>pattern</code>：配置的正则表达式，是为了合并异常信息（而不是单行显示），匹配以<code>&quot;&#123;</code>开头的字符串（判断是否 Json 格式），如果匹配不到的话，就进行合并行。</li><li><code>document_type</code>：配置的是 Elasticsearch 的 Type 值，方便 Elasticsearch 对日志数据的归类。</li><li><code>logtype</code>：新增的字段，用于 Filebeat 和 Logstash 之间传递参数，进行过滤的判断逻辑。</li></ul><p>Logstash 示例配置（<code>vi /etc/logstash/conf.d/logstash.conf</code>）：</p><pre><code class="yaml">input &#123; beats &#123;   port =&gt; 10515  &#125;&#125;filter &#123;  if [fields][logtype] == &quot;syslog&quot; &#123;    grok &#123;      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;&quot;       add_field =&gt; [ &quot;received_at&quot;, &quot;%&#123;@timestamp&#125;&quot; ]      add_field =&gt; [ &quot;received_from&quot;, &quot;%&#123;host&#125;&quot; ]    &#125;    syslog_pri &#123; &#125;    date &#123;      match =&gt; [ &quot;syslog_timestamp&quot;, &quot;MMM  d HH:mm:ss&quot;, &quot;MMM dd HH:mm:ss&quot; ]    &#125;  &#125;  if [fields][logtype] == &quot;spring-boot-log4j2&quot; &#123;    json &#123;      source =&gt; &quot;message&quot;      target =&gt; &quot;data&quot;    &#125;  &#125;&#125;output &#123;  if [fields][logtype] == &quot;spring-boot-log4j2&quot;&#123;    elasticsearch &#123;      hosts =&gt; [&quot;127.0.0.1:9200&quot;]      index =&gt; &quot;spring-boot-log4j2-%&#123;+YYYY.MM.dd&#125;&quot;    &#125;  &#125;    if [fields][logtype] == &quot;syslog&quot;&#123;    elasticsearch &#123;      hosts =&gt; [&quot;127.0.0.1:9200&quot;]      index =&gt; &quot;filebeat-%&#123;+YYYY.MM.dd&#125;&quot;    &#125;  &#125;&#125;</code></pre><p>上面的配置需要注意几点：</p><ul><li>logstash.conf：配置文件可以配置多个，<code>input</code>、<code>filter</code>和<code>output</code>可以单独文件配置。</li><li>fields logtype：就是上面 Filebeat 配置的字段，这边用来判断服务来源，然后进行单独的处理。</li><li>filter：过滤器做了两件事，一个是使用<code>grok</code>插件，匹配数据和增加字段值，另一个就是使用<code>json</code>插件，将字符串转换成 Json 对象（会创建<code>data</code>层级结构，如果不想新建层级的话，删掉<code>target</code>配置即可）。</li><li>output：根据<code>logtype</code>判断，输出到指定的 Elasticsearch 地址，以及创建指定的索引。</li></ul><p>简单总结下， Filebeat 是客户端，一般部署在 Service 所在服务器（有多少服务器，就有多少 Filebeat），不同 Service 配置不同的<code>input_type</code>（也可以配置一个），采集的数据源可以配置多个，然后 Filebeat 将采集的日志数据，传输到指定的 Logstash 进行过滤，最后将处理好的日志数据，存储到指定的 Elasticsearch。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、环境：&quot;&gt;&lt;a href=&quot;#一、环境：&quot; class=&quot;headerlink&quot; title=&quot;一、环境：&quot;&gt;&lt;/a&gt;一、环境：&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Ubuntu18.04 + Docker 18.09 + ELK Docker Image 7.1&lt;</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/ELK/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ELK自定义索引配置</title>
    <link href="https://www.langxw.com/2021/02/02/ELK%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B4%A2%E5%BC%95%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.langxw.com/2021/02/02/ELK%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B4%A2%E5%BC%95%E9%85%8D%E7%BD%AE/</id>
    <published>2021-02-02T02:26:17.000Z</published>
    <updated>2021-02-02T02:27:57.429Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p>ELK中，如果是你使用Logstash做日志收集Agent，那么默认索引为logstash-<em>；如果你使用Filebeat做日志收集Agent，那么默认索引为filebeat-</em> 。</p><p>默认的索引，不利于我们区分不同的应用日志，所以要自定义索引和应用一一对应，这样才能更清晰快速的检索日志。</p><p><strong>环境：Ubuntu18 + ELK 7.1.0 + Docker， 采用 Filebeat –&gt; Logstash –&gt; Elasticsearch –&gt; Kibana</strong></p><h2 id="二、架构分析："><a href="#二、架构分析：" class="headerlink" title="二、架构分析："></a>二、架构分析：</h2><p>目前知道的架构方式有三种：</p><ol><li>Logstash –&gt; Elasticsearch –&gt; Kibana     弃用</li><li><strong>Filebeat –&gt;  Elasticsearch –&gt; Kibana</strong>       简单需求使用</li><li><strong>Filebeat –&gt; Logstash –&gt; Elasticsearch –&gt; Kibana</strong>    复杂需求使用</li></ol><p>由于Filebeat和Logstash相比，更轻量更节省资源，对采集日志的机器负担最小，Agent目前普遍才用Filebeat（Beat等）。</p><p>故以上第一种架构方式基本被舍弃，如果应用少、采集日志需求简单，直接使用第二种方式；如果应用日志多、需求复杂，则要使用第三种方式。</p><h2 id="三、解决办法："><a href="#三、解决办法：" class="headerlink" title="三、解决办法："></a>三、解决办法：</h2><p>不同的架构方式，自定义配置索引的方式不同。</p><h3 id="1、Filebeat-output-到ES（待验证）："><a href="#1、Filebeat-output-到ES（待验证）：" class="headerlink" title="1、Filebeat output 到ES（待验证）："></a>1、Filebeat output 到ES（待验证）：</h3><p>修改filebeat.yml配置文件</p><pre><code class="yml"># 配置输入filebeat.inputs:- type: log  enabled: true  paths:    - /home/wwwlogs/access.log  json.keys_under_root: true  json.add_error_key: true  fields:    source: &#39;nginx-access&#39;- type: log  enabled: true  paths:    - /home/wwwlogs/kibana.log  json.keys_under_root: true  json.add_error_key: true  fields:    source: &#39;kibana-access&#39;# 配置输出output.elasticsearch:  hosts: [&quot;192.168.0.4:9200&quot;]  indices:    - index: &quot;%&#123;[fields.source]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;      when.contains:        fields.source: &quot;nginx-access&quot;    - index: &quot;%&#123;[fields.source]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;      when.contains:        fields.source: &quot;kibana-access&quot;</code></pre><p>主要是在input那里配置自定义字段fields.source，然后再output es那里使用indices+when，即实现自定义索引。</p><h3 id="2、Filebeat-output-到Logstash（已验证）："><a href="#2、Filebeat-output-到Logstash（已验证）：" class="headerlink" title="2、Filebeat output 到Logstash（已验证）："></a>2、Filebeat output 到Logstash（已验证）：</h3><p>这一个需要filebeat和logstash的配合，索引的自定义在logstash的output完成。</p><h4 id="1）修改filebet的配置"><a href="#1）修改filebet的配置" class="headerlink" title="1）修改filebet的配置"></a>1）修改filebet的配置</h4><p><code>vim filebeat.yml</code></p><pre><code class="yml"># 配置输入filebeat.inputs:- type: log  enabled: true  paths:    - /data/logs/ca/ca.log  fields:    type: &quot;ca&quot;- type: log  enabled: true  paths:    - /data/logs/ws-fund/ws-fund.log  fields:    type: &quot;ws-fund&quot;# 配置输出output.logstash:  hosts: [&quot;192.168.0.4:5044&quot;]</code></pre><h4 id="2）-修改logstash配置"><a href="#2）-修改logstash配置" class="headerlink" title="2） 修改logstash配置"></a>2） 修改logstash配置</h4><p><code>vim logstash.conf</code></p><pre><code class="bash"># 配置输入input &#123;  beats &#123;    port =&gt; 5044  &#125;&#125;# 配置输出output &#123;    if [fields][type] == &quot;ws-fund&quot;&#123;      elasticsearch &#123;        hosts =&gt; [&quot;http://es01:9200&quot;]        index =&gt; &quot;ws-fund-%&#123;+YYYY.MM.dd&#125;&quot;      &#125;    &#125;else if [fields][type] == &quot;ca&quot;&#123;      elasticsearch &#123;        hosts =&gt; [&quot;http://es01:9200&quot;]        index =&gt; &quot;ca-%&#123;+YYYY.MM.dd&#125;&quot;      &#125;    &#125;else &#123;      elasticsearch &#123;        hosts =&gt; [&quot;http://es01:9200&quot;]        index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;      &#125;    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;ELK中，如果是你使用Logstash做日志收集Agent，那么默认索引为logstash-&lt;em&gt;；如果你使用Fi</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/ELK/"/>
    
    
    <category term="ELK" scheme="https://www.langxw.com/tags/ELK/"/>
    
    <category term="index" scheme="https://www.langxw.com/tags/index/"/>
    
    <category term="log" scheme="https://www.langxw.com/tags/log/"/>
    
  </entry>
  
  <entry>
    <title>Filebeat合并多行日志</title>
    <link href="https://www.langxw.com/2021/02/02/Filebeat%E5%90%88%E5%B9%B6%E5%A4%9A%E8%A1%8C%E6%97%A5%E5%BF%97/"/>
    <id>https://www.langxw.com/2021/02/02/Filebeat%E5%90%88%E5%B9%B6%E5%A4%9A%E8%A1%8C%E6%97%A5%E5%BF%97/</id>
    <published>2021-02-02T02:23:55.000Z</published>
    <updated>2021-02-02T02:25:55.605Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、配置解释："><a href="#一、配置解释：" class="headerlink" title="一、配置解释："></a>一、配置解释：</h2><p>在filebeat.yml的filebeat.inputs中，有关于多行日志合并的配置：</p><pre><code class="yaml">multiline.pattern # 指定正则表达式去匹配指定的行，例如multiline.pattern: &#39;^\[&#39;，意思是去匹配以[开头的行multiline.negate # 定义pattern是否被否认，默认值是false，若为true，意思是对上面的匹配进行反转(就是实际去匹配不以pattern的行)multiline.match # 指定Filebeat如何合并匹配的行，有两个值after和before# 如果negate设置为false，match设置为after，Filebeat就会把不匹配的行作为行首，把匹配的行插入到行首后。# 如果negate设置为true，match设置为after，Filebeat就会把匹配的行作为行首，把不匹配的行插入到行首后。multiline.flush_pattern # 指定正则表达式去匹配指定的行作为multline-message的结束，刷新的内存，开始匹配新的多行multiline.max_lines # 指定合并最大行数multiline.timeout  # 设定一个超时时间，在时间结束后，即使没有匹配到新pattern来启动新事件，Filebeat也会发送多行事件。默认值是5秒</code></pre><h2 id="二、我司示例："><a href="#二、我司示例：" class="headerlink" title="二、我司示例："></a>二、我司示例：</h2><p>观察到我司日志每一条都是以时间日期开头，后面日志内容会有换行，行首还有空格，还会有java堆栈报错，经实践采用以下配置：</p><pre><code class="shell">  multiline.pattern: &#39;^\[[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&#39;  multiline.negate: true  multiline.match: after</code></pre><p>上面配置的意思是：不以时间格式（[2019-06-06）开头的行都合并到上一行的末尾。</p><p>注意：<strong>日志格式要统一</strong></p><h2 id="三、其他示例："><a href="#三、其他示例：" class="headerlink" title="三、其他示例："></a>三、其他示例：</h2><p>来自官方文档翻译：</p><h3 id="1、Java堆栈跟踪"><a href="#1、Java堆栈跟踪" class="headerlink" title="1、Java堆栈跟踪"></a>1、Java堆栈跟踪</h3><h4 id="1）Java示例一"><a href="#1）Java示例一" class="headerlink" title="1）Java示例一"></a>1）Java示例一</h4><p>Java堆栈跟踪由多行组成，每一行在初始行之后以空格开头，如本例中所述:</p><pre><code>Exception in thread &quot;main&quot; java.lang.NullPointerException        at com.example.myproject.Book.getTitle(Book.java:16)        at com.example.myproject.Author.getBookTitles(Author.java:25)        at com.example.myproject.Bootstrap.main(Bootstrap.java:14)</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;^[[:space:]]&#39;multiline.negate: falsemultiline.match: after</code></pre><p>此配置将以空格开头的所有行合并到上一行。</p><h4 id="2）Java示例二"><a href="#2）Java示例二" class="headerlink" title="2）Java示例二"></a>2）Java示例二</h4><p>下面是一个Java堆栈跟踪日志，稍微复杂的例子：</p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalStateException: A book has a null property       at com.example.myproject.Author.getBookIds(Author.java:38)       at com.example.myproject.Bootstrap.main(Bootstrap.java:14)Caused by: java.lang.NullPointerException       at com.example.myproject.Book.getId(Book.java:22)       at com.example.myproject.Author.getBookIds(Author.java:35)       ... 1 more</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;^[[:space:]]+(at|\.&#123;3&#125;)\b|^Caused by:&#39;multiline.negate: falsemultiline.match: after</code></pre><p>此配置解释如下：</p><ul><li>将以空格开头的所有行合并到上一行</li><li>并把以Caused by开头的也追加到上一行</li></ul><h3 id="2、C风格的日志"><a href="#2、C风格的日志" class="headerlink" title="2、C风格的日志"></a>2、C风格的日志</h3><p>一些编程语言在一行末尾使用反斜杠()字符，表示该行仍在继续，如本例中所示:</p><pre><code>printf (&quot;%10.10ld  \t %10.10ld \t %s\  %f&quot;, w, x, y, z );</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;\\$&#39;multiline.negate: falsemultiline.match: before</code></pre><p>此配置将以\字符结尾的任何行与后面的行合并。</p><h3 id="3、时间戳"><a href="#3、时间戳" class="headerlink" title="3、时间戳"></a>3、时间戳</h3><p>来自Elasticsearch等服务的活动日志通常以时间戳开始，然后是关于特定活动的信息，如下例所示：</p><pre><code>[2015-08-24 11:49:14,389][INFO ][env                      ] [Letha] using [1] data paths, mounts [[/(/dev/disk1)]], net usable_space [34.5gb], net total_space [118.9gb], types [hfs]</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;^\[[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&#39;multiline.negate: truemultiline.match: after</code></pre><p>此配置使用<code>negate: true</code>和<code>match: after</code>设置来指定任何不符合指定模式的行都属于上一行。</p><h3 id="4、应用程序事件"><a href="#4、应用程序事件" class="headerlink" title="4、应用程序事件"></a>4、应用程序事件</h3><p>有时您的应用程序日志包含以自定义标记开始和结束的事件，如以下示例：</p><pre><code>[2015-08-24 11:49:14,389] Start new event[2015-08-24 11:49:14,395] Content of processing something[2015-08-24 11:49:14,399] End event</code></pre><p>要在Filebeat中将其整合为单个事件，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;Start new event&#39;multiline.negate: truemultiline.match: aftermultiline.flush_pattern: &#39;End event&#39;</code></pre><p>此配置把指定字符串开头，指定字符串结尾的多行合并为一个事件。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、配置解释：&quot;&gt;&lt;a href=&quot;#一、配置解释：&quot; class=&quot;headerlink&quot; title=&quot;一、配置解释：&quot;&gt;&lt;/a&gt;一、配置解释：&lt;/h2&gt;&lt;p&gt;在filebeat.yml的filebeat.inputs中，有关于多行日志合并的配置：&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/ELK/"/>
    
    
    <category term="ELK" scheme="https://www.langxw.com/tags/ELK/"/>
    
    <category term="filebeat" scheme="https://www.langxw.com/tags/filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Git上传本地项目</title>
    <link href="https://www.langxw.com/2021/02/02/Git%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE/"/>
    <id>https://www.langxw.com/2021/02/02/Git%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE/</id>
    <published>2021-02-02T02:21:35.000Z</published>
    <updated>2021-02-02T02:23:08.699Z</updated>
    
    <content type="html"><![CDATA[<p><strong>目的：本地已有项目，想上传到Github。</strong></p><h2 id="一、Github-Desktop-客户端"><a href="#一、Github-Desktop-客户端" class="headerlink" title="一、Github Desktop 客户端"></a>一、Github Desktop 客户端</h2><p>不习惯命令行的用户，可以使用Github GUI来操作。</p><h2 id="二、Git-clone-命令"><a href="#二、Git-clone-命令" class="headerlink" title="二、Git clone 命令"></a>二、Git clone 命令</h2><h3 id="1、Github新建Project："><a href="#1、Github新建Project：" class="headerlink" title="1、Github新建Project："></a>1、Github新建Project：</h3><p>新建Project，设置.gitignore文件后，得到git project地址:<code>https://github.com/langlangago/alex_blog.git</code></p><h3 id="2、本地执行git-clone："><a href="#2、本地执行git-clone：" class="headerlink" title="2、本地执行git clone："></a>2、本地执行git clone：</h3><p>在本地目录中，执行git clone 命令，下载远端project：<code>git clone https://github.com/langlangago/alex_blog.git</code>。</p><p>之后，将本地项目的文件移动到git clone 目录alex_blog下。</p><h3 id="3、将本地文件上传："><a href="#3、将本地文件上传：" class="headerlink" title="3、将本地文件上传："></a>3、将本地文件上传：</h3><p>在alex_blog目录下，将新加入文件上传到远端：</p><pre><code class="bash">git add -Agit commit -m &quot;init&quot;git push origin master</code></pre><h2 id="三、初始化本地已有项目init"><a href="#三、初始化本地已有项目init" class="headerlink" title="三、初始化本地已有项目init"></a>三、初始化本地已有项目init</h2><h3 id="1、Github新建Project：-1"><a href="#1、Github新建Project：-1" class="headerlink" title="1、Github新建Project："></a>1、Github新建Project：</h3><p>同上。</p><h3 id="2、在本地项目根目录执行git-init命令："><a href="#2、在本地项目根目录执行git-init命令：" class="headerlink" title="2、在本地项目根目录执行git init命令："></a>2、在本地项目根目录执行git init命令：</h3><p><code>git init</code></p><h3 id="3、关联远程仓库："><a href="#3、关联远程仓库：" class="headerlink" title="3、关联远程仓库："></a>3、关联远程仓库：</h3><p><code>git remote add origin https://github.com/langlangago/alex_blog.git</code></p><h3 id="4、从远程分支拉取master分支并与本地master分支合并："><a href="#4、从远程分支拉取master分支并与本地master分支合并：" class="headerlink" title="4、从远程分支拉取master分支并与本地master分支合并："></a>4、从远程分支拉取master分支并与本地master分支合并：</h3><p><code>git pull origin master:master</code></p><h3 id="5、提交本地分支到远程分支："><a href="#5、提交本地分支到远程分支：" class="headerlink" title="5、提交本地分支到远程分支："></a>5、提交本地分支到远程分支：</h3><p><code>git push -u origin master</code></p><h3 id="6、将现有项目添加并提交上传："><a href="#6、将现有项目添加并提交上传：" class="headerlink" title="6、将现有项目添加并提交上传："></a>6、将现有项目添加并提交上传：</h3><pre><code class="bash">git add -Agit commit -m &quot;init&quot;git push --set-upstream origin master</code></pre><h2 id="四、Git命令说明："><a href="#四、Git命令说明：" class="headerlink" title="四、Git命令说明："></a>四、Git命令说明：</h2><h3 id="1、git-pull"><a href="#1、git-pull" class="headerlink" title="1、git pull"></a>1、git pull</h3><p>git pull命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂。</p><pre><code class="bash">$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。$ git pull origin next:master如果远程分支是与当前分支合并，则冒号后面的部分可以省略。$ git pull origin next</code></pre><h3 id="2、git-clone"><a href="#2、git-clone" class="headerlink" title="2、git clone"></a>2、git clone</h3><p>git克隆基本上是一个组合： </p><pre><code class="bash">git init(创建本地存储库)git remote add(将URL添加到该存储库)git fetch(从该URL中获取所有分支到本地存储库)git checkout(创建工作树中主分支的所有文件)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;目的：本地已有项目，想上传到Github。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;一、Github-Desktop-客户端&quot;&gt;&lt;a href=&quot;#一、Github-Desktop-客户端&quot; class=&quot;headerlink&quot; title=&quot;一、Gith</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="Git" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/Git/"/>
    
    
    <category term="git" scheme="https://www.langxw.com/tags/git/"/>
    
  </entry>
  
</feed>
