<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维人</title>
  
  
  <link href="https://www.langxw.com/atom.xml" rel="self"/>
  
  <link href="https://www.langxw.com/"/>
  <updated>2023-12-18T03:36:14.461Z</updated>
  <id>https://www.langxw.com/</id>
  
  <author>
    <name>运维人</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>容器内抓包</title>
    <link href="https://www.langxw.com/2023/12/18/%E5%AE%B9%E5%99%A8%E5%86%85%E6%8A%93%E5%8C%85/"/>
    <id>https://www.langxw.com/2023/12/18/%E5%AE%B9%E5%99%A8%E5%86%85%E6%8A%93%E5%8C%85/</id>
    <published>2023-12-18T02:03:29.000Z</published>
    <updated>2023-12-18T03:36:14.461Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、使用脚本一键进入Pod-netns-抓包"><a href="#一、使用脚本一键进入Pod-netns-抓包" class="headerlink" title="一、使用脚本一键进入Pod netns 抓包"></a>一、使用脚本一键进入Pod netns 抓包</h2><ol><li>执行以下命令，获取该 Pod 副本所在的节点和 Pod 名称。</li></ol><pre><code class="Plaintext">kubectl get pod -o wide</code></pre><ol start="2"><li>登录到Pod所在的节点</li></ol><pre><code class="Bash">#!/usr/bin/env bashfunction debug_net() &#123;  set -eu  echo $pod_name  containerID=$(crictl ps -q --label io.kubernetes.pod.name=$pod_name |sed -n 1p)  echo $containerID  pid=$(crictl inspect $&#123;containerID&#125; |grep -i pid --m 1 |awk &#39;&#123;print $2 &#125;&#39; |awk -F, &#39;&#123;print $1&#125;&#39;)  echo $pid  cmd=&quot;nsenter -n -t $&#123;pid&#125;&quot;  echo -e &quot;\033[32m Execute the command: $&#123;cmd&#125; \033[0m&quot;  $&#123;cmd&#125;    &#125;# 运行函数pod_name=$1debug_net</code></pre><p>在节点上执行命令进入Pod的容器的网络命名空间</p><pre><code class="Bash">./debug.sh &#123;PodName&#125;ip a ## 验证是否已经进入 查看ip是否是容器ip</code></pre><p>使用示例:</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZTU0MDE3MmIwMDFhMzM2MTBlNGI4Yzc5NTY1MTU3M2RfbDlTVFM0b3hKUU12RXFzcU42UXIxdHpROEJ1YTRkWXVfVG9rZW46Ym94Y25HQWlFQ1YzSmxaQ25DQzdoRk81RzBiXzE3MDI4NjUyMjA6MTcwMjg2ODgyMF9WNA"></p><p>在Pod的网络命名空间内抓包命令:</p><pre><code class="Bash">nohup tcpdump -i any tcp and host 域名 -C 100M -W 10 -w /tmp/debug-&#123;podName&#125;.pcap &amp;</code></pre><p>在节点上抓包不需要进入容器的网络命名空间</p><pre><code class="Bash">nohup tcpdump -i any tcp and host 域名 -C 100M -W 10 -w /tmp/debug-&#123;NodeName&#125;.pcap &amp;</code></pre><hr><h2 id="二、定制脚本对单个节点多个容器进行抓包，一键执行抓包"><a href="#二、定制脚本对单个节点多个容器进行抓包，一键执行抓包" class="headerlink" title="二、定制脚本对单个节点多个容器进行抓包，一键执行抓包"></a>二、定制脚本对单个节点多个容器进行抓包，一键执行抓包</h2><pre><code class="Bash">#!/usr/bin/env bashfunction debug_net() &#123;  set -eu  echo $pod_name  podID=$(crictl pods |grep $&#123;pod_name&#125;|awk &#39;&#123;print $1&#125;&#39;)  echo &quot;--&gt; $&#123;podID&#125;&quot;  pid=`crictl pods |grep $pod_name |awk &#39;&#123;print $1&#125;&#39; |xargs -n 1 -I &#123;&#125; sh -c &#39;crictl inspect $(crictl ps --pod &#123;&#125; -q) |grep -i pid --m 1&#39; |awk &#39;&#123;print $2&#125;&#39;|awk -F, &#39;&#123;print $1&#125;&#39;`  for p in $&#123;pid&#125;  do          echo -e &quot;\033[32m currunt PID: $p \033[0m&quot;        nohup  nsenter -n -t $&#123;p&#125; sh -c &quot;tcpdump -i any port 80 and host img-faceplay-dy-1300308946.cos.ap-guangzhou.myqcloud.com or host sh-segment-dp.oss-cn-shanghai.aliyuncs.com -C 100M -W 50 -w /tmp/debug-$p.pcap &quot; &amp;          echo -e &quot;\033[32m tcpdump started \033[0m&quot;  done&#125;# 运行函数pod_name=$1debug_net</code></pre><p>保存名称为容器pid.pcapxx</p><p>使用示例:</p><pre><code class="Bash">./debug.sh &#123;pod关键字&#125;</code></pre><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NTdhZDYyMTMyMTk0NTUwMjcxOGNlYmM4ZWM5MjIyZmVfa1FqS3FHdDI3UFV4WlJ1Sk92V0JTVVMyNklRQWpOMkxfVG9rZW46Ym94Y24xMm9sdlZqYW5zUzFYb29ydkxxS1RoXzE3MDI4NjUyMjA6MTcwMjg2ODgyMF9WNA"></p><h2 id="三、其他方式"><a href="#三、其他方式" class="headerlink" title="三、其他方式"></a>三、其他方式</h2><p><strong>kubelet debug</strong> </p><pre><code class="bash"> kubectl debug -it -n zhw-test zhw-test-shqclient-deploy-578df65c55-5dvmj \--image=busybox --share-processes \--copy-to=zhw-test-shqclient-deploy-578df65c55-5dvmj-debug \--container=shqclient-container-debug</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、使用脚本一键进入Pod-netns-抓包&quot;&gt;&lt;a href=&quot;#一、使用脚本一键进入Pod-netns-抓包&quot; class=&quot;headerlink&quot; title=&quot;一、使用脚本一键进入Pod netns 抓包&quot;&gt;&lt;/a&gt;一、使用脚本一键进入Pod netns </summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Shell" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Shell/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>Nginx不喜欢下划线_</title>
    <link href="https://www.langxw.com/2023/12/14/Nginx%E4%B8%8D%E5%96%9C%E6%AC%A2%E4%B8%8B%E5%88%92%E7%BA%BF/"/>
    <id>https://www.langxw.com/2023/12/14/Nginx%E4%B8%8D%E5%96%9C%E6%AC%A2%E4%B8%8B%E5%88%92%E7%BA%BF/</id>
    <published>2023-12-14T06:00:56.000Z</published>
    <updated>2023-12-14T09:29:09.780Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>最近有发生过一个诡异想象：</p><ol><li><p>生产环境异常，客户端添加的自定义Header：app_versiion，经过nginx和网关后，传到后端服务会丢失。</p></li><li><p>预发布环境正常，预发布和生产的差别在没经过nginx代理。初步判断是Nginx的问题。</p></li><li><p>在生产环境访问日志中打印Header信息$http_app_version，值为空。确认是Nginx丢弃了。</p></li><li><p>联想到之前upstream下划线的问题，怀疑是下划线的问题。更换Header中下划线为中划线即app-version后，再次通过curl模拟请求，Nginx日志正常打印了app-version的Header信息。</p></li></ol><h2 id="二、自定义Header不喜欢下划线"><a href="#二、自定义Header不喜欢下划线" class="headerlink" title="二、自定义Header不喜欢下划线"></a>二、自定义Header不喜欢下划线</h2><p><strong>Nginx会把header中变量的大写字母转化为小写字母，把中划线转换为下划线，再加上前缀http：比如X-LIST 转换为http_x_list。</strong></p><h3 id="1、原因"><a href="#1、原因" class="headerlink" title="1、原因"></a>1、原因</h3><p>为什么会使nginx和apache服务器对名称中带下划线header不做转发呢，查阅相关资料后发现是CGI（公共网关接口Common Gateway Interface，CGI是Web 服务器运行时外部程序的规范）的历史遗留问题如下，大概意思就是 下划线和中划线都为会被映射为 CGI 系统变量中名中的下划线，这样容易引起混淆。官方解释如下：</p><blockquote><p>If you do not explicitly set underscores_in_headers on;, NGINX will silently drop HTTP headers with underscores (which are perfectly valid according to the HTTP standard). This is done in order to prevent ambiguities when mapping headers to CGI variables as both dashes and underscores are mapped to underscores during that process.</p></blockquote><h3 id="2、Nginx关于头部的两个配置"><a href="#2、Nginx关于头部的两个配置" class="headerlink" title="2、Nginx关于头部的两个配置"></a>2、Nginx关于头部的两个配置</h3><ul><li>ignore_invalid_headers 默认on</li></ul><blockquote><p>Controls whether header fields with invalid names should be ignored. Valid names are composed of English letters, digits, hyphens, and possibly underscores (as controlled by the underscores_in_headers directive).</p></blockquote><ul><li>underscores_in_headers  默认off</li></ul><blockquote><p>Enables or disables the use of underscores in client request header fields. When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive.</p></blockquote><p>上述说明：</p><ol><li><p>underscores_in_headers 默认为off，带有下划线的header默认是invalid。</p></li><li><p>Nginx对valid_headers的规定就是英文字母，数字，连字号和下划线(可以通过underscores_in_headers控制)，默认情况下其他invalid_headers会忽略并丢弃。</p></li></ol><h3 id="3、解决办法"><a href="#3、解决办法" class="headerlink" title="3、解决办法"></a>3、解决办法</h3><ol><li><p><strong>在自定义header中要使用中划线，禁止使用下划线（推荐）。</strong></p></li><li><p>在http或者server中，将underscores_in_headers参数设置为on。</p></li></ol><h3 id="4、nginx的header还禁止dot"><a href="#4、nginx的header还禁止dot" class="headerlink" title="4、nginx的header还禁止dot(.)"></a>4、nginx的header还禁止dot(.)</h3><h2 id="三、Upstream-name不喜欢下划线"><a href="#三、Upstream-name不喜欢下划线" class="headerlink" title="三、Upstream name不喜欢下划线"></a>三、Upstream name不喜欢下划线</h2><p><strong>后端是Java服务</strong>的情况下，在配置upstream的name的时候，如果带有下划线，比如big_data，前端会反回400错误。</p><h3 id="1、原因-1"><a href="#1、原因-1" class="headerlink" title="1、原因"></a>1、原因</h3><ul><li><p>nginx在转发http请求的时候会加上实际的Host请求头，nginx在没有配置<code>proxy_set_header HOST $host</code> 的时候，在转发http请求的时候会默认把upstream的名称作为Host头部的内容。</p></li><li><p>比如<code>proxy_pass http://big_data;</code>中http header中Host字段值为big_data。</p></li><li><p><a href="https://github.com/spring-projects/spring-boot/issues/13236">[tomcat] Spring boot web always return 400 when use a domain name · Issue #13236 · spring-projects/spring-boot · GitHub</a> 从这里可以看出问题的原因是带有下划线的Host的http请求，tomcat认为是有问题。</p></li></ul><h3 id="2、解决办法"><a href="#2、解决办法" class="headerlink" title="2、解决办法"></a>2、解决办法</h3><ol><li><p>upsrteam的名字不是用下划线，使用中划线或者驼峰。</p></li><li><p>在location处设置 <code>proxy_set_header HOST $host</code></p><blockquote><p>这个配置的主要是在nginx在转发http请求的时候会加上实际的Host请求头。如http请求是 <a href="http://abc.com/hello%EF%BC%8C">http://abc.com/hello，</a> 那么nginx在转发http请求的时候会原封不动的把host请求头(Host:abc.com)转发给后台服务。对于nginx而言，如果没有配置proxy_set_header HOST $host的时候会默认修改Host为upstream的名称。</p></blockquote></li></ol><h2 id="四、排查手段"><a href="#四、排查手段" class="headerlink" title="四、排查手段"></a>四、排查手段</h2><h3 id="1、Nginx-错误日志级别"><a href="#1、Nginx-错误日志级别" class="headerlink" title="1、Nginx 错误日志级别"></a>1、Nginx 错误日志级别</h3><p>nginx error日志默认级别是error，只打印重要的错误日志。在调试和定位nginx问题的时候可以提高日志级别为debug 或者 info。<code>error_log logs/app_err.log debug;</code></p><h3 id="2、Curl-模拟请求"><a href="#2、Curl-模拟请求" class="headerlink" title="2、Curl 模拟请求"></a>2、Curl 模拟请求</h3><pre><code class="bash">curl -H &quot;app-version:1.2.3&quot; http://www.abc.com:/health-check</code></pre><h3 id="3、Tcpdump抓包"><a href="#3、Tcpdump抓包" class="headerlink" title="3、Tcpdump抓包"></a>3、Tcpdump抓包</h3><h2 id="五、启示"><a href="#五、启示" class="headerlink" title="五、启示"></a>五、启示</h2><ul><li><p>排查问题，第一是看日志，debug级别的日志。</p></li><li><p>排查问题，第二是看官方文档的相关说明。</p></li><li><p>运维必须系统地学习常用工具组件的官档和教程。</p></li><li><p>最好能看懂源代码，源代码能解决一切疑问。</p></li><li><p>抓包，当实在无法确认问题出在哪一个环节的时候，就抓包。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;最近有发生过一个诡异想象：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;生产环境异常，客户端添加的自定义Header：app_versi</summary>
      
    
    
    
    <category term="中间件" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="Nginx" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Nginx/"/>
    
    
    <category term="nginx" scheme="https://www.langxw.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>定期检查某个SSL证书的有效期并告警</title>
    <link href="https://www.langxw.com/2023/12/08/%E5%AE%9A%E6%9C%9F%E6%A3%80%E6%9F%A5%E6%9F%90%E4%B8%AASSL%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F%E5%B9%B6%E5%91%8A%E8%AD%A6/"/>
    <id>https://www.langxw.com/2023/12/08/%E5%AE%9A%E6%9C%9F%E6%A3%80%E6%9F%A5%E6%9F%90%E4%B8%AASSL%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F%E5%B9%B6%E5%91%8A%E8%AD%A6/</id>
    <published>2023-12-08T03:48:03.000Z</published>
    <updated>2023-12-08T03:55:27.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>由于历史原因，我司SSL证书分散在不同的云服务器上，更换证书的时候可能会有遗漏。故将分散的SSL证书记录在文件里，定期用脚本检查剩余有效期天数，并告警。可以防止更换遗漏的事情发生。</p><h2 id="二、脚本"><a href="#二、脚本" class="headerlink" title="二、脚本"></a>二、脚本</h2><ul><li>记录ssl证书所在服务器的位置</li></ul><pre><code>/root/ops_scripts/ip_ssl_path.txt10.10.10.1#/usr/local/nginx/conf/cert/didikaihei.com.pem10.10.10.2#/usr/local/nginx/conf/vhost/cert/zuhaowan.com.cn.pem</code></pre><ul><li>设置Crontab定时任务执行脚本，并发送微信告警</li></ul><pre><code class="shell">#!/bin/bashexport LC_ALL=Cerror_ips=&quot;&quot;notify()&#123;   curl &#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=5b37f5cc-d1ed-48d4-a4b4-7d4f8a9da478&#39; \   -H &#39;Content-Type: application/json&#39; \   -d &#39;   &#123;        &quot;msgtype&quot;: &quot;text&quot;,        &quot;text&quot;: &#123;            &quot;content&quot;: &quot;SSL证书有效期小于30天的IP列表(非Proxy机器):\n&#39;$1&#39;&quot;,            &quot;mentioned_mobile_list&quot;:[&quot;@all&quot;,]        &#125;   &#125;&#39;&#125;for line in `cat /root/ops_scripts/ip_ssl_path.txt`do        echo &quot;================================&quot;        ip=$(echo $line|awk -F&quot;#&quot; &#39;&#123;print $1&#125;&#39;)        ssl_path=$(echo $line|awk -F&quot;#&quot; &#39;&#123;print $2&#125;&#39;)        echo $ip        end_time=$(ssh $ip &quot;openssl x509 -in $ssl_path -noout -enddate |awk -F &#39;=&#39; &#39;&#123;print \$2&#125;&#39;&quot;)        end_times=`date -d &quot;$end_time&quot; +%s `        current_times=`date -d &quot;$(date -u &#39;+%b %d %T %Y GMT&#39;) &quot; +%s `        let left_time=$end_times-$current_times        days=`expr $left_time / 86400`        echo &quot;剩余天数: &quot; $days        [ $days -lt 31 ] &amp;&amp; echo &quot;https 证书有效期少于30天，存在风险&quot; &amp;&amp; error_ips=&quot;$error_ips#$ip&quot; doneecho -e &quot;准备过期的域名为： \n  $error_ips&quot;if [ &quot;$error_ips&quot; = &quot;&quot; ]then        echo &quot;不包含准备过期的域名&quot;else        notify $error_ips        echo &quot;包含准备过期的域名&quot; fi</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;由于历史原因，我司SSL证书分散在不同的云服务器上，更换证书的时候可能会有遗漏。故将分散的SSL证书记录在文件里，定期用脚本</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Shell" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Shell/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
    <category term="linux" scheme="https://www.langxw.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>批量检查域名SSL证书的有效期</title>
    <link href="https://www.langxw.com/2023/12/08/%E6%89%B9%E9%87%8F%E6%A3%80%E6%9F%A5%E5%9F%9F%E5%90%8DSSL%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F/"/>
    <id>https://www.langxw.com/2023/12/08/%E6%89%B9%E9%87%8F%E6%A3%80%E6%9F%A5%E5%9F%9F%E5%90%8DSSL%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F/</id>
    <published>2023-12-08T03:35:10.000Z</published>
    <updated>2023-12-08T03:45:30.148Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>我司的某个主域名有很多子域名，SSL证书到期提示更换，由于没有记录哪个域名使用了https，手动一个个去验证很麻烦，就想到靠一个脚本解决。</p><h2 id="二、脚本"><a href="#二、脚本" class="headerlink" title="二、脚本"></a>二、脚本</h2><p>先将子域名一行一个地写入https_list.txt文件里，然后执行脚本即可。</p><pre><code class="bash">#!/bin/bash# 检测https证书有效echo &#39;开始检查 https证书有效期 &#39;# 先手动写域名到文件https_list.txt中，再读取文件检查证书是否过期了# 例子：#echo &#39;www.baidu.com&#39; &gt;&gt; https_list.txtsource /etc/profile# 定义错误的域名errorDominStr=&quot;&quot;while read line; do    echo &quot;=====================================================================================&quot;    echo &quot;当前检测的域名：&quot; $line    end_time=$(echo | timeout 1 openssl s_client -servername $line -connect $line:443 2&gt;/dev/null | openssl x509 -noout -enddate 2&gt;/dev/null | awk -F &#39;=&#39; &#39;&#123;print $2&#125;&#39;)    ([ $? -ne 0 ] || [[ $end_time == &#39;&#39; ]]) &amp;&amp; echo &#39;该域名链接不上,跳到下一个域名&#39; &amp;&amp; continue    end_times=`date -d &quot;$end_time&quot; +%s `    current_times=`date -d &quot;$(date -u &#39;+%b %d %T %Y GMT&#39;) &quot; +%s `    let left_time=$end_times-$current_times    days=`expr $left_time / 86400`    echo &quot;剩余天数: &quot; $days    [ $days -lt 60 ] &amp;&amp; echo &quot;https 证书有效期少于60天，存在风险&quot;  &amp;&amp; errorDominStr=&quot;$errorDominStr \n $line&quot;done &lt; ~/https_list.txtecho -e &quot;准备过期的域名为： \n  $errorDominStr&quot;if [ &quot;$errorDominStr&quot; = &quot;&quot; ]then  echo &quot;不包含准备过期的域名&quot;else  echo &quot;包含准备过期的域名&quot; &amp;&amp; exit 10fiecho &quot;Good bye!&quot;exit 0</code></pre><p><strong>注意：脚本输出的准备过期的域名提示仅供参考，具体还需要看脚本的详细日志逐个甄别</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;我司的某个主域名有很多子域名，SSL证书到期提示更换，由于没有记录哪个域名使用了https，手动一个个去验证很麻烦，就想到靠</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Shell" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Shell/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
    <category term="linux" scheme="https://www.langxw.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>命令行sed提取字符串中的字段</title>
    <link href="https://www.langxw.com/2023/12/08/%E5%91%BD%E4%BB%A4%E8%A1%8Csed%E6%8F%90%E5%8F%96%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E5%AD%97%E6%AE%B5/"/>
    <id>https://www.langxw.com/2023/12/08/%E5%91%BD%E4%BB%A4%E8%A1%8Csed%E6%8F%90%E5%8F%96%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E5%AD%97%E6%AE%B5/</id>
    <published>2023-12-08T03:23:50.000Z</published>
    <updated>2023-12-08T03:26:56.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>一般切割提取字符串的字段，如果有规律可寻，采用awk或者cut就可以搞定。如果无规律的分隔符，就必须要用正则表达式来提取需要的数据了。</p><h2 id="二、解决办法"><a href="#二、解决办法" class="headerlink" title="二、解决办法"></a>二、解决办法</h2><p>使用sed时，我通常通过搜索除分隔符之外的任何东西来实现非贪婪搜索，直到分隔符为止：</p><pre><code class="bash">echo &quot;http://www.suon.co.uk/product/1/7/3/&quot; | sed -n &#39;s;\(http://[^/]*\)/.*;\1;p&#39;</code></pre><p>输出</p><pre><code class="bash">http://www.suon.co.uk</code></pre><p>这是：</p><ul><li>不输出不打印 <code>-n</code></li><li>s搜索，匹配模式，替换并打印 <code>s/&lt;pattern&gt;/&lt;replace&gt;/p</code></li><li>使用<code>;</code>搜索命令分隔符而不是<code>/</code>使其更容易键入，以便<code>s;&lt;pattern&gt;;&lt;replace&gt;;p</code></li><li>记住括号之间的匹配<code>\(</code>… <code>\)</code>，以后可通过<code>\1</code>，<code>\2</code>… 访问</li><li>固定匹配 <code>http://</code></li><li>后面在括号任何东西<code>[]</code>，<code>[ab/]</code>就意味着无论是<code>a</code>或<code>b</code>或<code>/</code></li><li>首先<code>^</code>是<code>[]</code>中的<code>not</code>，所以<code>[^/]</code>是除了<code>/</code>的其他字符</li><li><code>*</code>是重复前一组，<code>[^/]*</code>表示重复除<code>/</code>以外的字符，也意味着重复到<code>/</code>就结束了。</li><li>到目前为止，<code>sed -n &#39;s;\(http://[^/]*\)</code>表示搜索并记住（提取），<code>http://</code>后面紧跟任何字符，除了<code>/</code>，记住（提取）您找到的内容</li><li>我们要搜索直到域的末尾，所以在下一个<code>/</code>停止，因此<code>/</code>在末尾添加。另一个：<code>sed -n &#39;s;\(http://[^/]*\)/&#39;</code>。（可以不需要）</li><li>我们要匹配域后的其余行，因此添加<code>.*</code></li><li>在组1（<code>\1</code>）中记住的匹配项是域，因此将匹配的行替换为保存在组中<code>\1</code>并把内容打印<code>p</code>出来：<code>sed -n &#39;s;\(http://[^/]*\)/.*;\1;p&#39;</code></li></ul><h2 id="三、实际例子"><a href="#三、实际例子" class="headerlink" title="三、实际例子"></a>三、实际例子</h2><p>提取SQL语句中的某个字段（goods_sku）</p><p>SQL语句如下：</p><pre><code>string=&quot;UPDATE \`db\`.\`purchase_mould\` SET \`update_time\`=1, \`__dropped_col_16__\`=\`2023-11-14 23:27:55\`, \`goods_id\`=\`123123123\`, \`mould_id\`=123123, \`specs_crc\`=123123, \`pid\`=123123, \`state\`=8.00, \`pusername\`=\`aaaa\`, \`protect_price\`=2, \`shop_id\`=123123, \`create_time\`=\`2023-12-02 19:37:56\`, \`game_name\`=\`火影\`, \`goods_sku\`=316123123, \`duration\`=1, \`game_id\`=560, \`mould_name\`=\`鲛肌\`, \`id\`=54916 WHERE \`update_time\`=2 AND \`__dropped_col_16__\`=\`2023-11-14 23:27:55\` AND \`goods_id\`=\`5123431\` AND \`mould_id\`=12222 AND \`specs_crc\`=123123444 AND \`pid\`=1122222 AND \`state\`=1.00 AND \`pusername\`=\`zaaaaa\` AND \`protect_price\`=2 AND \`shop_id\`=741231 AND \`create_time\`=\`2023-12-02 19:37:27\` AND \`game_name\`=\`火影\` AND \`goods_sku\`=316123 AND \`duration\`=1 AND \`game_id\`=560 AND \`mould_name\`=\`鲛肌` AND \`id\`=5123 LIMIT 1; #start 349365354 end 349365957 time 2023-12-02 19:37:56&quot;</code></pre><p>sed正则表达式：</p><pre><code class="bash"> echo $string |sed -n &quot;s;.*\(\`goods_sku\`=[^ ]*\).*;\1;p</code></pre><p>如果只具体的值，不要字段，只需要把字段移到分组括号外就行。</p><pre><code class="bash">echo $string1 |sed -n &quot;s;.*\`goods_sku\`=\([^ ]*\).*;\1;p&quot;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;一般切割提取字符串的字段，如果有规律可寻，采用awk或者cut就可以搞定。如果无规律的分隔符，就必须要用正则表达式来提取需要</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="命令行" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/%E5%91%BD%E4%BB%A4%E8%A1%8C/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>浅析OCI、CRI、Docker、Containerd、runc、Dockershim、Containerd-shim分别是什么</title>
    <link href="https://www.langxw.com/2023/08/18/%E6%B5%85%E6%9E%90OCI%E3%80%81CRI%E3%80%81Docker%E3%80%81Containerd%E3%80%81runc%E3%80%81Dockershim%E3%80%81Containerd-shim%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/"/>
    <id>https://www.langxw.com/2023/08/18/%E6%B5%85%E6%9E%90OCI%E3%80%81CRI%E3%80%81Docker%E3%80%81Containerd%E3%80%81runc%E3%80%81Dockershim%E3%80%81Containerd-shim%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/</id>
    <published>2023-08-18T07:25:51.000Z</published>
    <updated>2023-08-18T08:50:53.282Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>在学习K8S的过程中，会经常看到runc，cri，containerd容器运行时这些名词，必须弄清楚了，才能对K8S的架构又更清晰深入的了解。</p><p><strong>如今容器已不再与Docker紧密耦合，我们可以使用Docker或者其他非Docker工具运行容器。Docker不能代表容器，日常中紧紧指代Docker工具。</strong></p><h2 id="二、名词解释"><a href="#二、名词解释" class="headerlink" title="二、名词解释"></a>二、名词解释</h2><h3 id="1、容器生态系统"><a href="#1、容器生态系统" class="headerlink" title="1、容器生态系统"></a>1、容器生态系统</h3><p>容器生态系统是由许多令人兴奋的技术、大量行话组成，是由许多大公司共同维护。</p><p><strong>容器相关主流标准：</strong></p><ol><li><p>Open Container Initiative（OCI）发布了容器运行时标准和容器镜像标准</p></li><li><p>Container Runtime Interface（CRI）定义了 Kubernetes 和下层容器运行时之间的 API</p></li></ol><p>下图准确展示了 Kubernetes、Docker、CRI、OCI、containerd 和 runc 在这个生态系统中是如何组织到一起的。</p><p><img src="https://s2.loli.net/2023/08/18/ztofpl4ga2b1WIc.png" alt="container-ecosystem.drawio.png"></p><h3 id="2、Docker"><a href="#2、Docker" class="headerlink" title="2、Docker"></a>2、Docker</h3><p>Docker是最流行的容器工具，Docker被设计成安装在个人电脑或者服务器上的一组工具，开发者能够轻松的用它投建或者运行容器。</p><h4 id="2-1-docker项目组成"><a href="#2-1-docker项目组成" class="headerlink" title="2.1 docker项目组成"></a>2.1 docker项目组成</h4><ul><li><p>docker-cli：docker daemon的命令行交互工具，我们说的docker默认指它</p></li><li><p>containerd：运行和管理容器的守护进程，推送和拉取镜像、管理存储和网络并监视容器的运行状态。<strong>高级别容器运行时。</strong></p></li><li><p>containerd-shim：属于containerd，是一个代理，负责containerd和底层runc进行交互。</p></li><li><p>runc：底层的容器运行时，<strong>低级别容器运行时</strong>，真正创建并运行容器的东西，包括 libcontainer。创建完容器后会退出，由containerd-shim接管。</p></li></ul><p>Docker简版调用图：</p><p><img src="https://s2.loli.net/2023/08/18/2takTCcVYzMUegs.png" alt="container-ecosystem-docker.drawio.png"></p><p>更进一步逻辑：</p><p><img src="https://s2.loli.net/2023/08/18/LWwxvCmlsFKGejU.png" alt="微信截图_20230818141342.png"></p><h4 id="2-2-Docker模块详解"><a href="#2-2-Docker模块详解" class="headerlink" title="2.2 Docker模块详解"></a>2.2 Docker模块详解</h4><p>从 Docker 1.11 之后，Docker Daemon 被分成了多个模块以适应 OCI 标准。拆分之后，结构分成了以下几个部分。</p><p><img src="https://s2.loli.net/2023/08/18/Ud2kCmyLapzOgMP.png" alt="6b576aff173724d6a8055bde5d06a1e7.png"></p><p>其中，containerd 独立负责容器运行时和生命周期(如创建、启动、停止、中止、信号处理、删除等)，其他一些如镜像构建、卷管理、日志等由 Docker Daemon 的其他模块处理。</p><ul><li><p>Docker 的模块块拥抱了开放标准，希望通过 OCI 的标准化，容器技术能够有很快的发展。</p></li><li><p>现在创建一个docker容器的时候，Docker Daemon 并不能直接帮我们创建了，而是请求 containerd 来创建一个容器。当containerd 收到请求后，也不会直接去操作容器，而是创建一个叫做 containerd-shim 的进程。让这个进程去操作容器，我们指定容器进程是需要一个父进程来做状态收集、维持 stdin 等 fd 打开等工作的，假如这个父进程就是 containerd，那如果 containerd 挂掉的话，整个宿主机上所有的容器都得退出了，而引入 containerd-shim 这个垫片就可以来规避这个问题了，就是提供的live-restore的功能。这里需要注意systemd的 MountFlags=slave。</p></li><li><p>然后创建容器需要做一些 namespaces 和 cgroups 的配置，以及挂载 root 文件系统等操作。runc 就可以按照这个 OCI 文档来创建一个符合规范的容器。</p></li><li><p>真正启动容器是通过 containerd-shim 去调用 runc 来启动容器的，runc 启动完容器后本身会直接退出，containerd-shim 则会成为容器进程的父进程, 负责收集容器进程的状态, 上报给 containerd, 并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理, 确保不会出现僵尸进程。containerd，containerd-shim和容器进程(即容器主进程)三个进程，是有依赖关系的。</p></li></ul><h3 id="3、Dockershim"><a href="#3、Dockershim" class="headerlink" title="3、Dockershim"></a>3、Dockershim</h3><p>Kubernetes 曾经包含了一个叫做 dockershim 的组件（v1.24 版本中彻底移除），使它能够支持 Docker。</p><p>Kubernetes 偏向于通过支持 Container Runtime Interface（CRI）接口的任何容易运行时运行容器，但 Docker 比 Kubernetes 出现得更早，Docker 并不支持 CRI（容器运行时接口）这一 Kubernetes 运行时 API，而 Kubernetes 用户一直以来所使用的其实是名为“dockershim”的桥接服务。Dockershim 能够转换 Docker API 与 CRI。</p><blockquote><p>在软件系统中，shim 垫片扮演不同 API 之间桥的角色，或作为兼容层。当你想使用一个第三方的组件，但需要少许胶水代码来使其奏效，有时候就会添加一个 shim。</p></blockquote><p><img src="https://s2.loli.net/2023/08/18/3XOPYnV2QN9koJb.png" alt="cri-performance.png"></p><p>移除 dockershim 并不意味着 Kubernetes 无法运行 Docker 格式的容器。不论 containerd 还是 CRI-O 都能运行 Docker 格式（实际上是 OCI 格式）的镜像，只是无需通过 <code>docker</code> 命令或 Docker daemon 来进行。</p><h3 id="4、Docker镜像"><a href="#4、Docker镜像" class="headerlink" title="4、Docker镜像"></a>4、Docker镜像</h3><p><strong>大家所说的 Docker 镜像，实际上是以 Open Container Initiative（OCI）格式打包的。</strong></p><p>不论从 Docker Hub 还是其他 registry 拉取的镜像，都能够用 <code>docker</code> 命令使用它，亦或者是 Kubernetes 集群中，或者通过 podman 工具，还是其他支持 OCI 镜像格式规范的工具。</p><p>这就是有一个开放的标准的好处——任何人都可以编写支持标准的软件。</p><h3 id="5、CRI"><a href="#5、CRI" class="headerlink" title="5、CRI"></a>5、CRI</h3><p><strong>CRI-Container Runtime Interface） 是 Kubernetes 用来控制不同运行时创建和管理容器的协议。</strong></p><p>CRI 抽象了容器运行时，Kubernetes 无需关心到底是哪一种。Kubernetes 不应该自身支持<br>每一种容器运行时，那样代码库会更庞大而且难以管理，CRI API 描述了 Kubernetes 如何与运行时交互。这样，实际上管理容器的是下面的容器运行时。</p><p><img src="https://s2.loli.net/2023/08/18/Mybwf92K1IpRYtC.png" alt="微信截图_20230818144646.png"></p><p>不论 containerd 还是 CRI-O 都可以使用，因为这两种运行时都实现了 CRI 规范。作为用户的我们无需关心，每种 CRI 实现略有不同但旨在可插拔和无缝修改。</p><p>红帽的 OpenShift 使用 CRI-O 并为其提供支持而 Docker 支持它们自己的 containerd。</p><h3 id="6、Containerd"><a href="#6、Containerd" class="headerlink" title="6、Containerd"></a>6、Containerd</h3><p><strong>containerd 是来自于 Docker 的高级别容器运行时，并实现了 CRI 规范。真正创建和运行容器进程的是它所控制的底层运行时。</strong></p><ul><li>containerd 从 Docker 项目中拆分出来使其更模块化。</li><li>Docker 自己内部使用 containerd，安装 Docker 同时也会安装 containerd。</li><li>containerd 通过它的 cri 插件实现了 Kubernetes CRI。</li></ul><p><img src="https://s2.loli.net/2023/08/18/qgZteIOWBzj68xK.png" alt="1d2badf2b2f92fcfc4386dca8854e995.png"></p><p>containerd 是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性，containerd 可以负责干下面这些事情：</p><ul><li>管理容器的生命周期(从创建容器到销毁容器)</li><li>拉取/推送容器镜像</li><li>存储管理(管理镜像及容器数据的存储)</li><li>调用 runc 运行容器(与 runc 等容器运行时交互)</li><li>管理容器网络接口及网络</li></ul><p><img src="https://s2.loli.net/2023/08/18/4o7sQJbXmpB9tqG.png" alt="v2-dd73d91848ccbdb6db2d920da3b6db95_720w.png"></p><p>上图是 Containerd 整体的架构。由下往上，Containerd支持的操作系统和架构有 Linux、<br>Windows 以及像 ARM 的一些平台。在这些底层的操作系统之上运行的就是底层容器运行<br>时，其中有上文提到的runc、gVisor 等。在底层容器运行时之上的是Containerd 相关的组件，比如 Containerd 的 runtime、core、API、backend、store 还有metadata 等等。构筑在 Containerd 组件之上以及跟这些组件做交互的都是 Containerd 的 client，Kubernetes 跟 Containerd 通过 CRI 做交互时，本身也作为 Containerd 的一个 client。Containerd 本身有提供了一个 CRI，叫 ctr，不过这个命令行工具并不是很好用。</p><p>在这些组件之上就是真正的平台，Google Cloud、Docker、IBM、阿里云、微软云还有RANCHER等等都是，这些平台目前都已经支持 containerd， 并且有些已经作为自己的默认容器运行时了。</p><p>从 k8s 的角度看，选择 containerd作为运行时的组件，它调用链更短，组件更少，更稳定，占用节点资源更少。</p><p><img src="https://s2.loli.net/2023/08/18/oJbW5Lf7BVK9ZlT.png" alt="33c809cc2219b915c1168da271097d02.png"></p><h3 id="7、CRI-O"><a href="#7、CRI-O" class="headerlink" title="7、CRI-O"></a>7、CRI-O</h3><p><strong>CRI-O 是另一种高级别的容器运行时，也实现了 CRI。它作为 containerd 的替代选项，也通过底层容器运行时运行容器进程。</strong></p><ul><li>CRI-O 诞生于 Red Hat、IBM、Intel、SUSE 等大公司。</li><li>它就是专门作为 Kubernetes 容器运行时被打造的。</li></ul><h3 id="8、OCI"><a href="#8、OCI" class="headerlink" title="8、OCI"></a>8、OCI</h3><p><strong>OCI 是一组科技公司维护的规范，定义了容器镜像格式还有容器应该如何运行。</strong></p><p>OCI（Open Container Initiative）即开放的容器运行时<code>规范</code>，目的在于定义一个容器运行时及镜像的相关标准和规范，其中包括</p><ul><li>runtime-spec：容器的生命周期管理，具体参考<a href="https://github.com/opencontainers/runtime-spec/blob/master/runtime.md">runtime-spec</a>。</li><li>image-spec：镜像的生命周期管理，具体参考<a href="https://github.com/opencontainers/image-spec/blob/main/spec.md">image-spec</a>。</li></ul><p>实现OCI标准的容器运行时有<code>runc</code>，<code>kata</code>等。</p><p><img src="https://s2.loli.net/2023/08/18/WNiTGpHqQ7sxdbt.png" alt="oci-1.png"></p><p>OCI 对容器 runtime 的标准主要是指定容器的运行状态，和 runtime 需要提供的命令。下图可以是容器状态转换图：</p><p><img src="https://s2.loli.net/2023/08/18/QKAWrTw1Etf45vO.png" alt="oci-2.png"></p><ul><li>init 状态：这个是我自己添加的状态，并不在标准中，表示没有容器存在的初始状态</li><li>creating：使用 create 命令创建容器，这个过程称为创建中</li><li>created：容器创建出来，但是还没有运行，表示镜像和配置没有错误，容器能够运行在当前平台</li><li>running：容器的运行状态，里面的进程处于 up 状态，正在执行用户设定的任务</li><li>stopped：容器运行完成，或者运行出错，或者 stop 命令之后，容器处于暂停状态。这个状态，容器还有很多信息保存在平台中，并没有完全被删除</li></ul><h3 id="9、Containerd-shim"><a href="#9、Containerd-shim" class="headerlink" title="9、Containerd-shim"></a>9、Containerd-shim</h3><p><strong>containerd 并不直接调用 runc 去创建和运行容器，而是通过 containerd-shim 来进行。</strong></p><p>runc 创建完容器会直接退出，于是 containerd-shim 就成为容器的父进程，伴随容器的整个生命周期监控其运行状态。这样避免了 containerd 进程挂掉导致主机上的所有容器都退出。</p><h3 id="10、Runc"><a href="#10、Runc" class="headerlink" title="10、Runc"></a>10、Runc</h3><p><strong>runc 是一种 OCI 兼容的底层容器运行时。它实现了 OCI 规范并运行容器进程。</strong></p><p>runc 是 OCI 的<em>参考实现</em>。</p><blockquote><p>参考实现通常是第一个根据规范开发的软件。</p></blockquote><p>runc 为容器提供了所有底层功能：利用底层的 Linux 功能，例如命名空间和控制组。</p><p>runc 的几个替代选项：</p><ul><li><a href="https://github.com/containers/crun">crun</a>：C 编写的容器运行时（runc 是 Go 编写的）</li><li>KataContainer 项目的 <a href="https://github.com/kata-containers/kata-containers/tree/main/src/runtime">kata-runtime</a>：将 OCI 规范实现为轻量级的虚机</li><li>Google 的 <a href="https://gvisor.dev/">gVisor</a>：创建<em>有自己内核的容器</em>。它在自己的运行时 runsc 中实现 OCI。</li></ul><blockquote><p>runc 是在 Linux 上运行容器的工具；在 Windows 操作系统中则是微软的 Host Compute Service(HCS)，包括了一个叫 runhcs 的工具。</p></blockquote><p>在命令行中使用 runc，我们可以根据需要启动任意数量的容器。但是，如果我们想自动化这个过程，我们需要一个容器管理器。为什么这样?想象一下，我们需要启动数十个容器来跟踪它们的状态。其中一些需要在失败时重新启动，需要在终止时释放资源，必须从注册表中提取图像，需要配置容器间网络等等。就需要有Low-Level和High-Level容器运行时，runc就是Low-Level实现的实现。</p><h3 id="11、Low-Level和High-Level容器运行时"><a href="#11、Low-Level和High-Level容器运行时" class="headerlink" title="11、Low-Level和High-Level容器运行时"></a>11、Low-Level和High-Level容器运行时</h3><p>当人们想到容器运行时，可能会想到一系列示例;runc、lxc、lmctfy、Docker(容器)、rkt、cri-o。<br>这些中的每一个都是为不同的情况而构建的，并实现了不同的功能。有些，如 containerd 和 cri-o，实际上使用 runc 来运行容器，在High-Level实现镜像管理和 API。<br>与 runc 的Low-Level实现相比，可以将这些功能(包括镜像传输、镜像管理、镜像解包和 API)视为High-Level功能。考虑到这一点，您可以看到容器运行时空间相当复杂。每个运行时都涵盖了这个Low-Level到High-Level频谱的不同部分。<br>这是一个非常主观的图表：</p><p><img src="https://s2.loli.net/2023/08/18/xvOFHyViBe1I28l.png" alt="Low-Level和High-Level容器运行时.png"></p><p>因此，从实际出发，通常只专注于正在运行的容器的runtime通常称为“Low-Level容器运行时”，支持更多高级功能(如镜像管理和gRPC / Web API)的运行时通常称为“High-Level容器运行时”，“High-Level容器运行时”或通常仅称为“容器运行时”，我将它们称为“High-Level容器运行时”。<br>值得注意的是，Low-Level容器运行时和High-Level容器运行时是解决不同问题的、从根本上不同的事物。</p><h4 id="11-1、Low-Level容器运行时"><a href="#11-1、Low-Level容器运行时" class="headerlink" title="11.1、Low-Level容器运行时"></a>11.1、Low-Level容器运行时</h4><p>容器是通过Linux nanespace和Cgroups实现的，Namespace能让你为每个容器提供虚拟化系统资源，像是文件系统和网络，Cgroups提供了限制每个容器所能使用的资源的如内存和CPU使用量的方法。在最低级别的运行时中，容器运行时负责为容器建立namespaces和cgroups,然后在其中运行命令，Low-Level容器运行时支持在容器中使用这些操作系统特性。</p><p>目前来看低级容器运行时有：</p><ul><li><p>runc ：我们最熟悉也是被广泛使用的容器运行时，代表实现Docker。</p></li><li><p>runv：runV 是一个基于虚拟机管理程序(OCI)的运行时。它通过虚拟化 guest kernel，将容器和主机隔离开来，使得其边界更加清晰，这种方式很容易就能帮助加强主机和容器的安全性。代表实现是kata和Firecracker。</p></li><li><p>runsc：runsc = runc + safety ，典型实现就是谷歌的gvisor，通过拦截应用程序的所有系统调用，提供安全隔离的轻量级容器运行时沙箱。截止目前，貌似并不没有生产环境使用案例。</p></li><li><p>wasm : Wasm的沙箱机制带来的隔离性和安全性，都比Docker做的更好。但是wasm 容器处于草案阶段，距离生产环境尚有很长的一段路。</p></li></ul><h4 id="11-2、High-Level容器运行时"><a href="#11-2、High-Level容器运行时" class="headerlink" title="11.2、High-Level容器运行时"></a>11.2、High-Level容器运行时</h4><p>通常情况下，开发人员想要运行一个容器不仅仅需要Low-Level容器运行时提供的这些特性同时也需要与镜像格式、镜像管理和共享镜像相关的API接口和特性，而这些特性一般由High-Level容器运行时提供。<br>就日常使用来说，Low-Level容器运行时提供的这些特性可能满足不了日常所需，因为这个缘故，唯一会使用Low-Level容器运行时的人是那些实现High-Level容器运行时以及容器工具的开发人员。<br>那些实现Low-Level容器运行时的开发者会说High-Level容器运行时比如containerd和cri-o不像真正的容器运行时，因为从他们的角度来看，他们将容器运行的实现外包给了runc。但是从用户的角度来看，它们只是提供容器功能的单个组件，可以被另一个的实现替换，因此从这个角度将其称为runtime仍然是有意义的。即使containerd和cri-o都使用runc，但是它们是截然不同的项目，支持的特性也是非常不同的。</p><p>dockershim, containerd 和cri-o都是遵循CRI的容器运行时，我们称他们为高层级运行时(High-level Runtime)。</p><p>Kubernetes 只需支持 containerd 等high-level container runtime即可。由containerd 按照OCI 规范去对接不同的low-level container runtime，比如通用的runc，安全增强的gvisor，隔离性更好的runv。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h2&gt;&lt;p&gt;在学习K8S的过程中，会经常看到runc，cri，containerd容器运行时这些名词，必须弄清楚了，才能对K8S的架构又</summary>
      
    
    
    
    <category term="学习笔记" scheme="https://www.langxw.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="Kubernetes" scheme="https://www.langxw.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Kubernetes/"/>
    
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>ES集群搭建-K8s环境</title>
    <link href="https://www.langxw.com/2023/08/18/ES%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-K8s%E7%8E%AF%E5%A2%83/"/>
    <id>https://www.langxw.com/2023/08/18/ES%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-K8s%E7%8E%AF%E5%A2%83/</id>
    <published>2023-08-18T01:42:56.000Z</published>
    <updated>2023-08-18T01:49:53.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p><strong>ES集群上K8s，主要解决横向扩展复杂的问题，次要可以节约一定的成本。</strong></p><p>通过更改StatefulSet的副本数，可以有序横向扩展ES集群，并通过集群自动平衡数据的方法，将数据迁移到新加入的节点。</p><h2 id="二、预备环境"><a href="#二、预备环境" class="headerlink" title="二、预备环境"></a>二、预备环境</h2><ol><li><p>阿里云ASK集群：版本1.22.15-aliyun.1</p></li><li><p>ES集群：版本 elasticsearch:6.3.2</p></li><li><p>存储：阿里云SSD云盘</p></li></ol><h2 id="三、架构"><a href="#三、架构" class="headerlink" title="三、架构"></a>三、架构</h2><p><strong>部署在阿里云ASK集群的statefulset，不存在资源竞争</strong></p><ul><li><p>方案1（正常方案）：master节点3个，data节点N个。</p></li><li><p>方案2（简单粗暴）：初始3个节点，所有节点都是master节点和node节点；后续扩容不用在意discovery，保持master是初期节点即可。（<strong>本例采用</strong>）</p></li></ul><h2 id="四、部署步骤"><a href="#四、部署步骤" class="headerlink" title="四、部署步骤"></a>四、部署步骤</h2><h3 id="1、全部所需yaml文件预览"><a href="#1、全部所需yaml文件预览" class="headerlink" title="1、全部所需yaml文件预览"></a>1、全部所需yaml文件预览</h3><pre><code class="bash">create-ns.yaml             # 命名空间mhw-es-headless-svc.yaml   # 通过headless-svc配置es集群域名mhw-storage-class.yaml     # 动态存储卷mhw-es-statefulset.yaml    # 有状态应用ESmhw-es-svc.yaml            # LoadBalance类型的svc，作为集群入口mhw-kibana.yaml            # kibana</code></pre><h3 id="2、创建elasticsearch命名空间"><a href="#2、创建elasticsearch命名空间" class="headerlink" title="2、创建elasticsearch命名空间"></a>2、创建elasticsearch命名空间</h3><p>新建<strong>create-ns.yaml</strong></p><pre><code class="yaml">apiVersion: v1kind: Namespacemetadata:  name: elasticsearch  labels:    name: elasticsearch</code></pre><p>说明：创建专属的namespace和业务应用网络隔离，资源隔离。</p><h3 id="3、创建headless类型的svc"><a href="#3、创建headless类型的svc" class="headerlink" title="3、创建headless类型的svc"></a>3、创建headless类型的svc</h3><p>新建<strong>mhw-es-headless-svc.yaml</strong></p><pre><code class="yaml">kind: ServiceapiVersion: v1metadata:  name: mhw-es-svc  namespace: elasticsearchspec:  selector:    app: mhw-es   clusterIP: None  ports:  - name: rest # 节点与外部通信端口    port: 9200  - name: inter-node # 节点内部通信端口    port: 9300</code></pre><p>说明：有状态应用通过headless-svc所确定的域名来相互通信。</p><h3 id="4、创建动态存储卷storageclass"><a href="#4、创建动态存储卷storageclass" class="headerlink" title="4、创建动态存储卷storageclass"></a>4、创建动态存储卷storageclass</h3><p>新建<strong>mhw-storage-class.yaml</strong></p><pre><code class="yaml">apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  name: alicloud-disk-ssd-esprovisioner: diskplugin.csi.alibabacloud.comparameters:  type: cloud_ssd  fstype: ext4  resourceGroupId: &quot;rg-aek2q6kagvjz2zq&quot;volumeBindingMode: Immediate # 立即绑定，非延迟绑定reclaimPolicy: Delete # 保留策略，不保留，删除pvc的时候删除云盘allowVolumeExpansion: false # 是否动态扩展</code></pre><p>说明：数据存储采用云盘，云盘可以选择类型和IOPS，就是按量付费可能略贵。具体参数见文档：[使用阿里云云盘动态存储卷](<a href="https://help.aliyun.com/document_detail/134859.html?spm=a2c4g.134767.0.0.fe0e2b5aEvth5d">使用云盘动态存储卷 (aliyun.com)</a>)</p><h3 id="5、创建有状态应用ES"><a href="#5、创建有状态应用ES" class="headerlink" title="5、创建有状态应用ES"></a>5、创建有状态应用ES</h3><p>新建<strong>mhw-es-statefulset.yaml</strong></p><pre><code class="yaml">apiVersion: apps/v1kind: StatefulSetmetadata:  name: mhw-es-cluster # statefuleSet的名称  namespace: elasticsearch # 所属命名空间spec:  serviceName: mhw-es-svc # headless-svc的名称  selector:    matchLabels:      app: mhw-es  replicas: 3 # 3个节点  template:    metadata:      labels:        app: mhw-es # es容器标签      annotations:        k8s.aliyun.com/eci-use-specs : &quot;2-8Gi&quot; # 实例配置    spec:      containers:      - name: mhw-es # es容器名称        image: registry-vpc.cn-beijing.aliyuncs.com/zuhaowan-tools/elasticsearch:6.3.2        resources: # 分配的资源          requests:            cpu: 2            memory: 8Gi          limits:             cpu: 2            memory: 8Gi        livenessProbe:           tcpSocket:            port: 9200          initialDelaySeconds: 40          timeoutSeconds: 5          periodSeconds: 5        ports:        - containerPort: 9200          name: rest          protocol: TCP        - name: inter-node          containerPort: 9300          protocol: TCP        volumeMounts: # 数据卷挂载        - name: data          mountPath: /usr/share/elasticsearch/data        env:        - name: TZ # 时区设置          value: Asia/Shanghai        - name: cluster.name # ES集群名称          value: mhw-cluster        - name: node.name # ES节点名称，来自有状态应用自身名字          valueFrom:            fieldRef:              fieldPath: metadata.name        - name: discovery.zen.ping.unicast.hosts # 自动发现种子节点列表，用于后期选主节点          value: &quot;mhw-es-cluster-0.mhw-es-svc,mhw-es-cluster-1.mhw-es-svc,mhw-es-cluster-2.mhw-es-svc&quot;        - name: discovery.zen.minimum_master_nodes # 防止脑裂的配置          value: &quot;2&quot;        - name: ES_JAVA_OPTS # Java堆内存          value: &quot;-Xms4g -Xmx4g&quot;        - name: network.host           value: &quot;0.0.0.0&quot;        - name: http.cors.allow-origin          value: &quot;*&quot;        - name: http.cors.enabled          value: &quot;true&quot;        - name: http.max_initial_line_length          value: &quot;8k&quot;        - name: http.max_header_size          value: &quot;16k&quot;        - name: bootstrap.memory_lock # 内存锁定          value: &quot;false&quot;      initContainers: # init容器解决es数据目录权限问题      - name: fix-permissions        image: busybox        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;]        volumeMounts: # es数据目录挂载路径          - name:  data            mountPath:  /usr/share/elasticsearch/data  volumeClaimTemplates:  # PVC模版，使用storageclass动态创建pv  - metadata:      name: data    spec:      accessModes: [ &quot;ReadWriteOnce&quot; ] # 单节点读写      storageClassName: alicloud-disk-ssd-es      resources:        requests:          storage: 50Gi # 创建云盘的大小</code></pre><p>说明：</p><ul><li><p>ES6集群不需要配置集群初始化时引导选择主节点的配置，所以这个配置cluster.initial_master_nodes 可以不写。</p></li><li><p>这个集群三个节点默认都是master和data节点。</p></li><li><p>discovery.zen.ping.unicast.hosts 只在最开始配置三个节点即可，后续节点不用再添加进来，永远使用这三个选一个当主节点的意思。</p></li><li><p>注意指定时区</p></li></ul><h3 id="6、创建ES集群入口SLB"><a href="#6、创建ES集群入口SLB" class="headerlink" title="6、创建ES集群入口SLB"></a>6、创建ES集群入口SLB</h3><p>创建<strong>mhw-es-svc.yaml</strong></p><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  annotations: # 创建按量付费的SLB    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-connect-port: &#39;9200&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-flag: &#39;on&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-interval: &#39;3&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-type: tcp    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-healthy-threshold: &#39;4&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-scheduler: wlc    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-instance-charge-type: &quot;PayByCLCU&quot;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-unhealthy-threshold: &#39;4&#39;    service.beta.kubernetes.io/alicloud-loadbalancer-address-type: intranet    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-name: &quot;mhw-es&quot;  name: mhw-es-svc-slb  namespace: elasticsearch spec:  ports:    - name: http      port: 9200       protocol: TCP      targetPort: 9200   selector:    app: mhw-es  type: LoadBalancer</code></pre><p>说明：因为本实例中ES集群和业务应用分属于不同namespace，网络隔离了，通过headless-svc名称无法访问通。所以需要一个集群外的访问入口，这里使用私网SLB。</p><h3 id="7、创建Kibana"><a href="#7、创建Kibana" class="headerlink" title="7、创建Kibana"></a>7、创建Kibana</h3><p>创建<strong>mhw-kibana.yaml</strong></p><pre><code class="yaml">apiVersion: apps/v1kind: Deploymentmetadata:  name: mhw-kibana-deployment  namespace: elasticsearch  labels:    app: mhw-kibanaspec:  minReadySeconds: 15  replicas: 1  selector:    matchLabels:      app: mhw-kibana  template:    metadata:      labels:        app: mhw-kibana      annotations:        k8s.aliyun.com/eci-use-specs : &quot;1-2Gi&quot;    spec:      terminationGracePeriodSeconds: 40      containers:      - name: mhw-kibana        image: registry-vpc.cn-beijing.aliyuncs.com/zuhaowan-tools/kibana:6.3.2        ports:        - containerPort: 5601        resources:          requests:            cpu: 1            memory: 2Gi          limits:             cpu: 1            memory: 2Gi        livenessProbe:          tcpSocket:            port: 5601          initialDelaySeconds: 40          timeoutSeconds: 5          periodSeconds: 5        env:        - name: TZ # 时区          value: &quot;Asia/Shanghai&quot;        - name: ELASTICSEARCH_URL # ES集群的地址          value: &quot;http://mhw-es-svc:9200&quot;        - name: XPACK.MONITORING.UI.CONTAINER.ELASTICSEARCH.ENABLED # 关闭x-pack          value: &quot;false&quot;        - name: I18N.DEFAULTLOCALE # 本地化          value: &quot;zh-CN&quot;      imagePullSecrets:                - name: zhw-user-secret</code></pre><p>说明：</p><ul><li><p>注意连接ES集群地址的变量配置即可，ES6和ES7可能不一样。</p></li><li><p>可以直接使用容器IP或者创建nodeport和loadblance类型的svc来访问kibana。</p></li><li><p>本例是部署在ASK集群，集群内网是打通的，故直接使用容器IP访问Kibana。</p></li></ul><h2 id="五、遇到的问题"><a href="#五、遇到的问题" class="headerlink" title="五、遇到的问题"></a>五、遇到的问题</h2><h3 id="1、交换分区memory-lock问题"><a href="#1、交换分区memory-lock问题" class="headerlink" title="1、交换分区memory_lock问题"></a>1、交换分区memory_lock问题</h3><p>在ES的配置文件中，官方建议不使用交换分区（使用交换分区会使ES性能急剧下降），将bootstrap.memory_lock设置为true，或者最本质方法彻底禁用交换内存。</p><p>在本例中，ASK集群的底层是ECI主机，默认交换分区是禁用的（阿里云ECS交换分区默认也是禁用的）。故可以在配置文件中将bootstrap.memory_lock设置为false。</p><h3 id="2、缩容PVC释放问题"><a href="#2、缩容PVC释放问题" class="headerlink" title="2、缩容PVC释放问题"></a>2、缩容PVC释放问题</h3><ul><li><p>缩容的时候PVC默认是保留的，同样对应的PV和云盘都是保留的。</p></li><li><p>上面storageclass设置的PVC删除的时候PV和云盘是同时删除的。</p></li><li><p>基于以上，如果确认不再使用对应的PVC（存储），需要手动删除，云盘会立刻释放。</p></li></ul><h3 id="3、版本问题"><a href="#3、版本问题" class="headerlink" title="3、版本问题"></a>3、版本问题</h3><ul><li><p>以上是基于ES6部署的配置文件，如果是ES7或者ES8集群，可能会有所差别。</p></li><li><p>以上是基于阿里云ASK集群，如果是阿里云ACK集群（普通K8s集群），yaml文件可能有差别。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;ES集群上K8s，主要解决横向扩展复杂的问题，次要可以节约一定的成本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="ES" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/ES/"/>
    
    
    <category term="es" scheme="https://www.langxw.com/tags/es/"/>
    
  </entry>
  
  <entry>
    <title>Nacos集群搭建-K8s环境</title>
    <link href="https://www.langxw.com/2022/07/04/Nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-K8s%E7%8E%AF%E5%A2%83/"/>
    <id>https://www.langxw.com/2022/07/04/Nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-K8s%E7%8E%AF%E5%A2%83/</id>
    <published>2022-07-04T07:44:51.000Z</published>
    <updated>2022-07-04T07:45:54.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、预备环境"><a href="#一、预备环境" class="headerlink" title="一、预备环境"></a>一、预备环境</h2><ol><li>阿里云ASK集群 k8s版本：1.20.4-aliyun.1</li><li> nacos镜像：nacos/nacos-server:v2.0.3</li></ol><h2 id="二、流程图"><a href="#二、流程图" class="headerlink" title="二、流程图"></a>二、流程图</h2><pre class="mermaid">graph LRA[集群外部SLB] --> B[阿里云 Ingress] --> C[headless-Svc] --> D[statefulSet-Pod] --> E[MySQL]F[集群内部FQDN] --> CD --> G[PVC数据持久化]</pre><p>说明：</p><ul><li>集群入口：外部入口是SLB，主要是后台管理；内部入口是headless-svc的FQDN域名，内部服务间通信。</li><li>集群数据持久化：可以采用NAS，CEPH。如果不太关注落地数据，可以不需要，此篇文档就没有配置PVC。</li><li>如果不太想用Ingress，可以用LoadBlance类型的Service替代Ingress，只管理界面用途可以这么做。</li></ul><h2 id="三、搭建步骤"><a href="#三、搭建步骤" class="headerlink" title="三、搭建步骤"></a>三、搭建步骤</h2><h3 id="1、全部所需yaml文件概览"><a href="#1、全部所需yaml文件概览" class="headerlink" title="1、全部所需yaml文件概览"></a>1、全部所需yaml文件概览</h3><pre><code class="bash">nacos-k8s-cm.yamlnacos-k8s-headless-svc.yamlnacos-k8s-stateful.yamlnacos-k8s-svc.yaml                #可不用nginx_ingress_svc.yamlnginx_ingress.yaml</code></pre><h3 id="2、创建Config-Map数据库信息"><a href="#2、创建Config-Map数据库信息" class="headerlink" title="2、创建Config-Map数据库信息"></a>2、创建Config-Map数据库信息</h3><p>新建nacos-k8s-cm.yaml文件，并写入以下内容：</p><pre><code class="yaml">apiVersion: v1kind: ConfigMapmetadata:  name: nacos-cm  namespace: zhwdata:  mysql.host: &quot;xxxxxxx.mysql.rds.aliyuncs.com&quot;  mysql.db.name: &quot;nacos_cluster&quot;  mysql.port: &quot;3306&quot;  mysql.user: &quot;nacos&quot;  mysql.password: &quot;XN5lqwtnl8jUbWsu&quot;</code></pre><h3 id="3、创建Headless-Service"><a href="#3、创建Headless-Service" class="headerlink" title="3、创建Headless Service"></a>3、创建Headless Service</h3><p>新建nacos-k8s-headless-svc.yaml文件，并写入以下内容</p><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  name: nacos-headless  namespace: zhw  labels:    app: nacos-headlessspec:  type: ClusterIP  clusterIP: None  ports:    - port: 8848       name: server      targetPort: 8848    - port: 9848      name: client-rpc      targetPort: 9848    - port: 9849      name: raft-rpc      targetPort: 9849      ## 兼容1.4.x版本的选举端口    - port: 7848      name: old-raft-rpc      targetPort: 7848  selector:    app: nacos</code></pre><h3 id="4、创建StatefulSet有状态Pod"><a href="#4、创建StatefulSet有状态Pod" class="headerlink" title="4、创建StatefulSet有状态Pod"></a>4、创建StatefulSet有状态Pod</h3><p>新建nacos-k8s-stateful.yaml文件，并写入以下内容：</p><pre><code class="yaml">apiVersion: apps/v1kind: StatefulSetmetadata:  name: nacos  namespace: zhw  labels:    app: nacosspec:  # 上一步中headless-svc的名字  serviceName: nacos-headless  # nacos集群必须是三个节点  replicas: 3  selector:    matchLabels:      app: nacos  template:    metadata:      labels:        app: nacos      annotations:        # 阿里云ASK申请ECI的配置，可以忽略        k8s.aliyun.com/eci-use-specs : &quot;2-4Gi&quot;    spec:      affinity:        podAntiAffinity:          requiredDuringSchedulingIgnoredDuringExecution:            - labelSelector:                matchExpressions:                  - key: &quot;app&quot;                    operator: In                    values:                      - nacos              topologyKey: &quot;kubernetes.io/hostname&quot;      containers:        - name: nacos          imagePullPolicy: Always          image: nacos/nacos-server:v2.0.3           resources:            requests:              memory: &quot;4Gi&quot;              cpu: &quot;2&quot;          ports:            - containerPort: 8848              name: client            - containerPort: 9848              name: client-rpc            - containerPort: 9849              name: raft-rpc            - containerPort: 7848              name: old-raft-rpc          livenessProbe:            tcpSocket:              port: 8848            periodSeconds: 10            initialDelaySeconds: 30          readinessProbe:            tcpSocket:              port: 8848            initialDelaySeconds: 30            timeoutSeconds: 5            periodSeconds: 5          env:            - name: MYSQL_SERVICE_DB_PARAM              value: &quot;characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useSSL=false&quot;            - name: NACOS_REPLICAS              value: &quot;3&quot;            - name: MYSQL_SERVICE_HOST              valueFrom:                configMapKeyRef:                  name: nacos-cm                  key: mysql.host            - name: MYSQL_SERVICE_DB_NAME              valueFrom:                configMapKeyRef:                  name: nacos-cm                  key: mysql.db.name            - name: MYSQL_SERVICE_PORT              valueFrom:                configMapKeyRef:                  name: nacos-cm                  key: mysql.port            - name: MYSQL_SERVICE_USER              valueFrom:                configMapKeyRef:                  name: nacos-cm                  key: mysql.user            - name: MYSQL_SERVICE_PASSWORD              valueFrom:                configMapKeyRef:                  name: nacos-cm                  key: mysql.password            - name: MODE              value: &quot;cluster&quot;            - name: NACOS_SERVER_PORT              value: &quot;8848&quot;            - name: PREFER_HOST_MODE              value: &quot;hostname&quot;            - name: NACOS_SERVERS              # 集群的主机配置，这个value必须写对，格式为FQDN形式，pod-编号.headless-svc的名字.命名空间.svc.cluster.local:8848              value: &quot;nacos-0.nacos-headless.zhw.svc.cluster.local:8848 nacos-1.nacos-headless.zhw.svc.cluster.local:8848 nacos-2.nacos-headless.zhw.svc.cluster.local:8848&quot;</code></pre><p><strong>以上三步完成后，整个nacos集群基本已经就绪，应用可以使用headless-svc的域名<code>nacos-headless.zhw.svc.cluster.local</code>和nacos集群通信。如果想访问管理界面，就需要创建Ingress SLB或者LB类型的Service。</strong></p><h3 id="5、创建Ingress"><a href="#5、创建Ingress" class="headerlink" title="5、创建Ingress"></a>5、创建Ingress</h3><p>安装完ingress组件后，即可创建ingress规则文件nginx-ingress.yaml</p><pre><code class="yaml">apiVersion: extensions/v1beta1 kind: Ingressmetadata:  name: nacos-ingress  namespace: zhwspec:  rules:  # 配置七层域名。  - host: test.nacos.com    http:      paths:      # 配置Context Path。      - path: /        backend:          serviceName: nacos-headless          servicePort: 8848 </code></pre><p><strong>根据具体情况，可继续添加9848、9849等端口。</strong></p><h3 id="6、创建-ingress-lb-svc"><a href="#6、创建-ingress-lb-svc" class="headerlink" title="6、创建 ingress-lb-svc"></a>6、创建 ingress-lb-svc</h3><p>先手动创建好阿里云内网SLB，然后创建nginx-ingress-svc.yaml文件</p><pre><code class="yaml">#nginx ingress slb serviceapiVersion: v1kind: Servicemetadata:  name: nginx-ingress-lb  namespace: kube-system   labels:    app: nginx-ingress-lb  annotations:    # 指明SLB实例地址类型为私网类型。    service.beta.kubernetes.io/alicloud-loadbalancer-address-type: intranet    # 修改为您的私网SLB实例ID,事先创建好的slb。    service.beta.kubernetes.io/alicloud-loadbalancer-id: lb-2zev3l6hna765zkfi94ru     # 是否自动创建SLB端口监听（会覆写已有端口监听），也可手动创建端口监听。    service.beta.kubernetes.io/alicloud-loadbalancer-force-override-listeners: &#39;true&#39;spec:  type: LoadBalancer  # route traffic to other nodes  externalTrafficPolicy: &quot;Cluster&quot;  ports:  - port: 80    name: http    targetPort: 80  - port: 443    name: https    targetPort: 443  selector:    # select app=ingress-nginx pods    app: ingress-nginx</code></pre><p><strong>注意：这里的SLB既作为管理界面的入口，也可以作为Nacos集群的一个入口配置到各个服务的配置文件中，需要加上9848、9849等端口。</strong></p><h3 id="7、创建LB类型的Service"><a href="#7、创建LB类型的Service" class="headerlink" title="7、创建LB类型的Service"></a>7、创建LB类型的Service</h3><p>创建nacos-k8s-svc.yaml 文件，并写入以下内容：</p><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  annotations:    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-connect-port: &#39;8848&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-flag: &#39;on&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-interval: &#39;3&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-health-check-type: tcp    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-healthy-threshold: &#39;4&#39;    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-scheduler: wlc    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-spec: slb.s1.small    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-unhealthy-threshold: &#39;4&#39;    service.beta.kubernetes.io/alicloud-loadbalancer-address-type: intranet  name: nacos-svc  namespace: zhwspec:  ports:    - name: http      port: 80      protocol: TCP      targetPort: 8848  selector:    app: nacos  type: LoadBalancer</code></pre><p>在不想使用Ingress的情况下，可以用LB的类型SVC来创建一个管理入口。但是这个只建议做管理入口，不建议做集群入口。</p><h2 id="四、参考信息"><a href="#四、参考信息" class="headerlink" title="四、参考信息"></a>四、参考信息</h2><ul><li><a href="https://github.com/nacos-group/nacos-k8s">官方文档</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、预备环境&quot;&gt;&lt;a href=&quot;#一、预备环境&quot; class=&quot;headerlink&quot; title=&quot;一、预备环境&quot;&gt;&lt;/a&gt;一、预备环境&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;阿里云ASK集群 k8s版本：1.20.4-aliyun.1&lt;/li&gt;
&lt;li&gt; nacos镜像</summary>
      
    
    
    
    <category term="中间件" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="Nacos" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Nacos/"/>
    
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
    <category term="nacos" scheme="https://www.langxw.com/tags/nacos/"/>
    
  </entry>
  
  <entry>
    <title>Kube-prometheus添加自定义监控项</title>
    <link href="https://www.langxw.com/2022/04/19/Kube-prometheus%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E9%A1%B9/"/>
    <id>https://www.langxw.com/2022/04/19/Kube-prometheus%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E9%A1%B9/</id>
    <published>2022-04-19T05:57:02.000Z</published>
    <updated>2022-04-19T06:22:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>本文档题目也可叫做，<strong>kube-prometheus添加target</strong>。</p><p>公司有个canal项目想接入prometheus进行监控告警，从<a href="https://github.com/alibaba/canal/wiki/Prometheus-QuickStart">canal官档</a>介绍看到只需配置prometheus.yaml添加canal的job后重启服务，即可将canal接入prometheus监控。</p><p>官档介绍的是非容器部署的prometheus，鉴于我司有k8s环境，我就想将canal接入k8s集群的prometheus监控。</p><h2 id="二、部署步骤（自建K8S的Prometheus）"><a href="#二、部署步骤（自建K8S的Prometheus）" class="headerlink" title="二、部署步骤（自建K8S的Prometheus）"></a>二、部署步骤（自建K8S的Prometheus）</h2><h3 id="1、Exporter介绍"><a href="#1、Exporter介绍" class="headerlink" title="1、Exporter介绍"></a>1、Exporter介绍</h3><p>一般来讲向Prometheus提供监控样本数据的程序都可以被称为一个Exporter，Exporter的一个实例称为Target。Prometheus通过轮询的方式定时从这些Target中获取监控数据样本，并且存储在数据库当中。</p><p><a href="https://imgtu.com/i/LdOyEF"><img src="https://s1.ax1x.com/2022/04/18/LdOyEF.png" alt="LdOyEF.png"></a></p><h4 id="1-1-Exporter按来源分类"><a href="#1-1-Exporter按来源分类" class="headerlink" title="1.1 Exporter按来源分类"></a>1.1 Exporter按来源分类</h4><ul><li><p><strong>社区提供的</strong>：比如Node Exporter、MySQL Exporter、Nginx Exporter等</p><table><thead><tr><th align="center">范围</th><th align="center">常用Exporter</th></tr></thead><tbody><tr><td align="center">数据库</td><td align="center">MySQL Exporter, Redis Exporter,  MongoDB Exporter, MSSQL Exporter等</td></tr><tr><td align="center">硬件</td><td align="center">Apcupsd Exporter，IoT Edison  Exporter， IPMI Exporter, Node Exporter等</td></tr><tr><td align="center">消息队列</td><td align="center">Beanstalkd Exporter, Kafka  Exporter, NSQ Exporter, RabbitMQ Exporter等</td></tr><tr><td align="center">存储</td><td align="center">Ceph Exporter, Gluster Exporter,  HDFS Exporter, ScaleIO Exporter等</td></tr><tr><td align="center">HTTP服务</td><td align="center">Apache Exporter, HAProxy  Exporter, Nginx Exporter等</td></tr><tr><td align="center">API服务</td><td align="center">AWS ECS Exporter， Docker Cloud  Exporter, Docker Hub Exporter, GitHub Exporter等</td></tr><tr><td align="center">日志</td><td align="center">Fluentd Exporter, Grok Exporter等</td></tr><tr><td align="center">监控系统</td><td align="center">Collectd Exporter, Graphite  Exporter, InfluxDB Exporter, Nagios Exporter, SNMP Exporter等</td></tr><tr><td align="center">其它</td><td align="center">Blockbox Exporter, JIRA  Exporter, Jenkins Exporter， Confluence Exporter等</td></tr></tbody></table></li><li><p><strong>用户自定义的</strong>：用户还可以基于Prometheus提供的Client Library创建自己的Exporter程序。目前Promthues社区官方提供了对以下编程语言的支持：Go、Java/Scala、Python、Ruby。同时还有第三方实现的如：Bash、C++、Common Lisp、Erlang,、Haskeel、Lua、Node.js、PHP、Rust等。</p></li></ul><h4 id="1-2-Exporter按运行方式分类"><a href="#1-2-Exporter按运行方式分类" class="headerlink" title="1.2 Exporter按运行方式分类"></a>1.2 Exporter按运行方式分类</h4><ul><li><p><strong>独立使用的</strong></p><p>以我们已经使用过的Node Exporter为例，由于操作系统本身并不直接支持Prometheus，同时用户也无法通过直接从操作系统层面上提供对Prometheus的支持。因此，用户只能通过独立运行一个程序的方式，通过操作系统提供的相关接口，将系统的运行状态数据转换为可供Prometheus读取的监控数据。 除了Node Exporter以外，比如MySQL Exporter、Redis Exporter等都是通过这种方式实现的。 这些Exporter程序扮演了一个中间代理人的角色。</p></li><li><p><strong>集成到应用中的</strong></p><p>为了能够更好的监控系统的内部运行状态，有些开源项目如Kubernetes，ETCD等直接在代码中使用了Prometheus的Client Library，提供了对Prometheus的直接支持。这种方式打破的监控的界限，让应用程序可以直接将内部的运行状态暴露给Prometheus，适合于一些需要更多自定义监控指标需求的项目。</p><pre><code> **我要纳入监控的cannal项目，就属于集成到应用中的，直接访问http://ip:port即可拿到监控数据，不要部署代理Exporter程序。**</code></pre></li></ul><h3 id="2、部署Prometheus"><a href="#2、部署Prometheus" class="headerlink" title="2、部署Prometheus"></a>2、部署Prometheus</h3><h4 id="2-1-下载"><a href="#2-1-下载" class="headerlink" title="2.1 下载"></a>2.1 下载</h4><pre><code class="bash">git clone https://github.com/prometheus-operator/kube-prometheus.gitcd kube-prometheus</code></pre><h4 id="2-2-部署"><a href="#2-2-部署" class="headerlink" title="2.2 部署"></a>2.2 部署</h4><pre><code class="bash"># Create the namespace and CRDs, and then wait for them to be available before creating the remaining resourceskubectl apply --server-side -f manifests/setupuntil kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo &quot;&quot;; donekubectl apply -f manifests/</code></pre><p>部署成功后，结果如下（如果部署失败，可手动想办法更换镜像地址）：</p><pre><code class="bash">root@k8s-master001:~# kubectl get pods -n monitoringNAME                                  READY   STATUS    RESTARTS   AGEalertmanager-main-0                   2/2     Running   0          3d1halertmanager-main-1                   2/2     Running   0          3d1halertmanager-main-2                   2/2     Running   0          3d1hblackbox-exporter-5cb5d7479d-cqxrd    3/3     Running   0          3d1hgrafana-789bc4b4b8-wjk4j              1/1     Running   0          3d1hkube-state-metrics-79f478884f-w6mqw   3/3     Running   0          3d1hnode-exporter-cl42r                   2/2     Running   0          3d1hnode-exporter-f8n6n                   2/2     Running   0          3d1hnode-exporter-m4xqr                   2/2     Running   0          3d1hprometheus-adapter-7bf7ff5b67-gph5t   1/1     Running   0          3d1hprometheus-adapter-7bf7ff5b67-pppq2   1/1     Running   0          3d1hprometheus-k8s-0                      2/2     Running   0          3d1hprometheus-k8s-1                      2/2     Running   0          3d1hprometheus-operator-b998f8597-k75bm   2/2     Running   0          3d1h</code></pre><p>将Prometheus映射出去，可以在局域网（公网）访问：</p><pre><code class="bash">#!/bin/bashnohup kubectl --namespace monitoring port-forward --address 0.0.0.0 svc/prometheus-k8s 9090:9090 &amp;</code></pre><p>之后可以通过 http://内网IP:9090 访问Prometheus的dashboard。</p><h4 id="2-3-删除（根据需求）"><a href="#2-3-删除（根据需求）" class="headerlink" title="2.3 删除（根据需求）"></a>2.3 删除（根据需求）</h4><p><code>kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup</code></p><h3 id="3、添加target并应用到集群"><a href="#3、添加target并应用到集群" class="headerlink" title="3、添加target并应用到集群"></a>3、添加target并应用到集群</h3><h4 id="3-1-增加target"><a href="#3-1-增加target" class="headerlink" title="3.1 增加target"></a>3.1 增加target</h4><p>编写需要增加的target添加到prometheus-additional.yaml 文件里面，不存在就新建。</p><pre><code class="bash">cat &gt;&gt; ./kube-prometheus/manifests/prometheus-additional.yaml  &lt;&lt; EOF- job_name: &#39;canal&#39;  scrape_interval: 15s  scrape_timeout: 15s  static_configs:  - targets: [&#39;10.31.4.225:11112&#39;]EOF</code></pre><p>注释：根据实际情况，修改job_name和targets变量即可。</p><h4 id="3-2-创建新的secret并应用到prometheus"><a href="#3-2-创建新的secret并应用到prometheus" class="headerlink" title="3.2 创建新的secret并应用到prometheus"></a>3.2 创建新的secret并应用到prometheus</h4><pre><code class="bash">cd ./kube-prometheus/manifests/# 创建secretkubectl create secret generic additional-scrape-configs -n monitoring --from-file=prometheus-additional.yaml --dry-run=client -o yaml &gt; additional-scrape-configs.yaml# 应用到prometheuskubectl apply -f additional-scrape-configs.yaml -n monitoring</code></pre><h4 id="3-3-将target应用到集群"><a href="#3-3-将target应用到集群" class="headerlink" title="3.3 将target应用到集群"></a>3.3 将target应用到集群</h4><p>这一步类似于修改正常部署模式下的prometheus.yaml配置文件。</p><pre><code class="bash">vim kube-prometheus/manifests/prometheus-prometheus.yaml  additionalScrapeConfigs:    name: additional-configs    key: prometheus-additional.yaml</code></pre><p>具体添加位置如下：</p><p><a href="https://imgtu.com/i/L0NIDe"><img src="https://s1.ax1x.com/2022/04/19/L0NIDe.png" alt="L0NIDe.png"></a></p><p>应用变更到K8S生效：</p><pre><code class="bash">kubectl apply -f kube-prometheus/manifests/prometheus-prometheus.yaml -n monitoring</code></pre><h4 id="4、验证"><a href="#4、验证" class="headerlink" title="4、验证"></a>4、验证</h4><p>稍等片刻，查看prometheus的target列表即可，或者prometheus–&gt; Status–&gt;Configuration 中可以搜到job_name为canal的配置信息。</p><p><a href="https://imgtu.com/i/L0Urxf"><img src="https://s1.ax1x.com/2022/04/19/L0Urxf.png" alt="L0Urxf.png"></a></p><p>同时，我们上一步添加的Secret可以通过K8s集群查看到。</p><p><strong>以上的修改和添加，在Prometheus Operator项目的example/<a href="https://github.com/prometheus-operator/prometheus-operator/tree/main/example/additional-scrape-configs">additional-scrape-configs</a>中有一样的例子可供参考。</strong></p><h2 id="三、部署步骤（阿里云Prometheus）"><a href="#三、部署步骤（阿里云Prometheus）" class="headerlink" title="三、部署步骤（阿里云Prometheus）"></a>三、部署步骤（阿里云Prometheus）</h2><h3 id="1、部署"><a href="#1、部署" class="headerlink" title="1、部署"></a>1、部署</h3><p>需要监控部署在K8s集群之外的业务数据，如Redis连接数。操作步骤如下：</p><ol><li><p>在阿里云Prometheus监控服务控制台页面，选择相应地区的Prometheus实例。</p></li><li><p>在设置页面，单击<strong>Prometheus设置</strong>页签。</p></li><li><p>在Prometheus.yaml中输入以下内容，然后单击保存。</p><pre><code class="yaml">global:  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.scrape_configs:  - job_name: &#39;canal&#39;    static_configs:    - targets: [&#39;10.31.4.225:11112&#39;]</code></pre></li></ol><h3 id="2、验证"><a href="#2、验证" class="headerlink" title="2、验证"></a>2、验证</h3><p>在阿里云Prometheus监控服务页面，选择某个地区对应的实例后，选择客户端接入后，即可看到我们自定义接入的target。</p><p><a href="https://imgtu.com/i/L0wFPA"><img src="https://s1.ax1x.com/2022/04/19/L0wFPA.png" alt="L0wFPA.png"></a></p><h2 id="四、持久化数据存储"><a href="#四、持久化数据存储" class="headerlink" title="四、持久化数据存储"></a>四、持久化数据存储</h2><h3 id="4-1-根据需要调整持久化存储策略"><a href="#4-1-根据需要调整持久化存储策略" class="headerlink" title="4.1 根据需要调整持久化存储策略"></a>4.1 根据需要调整持久化存储策略</h3><ul><li><p>grafana和prometheus的数据都需要做持久存储。</p></li><li><p>grafana持久持久存储是因为可能安装些第三方的插件。</p></li><li><p>prometheus的持久存储，自不必多说，那是肯定需要的。</p></li></ul><p>我们部署在云上，持久化存储这块，可以很方便的使用他们提供的服务（NFS、OSS、aliyun-disk都可以）</p><h2 id="五、参考"><a href="#五、参考" class="headerlink" title="五、参考"></a>五、参考</h2><ul><li><p><a href="https://github.com/prometheus-operator/prometheus-operator">prometheus-operator项目</a></p></li><li><p><a href="https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/additional-scrape-config.md">添加自定义监控配置官方文档 Additional Scrape Configuration</a></p></li><li><p><a href="https://github.com/alibaba/canal/wiki/Prometheus-QuickStart">canal项目官方文档</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;本文档题目也可叫做，&lt;strong&gt;kube-prometheus添加target&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;公司有</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="k8s" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/k8s/"/>
    
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
    <category term="Prometheus" scheme="https://www.langxw.com/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>自建k8s使用阿里云存储插件csi</title>
    <link href="https://www.langxw.com/2022/03/22/%E8%87%AA%E5%BB%BAk8s%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E5%AD%98%E5%82%A8%E6%8F%92%E4%BB%B6csi/"/>
    <id>https://www.langxw.com/2022/03/22/%E8%87%AA%E5%BB%BAk8s%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E5%AD%98%E5%82%A8%E6%8F%92%E4%BB%B6csi/</id>
    <published>2022-03-22T05:01:45.000Z</published>
    <updated>2022-04-19T06:17:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>k8s在阿里云上使用，推荐还是使用阿里云的ack。无论是从稳定性，以及后期的维护来说，ack 都是最优的方案，自建k8s 阿里云不提供任何帮助，一旦集群出现问题（主要是网络问题）很难进行排查。</p><p>如果出于特殊原因，希望在阿里云上进行自建k8s当然也可以。<strong>自建k8s需要集成阿里云两个重要的插件cloud-controller-manager（负载均衡插件），csi(存储插件)。</strong>下面只介绍csi 存储插安装。</p><h2 id="二、部署"><a href="#二、部署" class="headerlink" title="二、部署"></a>二、部署</h2><h3 id="1、准备操作："><a href="#1、准备操作：" class="headerlink" title="1、准备操作："></a>1、准备操作：</h3><h4 id="1-1-自建k8s集群添加节点标签"><a href="#1-1-自建k8s集群添加节点标签" class="headerlink" title="1.1 自建k8s集群添加节点标签"></a>1.1 自建k8s集群添加节点标签</h4><ul><li>手动添加</li></ul><pre><code class="shell"># 获取providerIDMETA_EP=http://100.100.100.200/latest/meta-data &amp;&amp;echo `curl -s $META_EP/region-id`.`curl -s $META_EP/instance-id`# 打标签，注意修改node节点名称和providerIDkubectl patch node master1 -p &#39;&#123;&quot;spec&quot;:&#123;&quot;providerID&quot;: &quot;cn-zhangjiakou.i-8vbhy24ntae8zwo8zudn&quot;&#125;&#125;&#39;kubectl patch node master2 -p &#39;&#123;&quot;spec&quot;:&#123;&quot;providerID&quot;: &quot;cn-zhangjiakou.i-8vbhy24ntae8zwo8zudo&quot;&#125;&#125;&#39;kubectl patch node master3 -p &#39;&#123;&quot;spec&quot;:&#123;&quot;providerID&quot;: &quot;cn-zhangjiakou.i-8vbhy24ntae8zwo8zudr&quot;&#125;&#125;&#39;</code></pre><h4 id="1-2-配置CSI组建的RAM权限"><a href="#1-2-配置CSI组建的RAM权限" class="headerlink" title="1.2 配置CSI组建的RAM权限"></a>1.2 配置CSI组建的RAM权限</h4><ul><li><p>创建RAM用户 </p></li><li><p>创建并给予RAM用户自定义权限</p><pre><code class="json">&#123;    &quot;Version&quot;: &quot;1&quot;,    &quot;Statement&quot;: [        &#123;            &quot;Action&quot;: [                &quot;ecs:AttachDisk&quot;,                &quot;ecs:DetachDisk&quot;,                &quot;ecs:DescribeDisks&quot;,                &quot;ecs:CreateDisk&quot;,                &quot;ecs:ResizeDisk&quot;,                &quot;ecs:CreateSnapshot&quot;,                &quot;ecs:DeleteSnapshot&quot;,                &quot;ecs:CreateAutoSnapshotPolicy&quot;,                &quot;ecs:ApplyAutoSnapshotPolicy&quot;,                &quot;ecs:CancelAutoSnapshotPolicy&quot;,                &quot;ecs:DeleteAutoSnapshotPolicy&quot;,                &quot;ecs:DescribeAutoSnapshotPolicyEX&quot;,                &quot;ecs:ModifyAutoSnapshotPolicyEx&quot;,                &quot;ecs:AddTags&quot;,                &quot;ecs:DescribeTags&quot;,                &quot;ecs:DescribeSnapshots&quot;,                &quot;ecs:ListTagResources&quot;,                &quot;ecs:TagResources&quot;,                &quot;ecs:UntagResources&quot;,                &quot;ecs:ModifyDiskSpec&quot;,                &quot;ecs:CreateSnapshot&quot;,                &quot;ecs:DeleteDisk&quot;,                &quot;ecs:DescribeInstanceAttribute&quot;,                &quot;ecs:DescribeInstances&quot;            ],            &quot;Resource&quot;: [                &quot;*&quot;            ],            &quot;Effect&quot;: &quot;Allow&quot;        &#125;,        &#123;            &quot;Action&quot;: [                &quot;nas:DescribeFileSystems&quot;,                &quot;nas:DescribeMountTargets&quot;,                &quot;nas:AddTags&quot;,                &quot;nas:DescribeTags&quot;,                &quot;nas:RemoveTags&quot;,                &quot;nas:CreateFileSystem&quot;,                &quot;nas:DeleteFileSystem&quot;,                &quot;nas:ModifyFileSystem&quot;,                &quot;nas:CreateMountTarget&quot;,                &quot;nas:DeleteMountTarget&quot;,                &quot;nas:ModifyMountTarget&quot;,                &quot;nas:TagResources&quot;,                &quot;nas:SetDirQuota&quot;,                &quot;nas:EnableRecycleBin&quot;,                &quot;nas:GetRecycleBinAttribute&quot;            ],            &quot;Resource&quot;: [                &quot;*&quot;            ],            &quot;Effect&quot;: &quot;Allow&quot;        &#125;,        &#123;            &quot;Action&quot;: [                &quot;oss:PutBucket&quot;,                &quot;oss:GetObjectTagging&quot;,                &quot;oss:ListBuckets&quot;,                &quot;oss:PutBucketTags&quot;,                &quot;oss:GetBucketTags&quot;,                &quot;oss:PutBucketEncryption&quot;,                &quot;oss:GetBucketInfo&quot;            ],            &quot;Resource&quot;: [                &quot;*&quot;            ],            &quot;Effect&quot;: &quot;Allow&quot;        &#125;    ]&#125;</code></pre></li><li><p>为RAM用户创建AccessKsy。</p></li></ul><h3 id="2、安装CSI组件"><a href="#2、安装CSI组件" class="headerlink" title="2、安装CSI组件"></a>2、安装CSI组件</h3><p>  <strong>下载ACK相关组件，支持块存储、NAS和OSS</strong></p><h4 id="2-1-配置AK"><a href="#2-1-配置AK" class="headerlink" title="2.1 配置AK"></a>2.1 配置AK</h4><pre><code class="shell">kubectl -n kube-system create secret generic alibaba-addon-secret --from-literal=&#39;access-key-id=xxxxx&#39; --from-literal=&#39;access-key-secret=xxxxx&#39;</code></pre><h4 id="2-2-CSI插件下载"><a href="#2-2-CSI插件下载" class="headerlink" title="2.2 CSI插件下载"></a>2.2 CSI插件下载</h4><ul><li><p>阿里云csi插件<a href="https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver">地址</a>： <code>git clone https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver.git</code></p></li><li><p>rbac.yaml，csi-plugin.yaml，csi-provisioner.yaml 三个文件都需要。</p><pre><code class="shell">wget https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver/blob/master/deploy/rbac.yamlwget https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver/blob/master/deploy/ack/csi-plugin.yamlhttps://github.com/kubernetes-sigs/alibaba-cloud-csi-driver/blob/master/deploy/ack/csi-provisioner.yaml</code></pre><h4 id="2-3-编辑配置"><a href="#2-3-编辑配置" class="headerlink" title="2.3 编辑配置"></a>2.3 编辑配置</h4><p>在csi-plugin.yaml、csi-provisioner.yaml中添加如下env参数</p><pre><code class="yaml">          - name: ACCESS_KEY_ID            valueFrom:              secretKeyRef:                key: access-key-id                name: alibaba-addon-secret          - name: ACCESS_KEY_SECRET            valueFrom:              secretKeyRef:                key: access-key-secret                name: alibaba-addon-secret</code></pre><h4 id="2-4-部署rbac-yaml"><a href="#2-4-部署rbac-yaml" class="headerlink" title="2.4 部署rbac.yaml"></a>2.4 部署rbac.yaml</h4></li><li><p>部署 <code>kubectl  apply -f rbac.yaml</code></p></li><li><p>查看生成的 secrets 的csi token 名字 <code>kubectl get secrets -A |grep csi</code></p></li><li><p>替换两个csi*.yaml文件中secretName为上一步sc的名字，比如csi-admin-token-ssflh</p><h4 id="2-5-部署CSI"><a href="#2-5-部署CSI" class="headerlink" title="2.5 部署CSI"></a>2.5 部署CSI</h4><pre><code class="shell">kubectl apply -f csi-plugin.yamlkubectl apply -f csi-provisioner.yaml</code></pre><h4 id="2-6-查看部署情况"><a href="#2-6-查看部署情况" class="headerlink" title="2.6 查看部署情况"></a>2.6 查看部署情况</h4><p><code>kubectl get pods -A |grep csi</code></p></li></ul><h2 id="三、使用"><a href="#三、使用" class="headerlink" title="三、使用"></a>三、使用</h2><h3 id="1、创建StorageClass"><a href="#1、创建StorageClass" class="headerlink" title="1、创建StorageClass"></a>1、创建StorageClass</h3><p>SC已在csi-provisioner.yaml中创建成功。</p><h3 id="2、创建PVC"><a href="#2、创建PVC" class="headerlink" title="2、创建PVC"></a>2、创建PVC</h3><pre><code class="yaml">apiVersion: v1kind: PersistentVolumeClaimmetadata:  name: aliyun-csi-pvcspec:  accessModes:    - ReadWriteOnce  storageClassName: alicloud-disk-essd   resources:    requests:      storage: 20Gi</code></pre><p>然后执行<code>kubectl apply -f pvc.yaml</code></p><h3 id="3、创建Pod"><a href="#3、创建Pod" class="headerlink" title="3、创建Pod"></a>3、创建Pod</h3><pre><code class="yaml">apiVersion: v1 kind: Podmetadata:  name: nginx-aliyun-csispec:  containers:    - name: webserver      image: nginx      volumeMounts:        - name: mypvc          mountPath: /usr/share/nginx/html  volumes:    - name: mypvc      persistentVolumeClaim:        claimName: aliyun-csi-pvc        readOnly: false</code></pre><p>然后执行<code>kubectl apply -f nginx-pod.yaml</code></p><h3 id="4、查看创建情况"><a href="#4、查看创建情况" class="headerlink" title="4、查看创建情况"></a>4、查看创建情况</h3><pre><code class="she"># 查看pvc创建和绑定情况kubectl get pvc # 查看pod创建情况kubectl get pod</code></pre><h3 id="5、验证"><a href="#5、验证" class="headerlink" title="5、验证"></a>5、验证</h3><ul><li>登录阿里云控制台查看云盘创建和挂载情况</li><li>登录nginx-pod用<code>df -h &amp;&amp; fdisk -l &amp;&amp; mount</code> 等命令查看阿里云盘挂载情况</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h2&gt;&lt;p&gt;k8s在阿里云上使用，推荐还是使用阿里云的ack。无论是从稳定性，以及后期的维护来说，ack 都是最优的方案，自建k8s 阿</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="k8s" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/k8s/"/>
    
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
    <category term="csi-plugin" scheme="https://www.langxw.com/tags/csi-plugin/"/>
    
  </entry>
  
  <entry>
    <title>kubelet命令自动补全功能</title>
    <link href="https://www.langxw.com/2022/03/02/kubelet%E5%91%BD%E4%BB%A4%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E5%8A%9F%E8%83%BD/"/>
    <id>https://www.langxw.com/2022/03/02/kubelet%E5%91%BD%E4%BB%A4%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E5%8A%9F%E8%83%BD/</id>
    <published>2022-03-02T09:22:57.000Z</published>
    <updated>2022-03-02T09:28:12.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>我们在管理k8s集群的时候，避免不了使用kubectl命令工具，但是该命令还是挺复杂的，使用中也记不住那么多的api选项，故这里介绍一下kubectl命令补全工具的安装。</p><h2 id="二、实现"><a href="#二、实现" class="headerlink" title="二、实现"></a>二、实现</h2><h3 id="1、安装bash-completion"><a href="#1、安装bash-completion" class="headerlink" title="1、安装bash-completion"></a>1、安装bash-completion</h3><pre><code class="bash">yum install -y bash-completion source /usr/share/bash-completion/bash_completion</code></pre><h3 id="2、应用kubectl的completion到系统环境"><a href="#2、应用kubectl的completion到系统环境" class="headerlink" title="2、应用kubectl的completion到系统环境"></a>2、应用kubectl的completion到系统环境</h3><pre><code class="bash">source &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;我们在管理k8s集群的时候，避免不了使用kubectl命令工具，但是该命令还是挺复杂的，使用中也记不住那么多的api选项，故</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="k8s" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/k8s/"/>
    
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
    <category term="kubelet" scheme="https://www.langxw.com/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>K8S启用非安全内核参数</title>
    <link href="https://www.langxw.com/2022/02/21/K8S%E5%90%AF%E7%94%A8%E9%9D%9E%E5%AE%89%E5%85%A8%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0/"/>
    <id>https://www.langxw.com/2022/02/21/K8S%E5%90%AF%E7%94%A8%E9%9D%9E%E5%AE%89%E5%85%A8%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0/</id>
    <published>2022-02-21T10:03:19.000Z</published>
    <updated>2022-04-19T06:17:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>我司从云主机向k8s迁移的过程中，由于在云主机上对内核参数进行过优化，所以尽量想K8s也和云主机的内存参数保持一致。</p><h2 id="二、解决办法："><a href="#二、解决办法：" class="headerlink" title="二、解决办法："></a>二、解决办法：</h2><p><strong>k8s并不是支持所有的linux的内核参数，具体支持情况看k8s集群环境和参考<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/sysctl-cluster/">官方文档</a>。</strong></p><p><strong>实际设定还是结合产品自身用以下方式进行操作了，原则就是pod镜像系统里面进去看没有的就不能开启了，具体进容器里面看一下/proc/sys/的文件信息。</strong></p><h3 id="1、设置集群的PSP"><a href="#1、设置集群的PSP" class="headerlink" title="1、设置集群的PSP"></a>1、设置集群的PSP</h3><h4 id="1-1-解释"><a href="#1-1-解释" class="headerlink" title="1.1 解释"></a>1.1 解释</h4><p>可以通过在 PodSecurityPolicy 的 <code>forbiddenSysctls</code> 或 <code>allowedUnsafeSysctls</code> 字段中，指定sysctl 或填写 sysctl 匹配模式来进一步为 Pod 设置 sysctl 参数。 sysctl 参数匹配模式以 <code>*</code> 字符结尾，如 <code>kernel.*</code>。 单独的 <code>*</code> 字符匹配所有 sysctl 参数。</p><p>以下示例设置启用了以 <code>kernel.msg</code> 为前缀的非安全的 sysctl 参数，同时禁用了 sysctl 参数 <code>kernel.shm_rmid_forced</code>。</p><pre><code class="yaml">apiVersion: policy/v1beta1kind: PodSecurityPolicymetadata:  name: sysctl-pspspec:  allowedUnsafeSysctls:  - kernel.msg*  forbiddenSysctls:  - kernel.shm_rmid_forced ...</code></pre><h4 id="1-2-具体操作"><a href="#1-2-具体操作" class="headerlink" title="1.2 具体操作"></a>1.2 具体操作</h4><ol><li><p>通过<code>kubectl describe PodSecurityPolicy  </code>查询psp内容，看是否有内核参数的相关内容</p></li><li><p>通过<code>kubectl edit PodSecurityPolicy  </code> 修改psp内容，加入allowed的内核参数的配置</p></li><li><p>再次查询psp的内容，确认修改是否生效。</p></li></ol><h3 id="2、启用非安全的sysctl参数"><a href="#2、启用非安全的sysctl参数" class="headerlink" title="2、启用非安全的sysctl参数"></a>2、启用非安全的sysctl参数</h3><h4 id="2-1-解释"><a href="#2-1-解释" class="headerlink" title="2.1 解释"></a>2.1 解释</h4><p><strong>所有的安全sysctl参数都默认启用。</strong></p><p>集群管理员只有在一些非常特殊的情况下（如：高可用或实时应用调整）， 才可以启用特定的 <em>非安全的</em> sysctl 参数。 如需启用 <em>非安全的</em> sysctl 参数，请你在每个节点上分别设置 kubelet 命令行参数。例如：</p><pre><code class="shell">kubelet --allowed-unsafe-sysctls \  &#39;kernel.msg*,net.core.somaxconn&#39; ...</code></pre><h4 id="2-2-具体操作"><a href="#2-2-具体操作" class="headerlink" title="2.2 具体操作"></a>2.2 具体操作</h4><ol><li><p>在所有的node节点上找到kubelet启动的配置文件，比如<code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code></p></li><li><p>在ExecStart=后面添加启动非安全内存参数的配置<code>--allowed-unsafe-sysctls=net.core.somaxconn</code></p><pre><code>[Service]Environment=&quot;KUBELET_EXTRA_ARGS=--node-labels=alibabacloud.com/nodepool-&quot;.............................................ExecStart=ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CGROUP_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS $KUBELET_CUSTOMIZED_ARGS  --allowed-unsafe-sysctls=net.core.somaxconn,kernel.msgmax,net.ipv4.*,net.core.netdev_max_backlog,net.nf_conntrack_max,net.netfilter.nf_conntrack_tcp_timeout_established</code></pre></li><li><p>重启kubelet，<code>systemctl daemon-reload &amp;&amp; systemctl restart kubelet</code>。若启动不成功，请查看日志</p></li><li><p>ps -ef|grep kubelet 确认参数已生效</p><pre><code>/usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --max-pods 256 --pod-max-pids 16384 --pod-manifest-path=/etc/kubernetes/manifests --feature-gates=IPv6DualStack=true --network-plugin=cni .................................--system-reserved=cpu=100m,memory=1280Mi --kube-reserved=cpu=100m,memory=1280Mi --kube-reserved=pid=1000 --system-reserved=pid=1000 --allowed-unsafe-sysctls=net.core.somaxconn,kernel.msgmax,net.ipv4.*,net.core.netdev_max_backlog,net.nf_conntrack_max,net.netfilter.nf_conntrack_tcp_timeout_established</code></pre></li></ol><h3 id="3、设置Pod的Sysctl参数"><a href="#3、设置Pod的Sysctl参数" class="headerlink" title="3、设置Pod的Sysctl参数"></a>3、设置Pod的Sysctl参数</h3><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: sysctl-examplespec:  securityContext:    sysctls:    - name: kernel.shm_rmid_forced      value: &quot;0&quot;    - name: net.core.somaxconn      value: &quot;1024&quot;    - name: kernel.msgmax      value: &quot;65536&quot;  ...</code></pre><p><strong>注意：deployment的sysctl参数设置在spec.template.spec.securityContext.sysctls</strong></p><h2 id="三、其他解决方案"><a href="#三、其他解决方案" class="headerlink" title="三、其他解决方案"></a>三、其他解决方案</h2><h3 id="1、使用-initContainers"><a href="#1、使用-initContainers" class="headerlink" title="1、使用 initContainers"></a>1、使用 initContainers</h3><p>如果希望设置内核参数更简单通用，可以在 initContainer 中设置，不过这个要求给 initContainer 打开 <code>privileged</code> 权限。</p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: sysctl-example-initspec:  initContainers:  - image: busybox    command:    - sh    - -c    - |      sysctl -w net.core.somaxconn=65535      sysctl -w net.ipv4.ip_local_port_range=&quot;1024 65535&quot;      sysctl -w net.ipv4.tcp_tw_reuse=1      sysctl -w fs.file-max=1048576    imagePullPolicy: Always    name: setsysctl    securityContext:      privileged: true  containers:  ......</code></pre><h3 id="2、使用-tuning-CNI-插件统一设置-sysctl"><a href="#2、使用-tuning-CNI-插件统一设置-sysctl" class="headerlink" title="2、使用 tuning CNI 插件统一设置 sysctl"></a>2、使用 tuning CNI 插件统一设置 sysctl</h3><p>如果想要为所有 Pod 统一配置某些内核参数，可以使用 <a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/tuning">tuning</a> 这个 CNI 插件来做:</p><pre><code class="json">&#123;  &quot;name&quot;: &quot;mytuning&quot;,  &quot;type&quot;: &quot;tuning&quot;,  &quot;sysctl&quot;: &#123;          &quot;net.core.somaxconn&quot;: &quot;500&quot;,          &quot;net.ipv4.tcp_tw_reuse&quot;: &quot;1&quot;  &#125;&#125;</code></pre><h2 id="四、参考文档"><a href="#四、参考文档" class="headerlink" title="四、参考文档"></a>四、参考文档</h2><ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/">Using sysctls in a Kubernetes Cluster</a></li><li><a href="https://www.cni.dev/plugins/current/meta/tuning/">tuning 插件文档</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;我司从云主机向k8s迁移的过程中，由于在云主机上对内核参数进行过优化，所以尽量想K8s也和云主机的内存参数保持一致。&lt;/p&gt;</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="k8s" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/k8s/"/>
    
    
    <category term="k8s" scheme="https://www.langxw.com/tags/k8s/"/>
    
    <category term="sysctl" scheme="https://www.langxw.com/tags/sysctl/"/>
    
  </entry>
  
  <entry>
    <title>统计15天内阿里云SLB后端异常和并发指标</title>
    <link href="https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91SLB%E5%90%8E%E7%AB%AF%E5%BC%82%E5%B8%B8%E5%92%8C%E5%B9%B6%E5%8F%91%E6%8C%87%E6%A0%87/"/>
    <id>https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91SLB%E5%90%8E%E7%AB%AF%E5%BC%82%E5%B8%B8%E5%92%8C%E5%B9%B6%E5%8F%91%E6%8C%87%E6%A0%87/</id>
    <published>2021-12-01T03:00:46.000Z</published>
    <updated>2021-12-01T03:04:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p><strong>本脚本是阿里云资源利用率定期统计方案中的其中一个脚本。</strong></p><p>本脚本可实现，从每天95个平均值数据中取平均值，15天15个中位数取平均值，得到最终的15天内CPU和内存使用率数值。</p><p>进而根据阈值进行判断，资源是否处于低利用率状态。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><p><strong>Python3.7 + 阿里云云监控SDK + 阿里云SLB的SDK + pandas + numpy</strong></p><h2 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h2><pre><code class="bash"># -*- coding: utf-8 -*-import timeimport numpyimport jsonimport pandas as pdfrom typing import Listfrom alibabacloud_slb20140515.client import Client as Slb20140515Clientfrom alibabacloud_tea_openapi import models as open_api_modelsfrom alibabacloud_slb20140515 import models as slb_20140515_modelsfrom alibabacloud_cms20190101.client import Client as Cms20190101Clientfrom alibabacloud_cms20190101 import models as cms_20190101_models# cn-zhangjiakou 张家口区域的SLB在其他区域的config查不到，只能用张家口configREGION_ID = [&#39;cn-beijing&#39;, &#39;cn-hangzhou&#39;, &#39;cn-hongkong&#39;]PAGE_SIZE = 100class GetMonitorData:    def __init__(self):        pass    @staticmethod    def create_client(        access_key_id: str,        access_key_secret: str,    ) -&gt; Cms20190101Client:        config = open_api_models.Config(            access_key_id=&#39;xxxxxxxx&#39;,            access_key_secret=&#39;xxxxxxxxxxxx&#39;        )        config.endpoint = &#39;metrics.cn-hangzhou.aliyuncs.com&#39;        return Cms20190101Client(config)    @staticmethod    def main(        args: List[str],    ) -&gt; None:        client = GetMonitorData.create_client(&#39;acessKeyId&#39;, &#39;accessKeySecret&#39;)        describe_metric_list_request = cms_20190101_models.DescribeMetricListRequest(            metric_name=args[1],            namespace=args[0],            period=&#39;900&#39;,            start_time=args[2],            end_time=args[3],            length=&#39;100&#39;,            dimensions=&#39;&#123;&#123;"instanceId":&#123;&#125;&#125;&#125;&#39;.format(args[4]),            next_token=args[5]        )        res = client.describe_metric_list(describe_metric_list_request)        return res.bodyclass GetInstanceIdName:    def __init__(self):        pass    @staticmethod    def create_client(        access_key_id: str,        access_key_secret: str,    ) -&gt; Slb20140515Client:        config = open_api_models.Config(            access_key_id=&#39;xxxxxxxxxxx&#39;,            access_key_secret=&#39;xxxxxxxxxxxxx&#39;        )        # 访问的域名        config.endpoint = &#39;slb.aliyuncs.com&#39;        return Slb20140515Client(config)    @staticmethod    def main(        args: List[str],    ) -&gt; None:        client = GetInstanceIdName.create_client(&#39;accessKeyId&#39;, &#39;accessKeySecret&#39;)        describe_load_balancers_request = slb_20140515_models.DescribeLoadBalancersRequest(            region_id=args[0],            page_size=PAGE_SIZE,            page_number=args[1]        )        res = client.describe_load_balancers(describe_load_balancers_request)        return res.bodydef get_id_name_dict():    instance_dict = &#123;&#125;    for i in range(0, len(REGION_ID)):        result = GetInstanceIdName.main([REGION_ID[i], 1])        total_page = result.total_count // PAGE_SIZE + 1        for j in range(0, total_page):            result2 = GetInstanceIdName.main([REGION_ID[i], j+1])            slb_info = result2.load_balancers.load_balancer            for k in range(0, len(slb_info)):                instance_dict[slb_info[k].load_balancer_id] = slb_info[k].load_balancer_name    print(&#39;实例ID和名字的字典:&#39;, instance_dict)    return instance_dictdef get_average_24h(instance_dict, pre_days, metric_name):    average_dict = &#123;&#125;    today = time.strftime(&#39;%Y-%m-%d&#39;, time.localtime(time.time()))    today_time = time.mktime(time.strptime(today, &#39;%Y-%m-%d&#39;))    # 从昨天开始，往前推15天，15次循环,取1-15。取00:00:00-23:59:59的时间戳    start_time = str(round((today_time - 86400*pre_days)*1000))    end_time = str(round((today_time - 86400*(pre_days-1) - 1)*1000))    namespace = &#39;acs_slb_dashboard&#39;    for i in instance_dict.keys():        token = &#39;init_data&#39;        average_list = []        while token:            result = GetMonitorData.main([namespace, metric_name, start_time, end_time, i, token])            token = result.next_token            res_list = json.loads(result.datapoints)            # 停机和未安装监控agent的主机拿不到监控数据，res_list是个空列表，计算平均是会报错            if len(res_list) != 0:                for j in range(0, len(res_list)):                    # print(res_list[i])                    average_list.append(round(res_list[j][&#39;Average&#39;], 2))            else:                average_list = [0.00, ]        # 取平均值        average_dict[i] = numpy.mean(average_list)        time.sleep(0.2)    return average_dictdef get_average_15days(instance_dict, metric):    temp_dict = &#123;&#125;    median_dict1 = get_average_24h(instance_dict, 1, metric)    for k, v in median_dict1.items():        temp_dict[k] = []    for k1, v1 in median_dict1.items():        temp_dict[k1].append(v1)    for i in range(2, 16):        median_dict = get_average_24h(instance_dict, i, metric)        for k2, v2 in median_dict.items():            temp_dict[k2].append(v2)    for k3, v3 in temp_dict.items():        temp_dict[k3] = round(numpy.mean(v3), 3)    print(temp_dict)    return temp_dictdef write_to_execl(data):    df = pd.DataFrame.from_dict(data, orient=&#39;index&#39;, columns=[&#39;后端异常ECS实例个数&#39;, &#39;实例每秒最大并发连接数&#39;])    df.to_excel(&#39;slb_statistics.xlsx&#39;)if __name__ == &#39;__main__&#39;:    # 获取InstanceId和InstanceName的对应字典    str_time = time.time()    instance_dict = get_id_name_dict()    # 数据合并处理    id_list_dict = &#123;&#125;    for k, v in instance_dict.items():        id_list_dict[k] = []    ecs_metric = [&#39;UnhealthyServerCount&#39;, &#39;InstanceMaxConnection&#39;]    for metric in ecs_metric:        metric_data = get_average_15days(instance_dict, metric)        for k2, v2 in metric_data.items():            id_list_dict[k2].append(v2)    for k_id, k_name in instance_dict.items():        if k_id in id_list_dict:            id_list_dict[k_name] = id_list_dict.pop(k_id)    # 数据写入excel表格    write_to_execl(id_list_dict)    print(time.time() - str_time)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;本脚本是阿里云资源利用率定期统计方案中的其中一个脚本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本脚本可实现，从每天</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Python" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Python/"/>
    
    
    <category term="Python" scheme="https://www.langxw.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>统计15天内阿里云ECS内存使用率和CPU使用率</title>
    <link href="https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91ECS%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%8E%87%E5%92%8CCPU%E4%BD%BF%E7%94%A8%E7%8E%87/"/>
    <id>https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91ECS%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%8E%87%E5%92%8CCPU%E4%BD%BF%E7%94%A8%E7%8E%87/</id>
    <published>2021-12-01T02:42:57.000Z</published>
    <updated>2021-12-01T02:59:02.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p><strong>本脚本是阿里云资源利用率定期统计方案中的其中一个脚本。</strong></p><p>本脚本可实现，从每天95个平均值数据中取中位数，15天15个中位数取平均值，得到最终的15天内CPU和内存使用率数值。</p><p>进而根据阈值进行判断，资源是否处于低利用率状态。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><p><strong>Python3.7 + 阿里云云监控SDK + 阿里云ECS的SDK + pandas + numpy</strong></p><h2 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h2><pre><code class="bash"># -*- coding: utf-7 -*-import timeimport numpyimport jsonimport pandas as pdfrom typing import Listfrom alibabacloud_cms20190101.client import Client as Cms20190101Clientfrom alibabacloud_tea_openapi import models as open_api_modelsfrom alibabacloud_cms20190101 import models as cms_20190101_modelsfrom alibabacloud_ecs20140526.client import Client as Ecs20140527Clientfrom alibabacloud_ecs20140526 import models as ecs_20140526_modelsREGION_ID = [&#39;cn-beijing&#39;, &#39;cn-hangzhou&#39;, &#39;cn-zhangjiakou&#39;, &#39;cn-shenzhen&#39;, &#39;cn-shanghai&#39;, &#39;cn-hongkong&#39;,             &#39;ap-southeast-1&#39;, &#39;ap-northeast-1&#39;]class GetMonitorData:    def __init__(self):        pass    @staticmethod    def create_client(        access_key_id: str,        access_key_secret: str,    ) -&gt; Cms20190101Client:        config = open_api_models.Config(            access_key_id=&#39;xxxxxxxxx&#39;,            access_key_secret=&#39;xxxxxxxxxxxxx&#39;        )        config.endpoint = &#39;metrics.cn-hangzhou.aliyuncs.com&#39;        return Cms20190101Client(config)    @staticmethod    def main(        args: List[str],    ) -&gt; None:        client = GetMonitorData.create_client(&#39;acessKeyId&#39;, &#39;accessKeySecret&#39;)        describe_metric_list_request = cms_20190101_models.DescribeMetricListRequest(            metric_name=args[1],            namespace=args[0],            period=&#39;900&#39;,            start_time=args[2],            end_time=args[3],            length=&#39;100&#39;,            dimensions=&#39;&#123;&#123;"instanceId":&#123;&#125;&#125;&#125;&#39;.format(args[4])        )        res = client.describe_metric_list(describe_metric_list_request)        return res.bodyclass GetInstanceIdName:    def __init__(self):        pass    @staticmethod    def create_client(        access_key_id: str,        access_key_secret: str,    ) -&gt; Ecs20140526Client:        config = open_api_models.Config(            access_key_id=&#39;xxxxxxxxxxxxxx&#39;,            access_key_secret=&#39;xxxxxxxxxxxxxxxxxxxx&#39;        )        config.endpoint = &#39;ecs-cn-hangzhou.aliyuncs.com&#39;        return Ecs20140526Client(config)    @staticmethod    def main(        args: List[str],    ) -&gt; None:        client = GetInstanceIdName.create_client(&#39;accessKeyId&#39;, &#39;accessKeySecret&#39;)        describe_instances_request = ecs_20140526_models.DescribeInstancesRequest(            region_id=args[1],            next_token=args[0],            max_results=50        )        res = client.describe_instances(describe_instances_request)        return res.bodydef get_id_name_dict():    instance_dict = &#123;&#125;    for i in range(0, len(REGION_ID)):        token = &#39;init_data&#39;        while token:            result = GetInstanceIdName.main([token, REGION_ID[i]])            token = result.next_token            info_list = result.instances.instance            for j in range(0, len(info_list)):                instance_dict[info_list[j].instance_id] = info_list[j].instance_name    print(&#39;实例ID和名字的字典:&#39;, instance_dict)    return instance_dictdef get_median_24h(instance_dict, pre_days, metric_name):    median_dict = &#123;&#125;    today = time.strftime(&#39;%Y-%m-%d&#39;, time.localtime(time.time()))    today_time = time.mktime(time.strptime(today, &#39;%Y-%m-%d&#39;))    # 从昨天开始，往前推15天，15次循环,取1-15。取00:00:00-23:59:59的时间戳    start_time = str(round((today_time - 86400*pre_days)*1000))    end_time = str(round((today_time - 86400*(pre_days-1) - 1)*1000))    namespace = &#39;acs_ecs_dashboard&#39;    for i in instance_dict.keys():        result = GetMonitorData.main([namespace, metric_name, start_time, end_time, i])        average_list = []        res_list = json.loads(result.datapoints)        # 停机和未安装监控agent的主机拿不到监控数据，res_list是个空列表，计算平均是会报错        if len(res_list) != 0:            for j in range(0, len(res_list)):                # print(res_list[i])                average_list.append(round(res_list[j][&#39;Average&#39;], 2))        else:            average_list = [0.00, ]        # print(len(average_list), average_list)        # 取中位数        median_dict[i] = numpy.median(average_list)        time.sleep(0.2)    return median_dictdef get_average_15days(instance_dict, metric):    temp_dict = &#123;&#125;    median_dict1 = get_median_24h(instance_dict, 1, metric)    for k, v in median_dict1.items():        temp_dict[k] = []    for k1, v1 in median_dict1.items():        temp_dict[k1].append(v1)    for i in range(2, 16):        median_dict = get_median_24h(instance_dict, i, metric)        for k2, v2 in median_dict.items():            temp_dict[k2].append(v2)    for k3, v3 in temp_dict.items():        temp_dict[k3] = round(numpy.mean(v3), 3)    print(temp_dict)    return temp_dictdef write_to_execl(data):    df = pd.DataFrame.from_dict(data, orient=&#39;index&#39;, columns=[&#39;CPU使用率&#39;, &#39;内存使用率&#39;])    df.to_excel(&#39;cpu_mem_15days.xlsx&#39;)if __name__ == &#39;__main__&#39;:    # 获取InstanceId和InstanceName的对应字典    # str_time = time.time()    instance_dict = get_id_name_dict()    # 数据合并处理，比较复杂    id_list_dict = &#123;&#125;    for k, v in instance_dict.items():        id_list_dict[k] = []    ecs_metric = [&#39;CPUUtilization&#39;, &#39;memory_usedutilization&#39;]    for metric in ecs_metric:        metric_data = get_average_15days(instance_dict, metric)        for k2, v2 in metric_data.items():            id_list_dict[k2].append(v2)    for k_id, k_name in instance_dict.items():        if k_id in id_list_dict:            id_list_dict[k_name] = id_list_dict.pop(k_id)    # 数据写入excel表格    write_to_execl(id_list_dict)    # print(time.time() - str_time)</code></pre><p><strong>注意：以上代码中24小时内的数据，是一个实例一个循环取的数据，调用接口次数多，耗时较长。经实践400个ECS，执行完本脚本要5个小时左右，可耐心等待。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;本脚本是阿里云资源利用率定期统计方案中的其中一个脚本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本脚本可实现，从每天</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Python" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Python/"/>
    
    
    <category term="python" scheme="https://www.langxw.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>统计阿里云ECS停机状态的主机</title>
    <link href="https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A1%E9%98%BF%E9%87%8C%E4%BA%91ECS%E5%81%9C%E6%9C%BA%E7%8A%B6%E6%80%81%E7%9A%84%E4%B8%BB%E6%9C%BA/"/>
    <id>https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A1%E9%98%BF%E9%87%8C%E4%BA%91ECS%E5%81%9C%E6%9C%BA%E7%8A%B6%E6%80%81%E7%9A%84%E4%B8%BB%E6%9C%BA/</id>
    <published>2021-12-01T02:32:24.000Z</published>
    <updated>2021-12-01T03:05:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p><strong>本脚本是阿里云资源利用率定期统计方案中的其中一个脚本。</strong></p><p>公司阿里云ECS比较多，地区比较多，乃至有多个账号，一个个查看和统计比较费事费力。现编写一个统计阿里云ECS处于停机状态的主机的脚本，输出Excel文档后，我们可以区分，哪些还处于停机收费状态，哪些可以释放，哪些不可以释放。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><p>**Python3.7 + 阿里云ECS的SDK + pandas **</p><h2 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h2><pre><code class="bash"># -*- coding: utf-8 -*-from typing import Listimport pandas as pdfrom alibabacloud_tea_openapi import models as open_api_modelsfrom alibabacloud_ecs20140526.client import Client as Ecs20140526Clientfrom alibabacloud_ecs20140526 import models as ecs_20140526_modelsREGION_ID = [&#39;cn-beijing&#39;, &#39;cn-hangzhou&#39;, &#39;cn-zhangjiakou&#39;, &#39;cn-shenzhen&#39;, &#39;cn-shanghai&#39;, &#39;cn-hongkong&#39;,             &#39;ap-southeast-1&#39;, &#39;ap-northeast-1&#39;]class GetInstanceIdName:    def __init__(self):        pass    @staticmethod    def create_client(        access_key_id: str,        access_key_secret: str,    ) -&gt; Ecs20140526Client:        config = open_api_models.Config(            access_key_id=&#39;xxxxxxxxxx&#39;,            access_key_secret=&#39;xxxxxxxxxx&#39;        )        config.endpoint = &#39;ecs-cn-hangzhou.aliyuncs.com&#39;        return Ecs20140526Client(config)    @staticmethod    def main(        args: List[str],    ) -&gt; None:        client = GetInstanceIdName.create_client(&#39;accessKeyId&#39;, &#39;accessKeySecret&#39;)        describe_instances_request = ecs_20140526_models.DescribeInstancesRequest(            region_id=args[1],            next_token=args[0],            max_results=50        )        res = client.describe_instances(describe_instances_request)        return res.bodydef get_instance_status():    instance_dict = &#123;&#125;    for i in range(0, len(REGION_ID)):        token = &#39;init_data&#39;        while token:            result = GetInstanceIdName.main([token, REGION_ID[i]])            token = result.next_token            info_list = result.instances.instance            # print(dir(info_list[0]))            for j in range(0, len(info_list)):                if info_list[j].status == &#39;Stopped&#39;:                    instance_dict[info_list[j].instance_id] = []            for k in range(0, len(info_list)):                if info_list[k].status == &#39;Stopped&#39;:                    instance_dict[info_list[k].instance_id].append(info_list[k].instance_name)                    instance_dict[info_list[k].instance_id].append(info_list[k].status)                    instance_dict[info_list[k].instance_id].append(info_list[k].stopped_mode)                    instance_dict[info_list[k].instance_id].append(info_list[k].description)    return instance_dictdef write_to_execl(data):    df = pd.DataFrame.from_dict(data, orient=&#39;index&#39;, columns=[&#39;实例名称&#39;, &#39;实例状态&#39;, &#39;停机收费状态&#39;, &#39;实例备注&#39;])    df.to_excel(&#39;ecs_stopped.xlsx&#39;)if __name__ == &#39;__main__&#39;:    instance_info = get_instance_status()    write_to_execl(instance_info)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;本脚本是阿里云资源利用率定期统计方案中的其中一个脚本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;公司阿里云ECS比较</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Python" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Python/"/>
    
    
    <category term="python" scheme="https://www.langxw.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>统计阿里云ECS磁盘使用率</title>
    <link href="https://www.langxw.com/2021/11/30/%E7%BB%9F%E8%AE%A1%E9%98%BF%E9%87%8C%E4%BA%91ECS%E7%A3%81%E7%9B%98%E4%BD%BF%E7%94%A8%E7%8E%87/"/>
    <id>https://www.langxw.com/2021/11/30/%E7%BB%9F%E8%AE%A1%E9%98%BF%E9%87%8C%E4%BA%91ECS%E7%A3%81%E7%9B%98%E4%BD%BF%E7%94%A8%E7%8E%87/</id>
    <published>2021-11-30T10:33:08.000Z</published>
    <updated>2021-12-01T03:05:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>公司阿里云主机很多业务模块，经常受磁盘告警烦恼，尤其是在周末或者假期，运维不敢随意清理，就得找开发确认乐之后才能清理。</p><p>为了减少假期的磁盘告警，保证业务的正常运行，可在周五或者假期前一天统计所有主机的磁盘使用率，对于大于65%的，一一进行核对和清理。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><p><strong>Python3.7 + 阿里云云监控SDK。</strong></p><h2 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h2><p><strong>调用阿里云云监控的接口，来查询磁盘使用率，并最终输出文档，按磁盘使用率倒序排列。</strong></p><pre><code class="bash"># -*- coding: utf-8 -*-import sysimport jsonimport timefrom typing import Listfrom operator import itemgetterfrom alibabacloud_cms20190101.client import Client as Cms20190101Clientfrom alibabacloud_tea_openapi import models as open_api_modelsfrom alibabacloud_cms20190101 import models as cms_20190101_modelsclass Sample:    def __init__(self):        pass    @staticmethod    def create_client(        access_key_id: str,        access_key_secret: str,    ) -&gt; Cms20190101Client:        &quot;&quot;&quot;        使用AK&amp;SK初始化账号Client        @param access_key_id:        @param access_key_secret:        @return: Client        @throws Exception        &quot;&quot;&quot;        config = open_api_models.Config(            # 您的AccessKey ID,            access_key_id=&#39;xxxxxxxxx&#39;,            # 您的AccessKey Secret,            access_key_secret=&#39;xxxxxxxx&#39;        )        # 访问的域名        config.endpoint = &#39;metrics.cn-hangzhou.aliyuncs.com&#39;        return Cms20190101Client(config)    @staticmethod    def main(        args: List[str],    ) -&gt; None:        client = Sample.create_client(&#39;accessKeyId&#39;, &#39;accessKeySecret&#39;)        describe_metric_list_request = cms_20190101_models.DescribeMetricListRequest(            metric_name=&#39;diskusage_utilization&#39;,            namespace=&#39;acs_ecs_dashboard&#39;,            period=&#39;60&#39;,            start_time=args[1],            end_time=args[2],            length=&#39;100&#39;,            next_token=args[0]        )        # 复制代码运行请自行打印 API 的返回值        res = client.describe_metric_list(describe_metric_list_request)        return res.bodydef get_disk_usage(api_res):    disk_list = []    # print(dir(api_res))    res_list = json.loads(api_res.datapoints)    for i in range(0, len(res_list)):        disk_list_tmp = [res_list[i][&#39;instanceId&#39;], res_list[i][&#39;diskname&#39;], res_list[i][&#39;Average&#39;]]        disk_list.append(disk_list_tmp)    return disk_listif __name__ == &#39;__main__&#39;:    token = &#39;init_data&#39;    disk_info = []    # 不能取当前时间，当前时间太近了，没有最新的监控数据。    day = time.strftime(&#39;%Y-%m-%d&#39;, time.localtime())    start_time = str(round((time.time()-300)*1000))    end_time = str(round((time.time()-240)*1000))    while token:        result = Sample.main([token, start_time, end_time])        token = result.next_token        disk_res = get_disk_usage(result)        disk_info.extend(disk_res)    order_disk_info = sorted(disk_info, key=itemgetter(2), reverse=True)    with open(&#39;statistics_disk_&#123;&#125;.txt&#39;.format(day), &#39;w&#39;) as f:        f.write(&#39;ECS实例ID \t\t盘符 \t\t磁盘使用率\n&#39;)        for i in range(0, len(order_disk_info)):            f.write(str(order_disk_info[i])+&#39;\n&#39;)</code></pre><p><strong>注意：输出文档只有实例ID，如果显示实例名称，可以参考另一篇文章的接口调用。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;公司阿里云主机很多业务模块，经常受磁盘告警烦恼，尤其是在周末或者假期，运维不敢随意清理，就得找开发确认乐之后才能清理。&lt;/p</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Python" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Python/"/>
    
    
    <category term="python" scheme="https://www.langxw.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>阿里云资源利用率定期统计方案</title>
    <link href="https://www.langxw.com/2021/11/30/%E9%98%BF%E9%87%8C%E4%BA%91%E8%B5%84%E6%BA%90%E5%88%A9%E7%94%A8%E7%8E%87%E5%AE%9A%E6%9C%9F%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%A1%88/"/>
    <id>https://www.langxw.com/2021/11/30/%E9%98%BF%E9%87%8C%E4%BA%91%E8%B5%84%E6%BA%90%E5%88%A9%E7%94%A8%E7%8E%87%E5%AE%9A%E6%9C%9F%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%A1%88/</id>
    <published>2021-11-30T10:07:12.000Z</published>
    <updated>2021-12-01T03:10:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、目标"><a href="#一、目标" class="headerlink" title="一、目标"></a>一、目标</h2><p>为提高阿里云资源利用率，运维会定期对阿里云资源进行资源使用情况统计，根据不同指标阈值来初步判断资源是否属于低利用率状态。</p><p>每次统计后形成输出文档，而后根据文档与相关负责人进行沟通后，进行服务下线或者服务合并操作，以提高资源利用率，节省费用。</p><h2 id="二、指标"><a href="#二、指标" class="headerlink" title="二、指标"></a>二、指标</h2><h3 id="1、ECS指标"><a href="#1、ECS指标" class="headerlink" title="1、ECS指标"></a>1、ECS指标</h3><table><thead><tr><th>指标序号</th><th>指标名称</th><th>采样规则</th><th>计算规则</th><th>判断阈值</th></tr></thead><tbody><tr><td>1</td><td>CPU使用率</td><td>采样间隔为900s，采样数值为平均值，1天会取到95个平均值</td><td>从每天95个平均值中取<strong>中位数</strong>，15天15个中位数取平均值，得到最终的15天内CPU使用率数值，作为最终指标</td><td>小于3%</td></tr><tr><td>2</td><td>内存使用率</td><td>同上</td><td>同上</td><td>小于10%</td></tr><tr><td>3</td><td>内网流入流量平均速率</td><td>同上</td><td>同上</td><td>小于500kbps</td></tr><tr><td>4</td><td>负载</td><td>待定</td><td>待定</td><td>待定</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h3 id="2、SLB指标"><a href="#2、SLB指标" class="headerlink" title="2、SLB指标"></a>2、SLB指标</h3><table><thead><tr><th>指标序号</th><th>指标名称</th><th>采样规则</th><th>计算规则</th><th>判断阈值</th></tr></thead><tbody><tr><td>1</td><td>后端异常ECS实例个数</td><td>采样间隔为900s，采样数值为平均值，1天会取到95个平均值</td><td>从每天95个平均值中取<strong>平均值</strong>，15天15个平局值再取平均值，得到最终的15天后端异常ECS实例个数，作为最终指标</td><td>大于0</td></tr><tr><td>2</td><td>实例每秒最大并发连接数</td><td>同上</td><td>同上</td><td>小于20</td></tr><tr><td>3</td><td>实例每秒入包数（实例每秒入包数）</td><td>待定</td><td>待定</td><td>待定</td></tr></tbody></table><h3 id="3、Pod指标"><a href="#3、Pod指标" class="headerlink" title="3、Pod指标"></a>3、Pod指标</h3><table><thead><tr><th>指标序号</th><th>指标名称</th><th>采样规则</th><th>计算规则</th><th>判断阈值</th></tr></thead><tbody><tr><td>1</td><td>CPU利用率</td><td>待定</td><td>待定</td><td>待定</td></tr><tr><td>2</td><td>内存使用率</td><td>待定</td><td>待定</td><td>待定</td></tr></tbody></table><p>鉴于目前处于容器化的初期，业务模块在容器化的时候都经过严格的人为控制，比如资源的申请、HPA自动伸缩等，并且有每天巡检来确定容器业务是否稳定、资源使用是否合理。故容器的定期资源利用率统计后期再考虑。</p><h3 id="3、参考指标"><a href="#3、参考指标" class="headerlink" title="3、参考指标"></a>3、参考指标</h3><p>就近选取节假日（例如国庆7天）或者寒暑假中的15天，作为高峰期对比参考指标，主要是考虑是否有业务会有那种短周期的大波动，为服务缩容或者服务合并作参考依据。</p><h2 id="三、具体实施"><a href="#三、具体实施" class="headerlink" title="三、具体实施"></a>三、具体实施</h2><p><strong>使用Python编写脚本，每隔15天跑一次（暂定15号和30号），获取分析结果，形成输出文档。</strong></p><h3 id="1、ECS实施"><a href="#1、ECS实施" class="headerlink" title="1、ECS实施"></a>1、ECS实施</h3><ul><li>暂定采用指标1和指标2来同时进行判定资源是否处于低负载状态，也可对CPU消耗型程序和内存消耗型程序单独进行判定。</li><li>对于指标3和指标4，可以在后续精细区分的时候，进行采集和判定。</li><li>判定为低负载状态的资源列入黄色名单，和相关负责人沟通后，进行业务裁撤或者合并。</li><li>同时，ECS会有一个已停机状态的检测，列入已停机名单，根据情况单独处理。</li></ul><h3 id="2、SLB实施"><a href="#2、SLB实施" class="headerlink" title="2、SLB实施"></a>2、SLB实施</h3><ul><li>主要使用指标1进行资源是否在使用的判定</li><li>指标2可以作为次要考虑，考虑是否需要配置降级</li></ul><h3 id="3、输入文档"><a href="#3、输入文档" class="headerlink" title="3、输入文档"></a>3、输入文档</h3><ol><li>15天内ECS的CPU和内存利用率统计文档</li><li>15天内ECS的停机主机统计文档</li><li>15天内SLB的后端异常ECS实例个数和实例每秒最大并发连接数统计文档</li></ol><h2 id="四、说明"><a href="#四、说明" class="headerlink" title="四、说明"></a>四、说明</h2><ul><li>以上方案为初步方案，指标、采样规则、计算规则和判断阈值等可能需要根据实际情况微调，后续可在具体实施中再次调整和完善。</li><li>合并相关事宜，也可以从服务器架构上考虑下，有些用途类似的服务器，可以合并使用或者建立公用服务器，提高使用率。</li></ul><h2 id="五、脚本实现："><a href="#五、脚本实现：" class="headerlink" title="五、脚本实现："></a>五、脚本实现：</h2><ul><li><a href="https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91ECS%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%8E%87%E5%92%8CCPU%E4%BD%BF%E7%94%A8%E7%8E%87/">统计阿里云ECS停机状态的主机</a></li><li><a href="https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91ECS%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%8E%87%E5%92%8CCPU%E4%BD%BF%E7%94%A8%E7%8E%87/">统计15天内阿里云ECS内存使用率和CPU使用率</a></li><li><a href="https://www.langxw.com/2021/12/01/%E7%BB%9F%E8%AE%A115%E5%A4%A9%E5%86%85%E9%98%BF%E9%87%8C%E4%BA%91SLB%E5%90%8E%E7%AB%AF%E5%BC%82%E5%B8%B8%E5%92%8C%E5%B9%B6%E5%8F%91%E6%8C%87%E6%A0%87/">统计15天内阿里云SLB后端异常和并发指标</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、目标&quot;&gt;&lt;a href=&quot;#一、目标&quot; class=&quot;headerlink&quot; title=&quot;一、目标&quot;&gt;&lt;/a&gt;一、目标&lt;/h2&gt;&lt;p&gt;为提高阿里云资源利用率，运维会定期对阿里云资源进行资源使用情况统计，根据不同指标阈值来初步判断资源是否属于低利用率状态。&lt;/</summary>
      
    
    
    
    <category term="方案" scheme="https://www.langxw.com/categories/%E6%96%B9%E6%A1%88/"/>
    
    
    <category term="方案" scheme="https://www.langxw.com/tags/%E6%96%B9%E6%A1%88/"/>
    
    <category term="规范" scheme="https://www.langxw.com/tags/%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ部署-DLedger集群模式-Docker版</title>
    <link href="https://www.langxw.com/2021/11/30/RocketMQ%E9%83%A8%E7%BD%B2-DLedger%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F-Docker%E7%89%88/"/>
    <id>https://www.langxw.com/2021/11/30/RocketMQ%E9%83%A8%E7%BD%B2-DLedger%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F-Docker%E7%89%88/</id>
    <published>2021-11-30T10:02:40.000Z</published>
    <updated>2021-11-30T10:04:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、RocketMQ组件介绍"><a href="#一、RocketMQ组件介绍" class="headerlink" title="一、RocketMQ组件介绍"></a>一、RocketMQ组件介绍</h2><p>这里介绍下 RocketMQ 相关的组件：</p><ul><li><strong>名字服务（Name Server）：</strong> 是一个几乎无状态节点，可集群部署，集群节点间相互独立没有信息交换。其功能主要为更新和发现 Broker 服务，生产者或消费者能够通过其查找到各主题相应的 Broker IP 列表。</li><li><strong>代理服务（Broker Server）：</strong> 消息中转角色，负责存储消息，转发消息。分为 Master Broker 和 Slave Broker，一个 Master Broker 可以对应多个 Slave Broker，但是一个 Slave Broker 只能对应一个 Master Broker。Broker 启动后需要完成一次将自己注册至 Name Server 的操作，随后每隔 30s 定期 向Name Server 上报 Topic 路由信息。</li><li><strong>生产者：</strong> 与 Name Server 集群中的其中一个节点（随机）建立长链接（Keep-alive），定期从 Name Server 读取 Topic 路由信息，并向提供 Topic 服务的 Master Broker 建立长链接，且定时向 Master Broker 发送心跳。</li><li><strong>消费者：</strong> 与 Name Server 集群中的其中一个节点（随机）建立长连接，定期从 Name Server 拉取 Topic 路由信息，并向提供 Topic 服务的 Master Broker、Slave Broker建立长连接，且定时向 Master Broker、Slave Broker 发送心跳。Consumer 既可以从 Master Broker 订阅消息，也可以从 Slave Broker 订阅消息，订阅规则由 Broker 配置决定。</li><li><strong>控制台（console）：</strong> RocketMQ 的 Web 可视化控制台，包含 RocketMQ 常用操作，可以用于简单管理 RocketMQ 平台。</li></ul><h2 id="二、RocketMQ部署模式介绍"><a href="#二、RocketMQ部署模式介绍" class="headerlink" title="二、RocketMQ部署模式介绍"></a>二、RocketMQ部署模式介绍</h2><p>RocketMQ 常用部署方案有以下几种：</p><ul><li><strong>单机模式</strong></li><li><strong>多主模式</strong></li><li><strong>双主双从/多主多从模式（异步复制）</strong></li><li><strong>双主双从/多主多从模式（同步双写）</strong></li><li><strong>Dledger 集群模式</strong></li></ul><h3 id="1、单机模式"><a href="#1、单机模式" class="headerlink" title="1、单机模式"></a>1、单机模式</h3><p>这种模式就如该名单机模式一样，就是部署单个 RocketMQ Broker 来使用，一般使用这种方式在生产中风险较大，一旦 Broker 重启或者宕机时，会导致整个服务不可用，所以常常在学习、开发过程中才会使用这种模式。</p><p>优缺点分析：</p><ul><li><strong>优点：</strong> 本地开发测试，配置简单，同步刷盘消息不会丢失。</li><li><strong>缺点：</strong> 不可靠，如果宕机会导致服务不可用。</li></ul><h3 id="2、多主模式"><a href="#2、多主模式" class="headerlink" title="2、多主模式"></a>2、多主模式</h3><p>全部由 Broker Master 节点组成（即可能部署两个或者更多 Broker），生产者发送的数据会分别存入不同的 Broker 中，这样能够避免某个 Broker 一直接收处理数据从而负载过高。</p><p>优缺点分析：</p><ul><li><strong>优点：</strong> 性能高，配置简单，单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复，由于 RAID10 磁盘非常可靠，消息也不会丢（异步刷盘可能会丢失少量消息，同步刷盘能保证消息不丢）。</li><li><strong>缺点：</strong> 单台服务器宕机期间，不可订阅该服务器上未被消费者消费的消息，只有机器恢复后才可恢复订阅，所以可能会影响消息的实时性。</li></ul><h3 id="3、双主双从-多主多从模式（异步复制）"><a href="#3、双主双从-多主多从模式（异步复制）" class="headerlink" title="3、双主双从/多主多从模式（异步复制）"></a>3、双主双从/多主多从模式（异步复制）</h3><p>一般会部署多个 Broker Master，同时也会为各个 Broker Master 部署一个 Broker Slave，且 Master 和 Slave 之间采用”异步复制数据”方式进行数据同步（主从同步消息会有延迟，毫秒级），这样在生产者将消息发送到 Broker Master 后不必等待数据同步到 Slave 节点，就返回成功。</p><p>优缺点分析：</p><ul><li><strong>优点：</strong> 性能高，且磁盘损坏也不会丢失大量消息，消息实时性不会受影响，Master 宕机后，消费者仍然可以从 Slave 消费。</li><li><strong>缺点：</strong> 主备有短暂消息延迟，毫秒级，如果Master宕机，磁盘损坏情况，会丢失少量消息。</li></ul><h3 id="4、双主双从-多主多从模式（同步双写）"><a href="#4、双主双从-多主多从模式（同步双写）" class="headerlink" title="4、双主双从/多主多从模式（同步双写）"></a>4、双主双从/多主多从模式（同步双写）</h3><p>一般会部署多个 Broker Master，同时也会为各个 Broker Master 部署一个 Broker Slave，且 Master 和 Slave 之间采用”同步复制数据”方式进行数据同步，这样在生产者将消息发送到 Broker Master 后需要等待数据同步到 Slave 节点成功后，才返回成功。</p><p>优缺点分析：</p><ul><li><strong>优点：</strong> 数据与服务都无单点故障，Master 宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；</li><li><strong>缺点：</strong> 性能比异步复制模式略低（大约低10%左右），发送单个消息的 RT 会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。</li></ul><h3 id="5、Dledger-集群模式"><a href="#5、Dledger-集群模式" class="headerlink" title="5、Dledger 集群模式"></a>5、Dledger 集群模式</h3><p>RocketMQ-on-DLedger Group 是指一组相同名称的 Broker，至少需要 3 个节点，通过 Raft 自动选举出一个 Leader，其余节点 作为 Follower，并在 Leader 和 Follower 之间复制数据以保证高可用。当 Master 节点出现问题宕机后也能自动容灾切换，并保证数据一致性。该模式也支持 Broker 水平扩展，即可以部署任意多个 RocketMQ-on-DLedger Group 同时对外提供服务。</p><p>优缺点分析：</p><ul><li><strong>优点</strong>：多节点（至少三个）组成集群，其中一个为 Leader 节点，其余为 Follower 节点组成高可用，能够自动容灾切换。</li><li><strong>缺点</strong>：需要 RocketMQ 4.5 及以后版本才支持。</li></ul><h2 id="三、RocketMQ-DLedger集群简介"><a href="#三、RocketMQ-DLedger集群简介" class="headerlink" title="三、RocketMQ DLedger集群简介"></a>三、RocketMQ DLedger集群简介</h2><h3 id="1、传统部署方式的不足"><a href="#1、传统部署方式的不足" class="headerlink" title="1、传统部署方式的不足"></a>1、传统部署方式的不足</h3><p>在 RocketMQ 4.5 之前的版本中，部署 RocketMQ 高可用方案一般都会采用多主多从方式，这种方式需要多个 Master 节点与实时备份 Master 节点数据的 Slave 节点，Slave 节点通过同步复制或异步复制的方式去同步 Master 节点数据。但这样的部署模式存在一定缺陷。比如故障转移方面，如果 Master 点挂了，还需要人为手动对 Master 节点进行重启或者切换，它无法自动的将 Slave 节点转换为 Master 节点。因此，我们希望能有一个新的多副本架构，去解决这个问题。</p><h3 id="2、新技术解决的问题"><a href="#2、新技术解决的问题" class="headerlink" title="2、新技术解决的问题"></a>2、新技术解决的问题</h3><p>新的多副本架构首先需要解决自动故障转移的问题，本质上来说问题关键点在于 Broker 如何自动推选主节点。这个问题的解决方案基本可以分为两种：</p><ul><li>利用第三方协调服务集群完成选主，比如 Zookeeper 或者 Etcd，但是这种方案会引入了重量级外部组件，使部署变得复杂，同时也会增加运维对组件的故障诊断成本，比如在维护 RocketMQ 集群还需要维护 Zookeeper 集群，保证 Zookeeper 集群如何高可用，不仅仅如此，如果 zookeeper 集群出现故障也会影响到 RocketMQ 集群。</li><li>利用 raft 协议来完成一个自动选主，raft 协议相比前者的优点是不需要引入外部组件，自动选主逻辑集成到各个节点的进程中，节点之间通过通信就可以完成选主。</li></ul><p>RocketMQ 最终选择使用 raft 协议来解决这个问题，而 DLedger 就是一个基于 raft 协议的 commitlog 存储库，也是 RocketMQ 实现新的高可用多副本架构的关键。</p><h3 id="3、Dledger-简介"><a href="#3、Dledger-简介" class="headerlink" title="3、Dledger 简介"></a>3、Dledger 简介</h3><p>分布式算法中比较常常听到的是 Paxos 算法，但是由于 Paxos 算法难于理解，且实现比较苦难，所以不太受业界欢迎。然后出现新的分布式算法 Raft，其比 Paxos 更容易懂与实现，到如今在实际中运用的也已经很成熟，不同的语言都有对其的实现。Dledger 就是其中一个 Java 语言的实现，其将算法方面的内容全部抽象掉，这样开发人员只需要关系业务即可，大大降低使用难度。</p><h3 id="4、DLedger-定位"><a href="#4、DLedger-定位" class="headerlink" title="4、DLedger 定位"></a>4、DLedger 定位</h3><p><img src="https://z3.ax1x.com/2021/08/20/fXpo2n.png" alt="img"></p><p>Raft 协议是复制状态机的实现，这种模型应用到消息系统中就会存在问题。对于消息系统来说，它本身是一个中间代理，commitlog 状态是系统最终状态，并不需要状态机再去完成一次状态构建。因此 DLedger 去掉了 raft 协议中状态机的部分，但基于raft协议保证commitlog 是一致的，并且是高可用的。</p><p><img src="https://z3.ax1x.com/2021/08/20/fX9px1.png" alt="img"></p><p>另一方面 DLedger 又是一个轻量级的 java library。它对外提供的 API 非常简单，append 和 get。Append 向 DLedger 添加数据，并且添加的数据会对应一个递增的索引，而 get 可以根据索引去获得相应的数据。因此 DLedger 是一个 append only 的日志系统。</p><h3 id="5、DLedger-应用场景"><a href="#5、DLedger-应用场景" class="headerlink" title="5、DLedger 应用场景"></a>5、DLedger 应用场景</h3><p><img src="https://z3.ax1x.com/2021/08/20/fX98Ig.png" alt="img"></p><p>DLedger 其中一个应用就是在分布式消息系统中，RocketMQ 4.5 版本发布后，可以采用 RocketMQ on DLedger 方式进行部署。DLedger commitlog 代替了原来的 commitlog，使得 commitlog 拥有了选举复制能力，然后通过角色透传的方式，raft 角色透传给外部 broker 角色，leader 对应原来的 master，follower 和 candidate 对应原来的 slave。</p><p>因此 RocketMQ 的 broker 拥有了自动故障转移的能力，在一组 broker 中如果 Master 挂了，能够依靠 DLedger 自动选主能力重新选出一个 leader，然后通过角色透传变成新的 Master。</p><p><img src="https://z3.ax1x.com/2021/08/20/fX9KMt.png" alt="img"></p><p>DLedger 还可以构建高可用的嵌入式 KV 存储。我们把对一些数据的操作记录到 DLedger 中，然后根据数据量或者实际需求，恢复到hashmap 或者 rocksdb 中，从而构建一致的、高可用的 KV 存储系统，应用到元信息管理等场景。</p><h3 id="6、RocketMQ-Dledger-的方案简介"><a href="#6、RocketMQ-Dledger-的方案简介" class="headerlink" title="6、RocketMQ Dledger 的方案简介"></a>6、RocketMQ Dledger 的方案简介</h3><p><img src="https://z3.ax1x.com/2021/08/20/fXiNzd.png" alt="img"></p><p>RocketMQ-on-DLedger Group 是指一组相同名称的 Broker，组中至少需要 3 个 Broker 节点来保证集群能够运行，在 Broker 启动时候，通过 raft 算法能够自动选举出一个 Broker 为 Leader 节点，其余为 Follower 节点。这种模式下 Leader 和 Follower 之间复制数据以保证高可用，如果 Leader 节点出现问题是可以自动进行容灾切换并保证数据一致性。且不仅仅如此，该模式也支持 Broker 节点水平扩展来增加吞吐量。所以该模式将会是部署 RocketMQ 常用模式之一。</p><h2 id="四、RocketMQ-DLedger集群架构"><a href="#四、RocketMQ-DLedger集群架构" class="headerlink" title="四、RocketMQ DLedger集群架构"></a>四、RocketMQ DLedger集群架构</h2><h3 id="1、本例中DLedger集群架构图"><a href="#1、本例中DLedger集群架构图" class="headerlink" title="1、本例中DLedger集群架构图"></a>1、本例中DLedger集群架构图</h3><p><img src="https://z3.ax1x.com/2021/08/20/fXP9HK.png" alt="img"></p><p><strong>这里采用两个分片的集群，这个集群架构和Mongodb的分片集群很像。</strong></p><h3 id="2、具体部署服务器安排"><a href="#2、具体部署服务器安排" class="headerlink" title="2、具体部署服务器安排"></a>2、具体部署服务器安排</h3><p>考虑到为初次压测环境，为了节省资源，只部署了6台服务器（namesrv、console分别部署在不同的broker机器上）。<strong>生产环境，建议考虑部署9-10台服务器，互不影响。</strong></p><table><thead><tr><th>服务器</th><th>部署的应用</th><th>物理资源</th><th>存储挂载目录</th></tr></thead><tbody><tr><td>192.168.1.1</td><td>Namesrv Server、Broker0-no</td><td>4C &amp;&amp; 8G</td><td>/usr/local/rocketmq</td></tr><tr><td>192.168.1.2</td><td>Console、Broker0-n1</td><td>4C &amp;&amp; 8G</td><td>/usr/local/rocketmq</td></tr><tr><td>192.168.1.3</td><td>Broker0-n2</td><td>4C &amp;&amp; 8G</td><td>/usr/local/rocketmq</td></tr><tr><td>192.168.1.4</td><td>Namesrv Server、Broker1-n0</td><td>4C &amp;&amp; 8G</td><td>/usr/local/rocketmq</td></tr><tr><td>192.168.1.5</td><td>Namesrv Server、Broker1-n1</td><td>4C &amp;&amp; 8G</td><td>/usr/local/rocketmq</td></tr><tr><td>192.168.1.6</td><td>Broker1-n2</td><td>4C &amp;&amp; 8G</td><td>/usr/local/rocketmq</td></tr></tbody></table><h3 id="3、环境"><a href="#3、环境" class="headerlink" title="3、环境"></a>3、环境</h3><ul><li>系统版本：Centos 7.9</li><li>Docker 20.10.8</li><li>RocketMQ镜像  apache/rocketmq:4.9.0</li><li>RocketMQ-Console镜像  apacherocketmq/rocketmq-console:2.0.0</li></ul><h2 id="五、部署RocketMQ-DLedger集群"><a href="#五、部署RocketMQ-DLedger集群" class="headerlink" title="五、部署RocketMQ DLedger集群"></a>五、部署RocketMQ DLedger集群</h2><h3 id="1、Dledger集群Broker节点示例配置"><a href="#1、Dledger集群Broker节点示例配置" class="headerlink" title="1、Dledger集群Broker节点示例配置"></a>1、Dledger集群Broker节点示例配置</h3><p>RocketMQ二进制一般自带配置文件（conf目录下），不同的集群使用不同的配置文件。可根据需求做下修改，如本例子使用（/conf/dledger/broker-n0.conf）。</p><pre><code class="bash">## RocketMQ基本配置brokerIP1=192.168.1.1listenPort=30911brokerClusterName=RaftClusterbrokerName=broker0namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLeger 配置dLegerSelfId=n0dLegerGroup=broker0enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.1:40911;192.168.1.2:40911;n2-192.168.1.3:40911sendMessageThreadPoolNums=4</code></pre><h4 id="基本配置参数说明："><a href="#基本配置参数说明：" class="headerlink" title="基本配置参数说明："></a>基本配置参数说明：</h4><table><thead><tr><th>参数名称</th><th>参数描述</th><th>参数示例</th></tr></thead><tbody><tr><td>brokerClusterName</td><td>Broker 集群名称</td><td>RaftCluster（整个集群都一样）</td></tr><tr><td>brokerName</td><td>Broker 名称</td><td>broker0（两分片集群，只有0和1）</td></tr><tr><td>listenPort</td><td>Broker 监听端口</td><td>30911</td></tr><tr><td>namesrvAddr</td><td>Broker Namesrv 地址</td><td>192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876</td></tr><tr><td>storePathRootDir</td><td>Broker 存储目录</td><td>/tmp/rmqstore/node00</td></tr><tr><td>storePathCommitLog</td><td>Commitlog 存储目录</td><td>/tmp/rmqstore/node00/commitlog</td></tr></tbody></table><h4 id="Dledger-配置参数说明："><a href="#Dledger-配置参数说明：" class="headerlink" title="Dledger 配置参数说明："></a>Dledger 配置参数说明：</h4><table><thead><tr><th>参数名称</th><th>参数描述</th><th>参数示例</th></tr></thead><tbody><tr><td>enableDLegerCommitLog</td><td>是否启动 DLedger</td><td>true</td></tr><tr><td>dLegerGroup</td><td>DLedger Raft Group 的名字，建议和 brokerName 保持一致</td><td>broker0</td></tr><tr><td>dLegerPeers</td><td>DLedger Group 内各节点的地址与端口信息（同一个 Group 内的各个节点配置必须要保证一致）</td><td>n0-192.168.1.1:40911;n1-192.168.1.2:40911;n2-192.168.1.3:40911</td></tr><tr><td>dLegerSelfId</td><td>节点 id, 必须属于 dLegerPeers 中的一个；同 Group 内各个节点要唯一</td><td>例如： 第一个节点配置为”n0” 第一个节点配置为”n1” 第一个节点配置为”n2”</td></tr><tr><td>sendMessageThreadPoolNums</td><td>发送线程个数（建议配置成 CPU 核数）</td><td>4</td></tr></tbody></table><h3 id="2、创建存储数据的目录和用户"><a href="#2、创建存储数据的目录和用户" class="headerlink" title="2、创建存储数据的目录和用户"></a>2、创建存储数据的目录和用户</h3><ol><li><p>分别在六台机器上创建以下目录</p><pre><code class="bash">## 创建 Broker 和 NameServer 持久化目录mkdir -p /usr/local/rocketmq/broker/conf &amp;&amp; \mkdir -p /usr/local/rocketmq/broker/logs &amp;&amp; \mkdir -p /usr/local/rocketmq/broker/store &amp;&amp; \mkdir -p /usr/local/rocketmq/server/logs</code></pre></li><li><p>创建rocketmq用户，并修改目录权限</p><pre><code class="bash">groupadd -g 3000 rocketmquseradd -u 3000 -g rocketmq -M  -s /sbin/nologin rocketmqchown -R rocketmq:rocketmq /usr/local/rocketmq</code></pre></li></ol><p><strong>注意：Docker容器挂载文件很容易涉及到权限问题，通过<code>docker history apache/rocketmq </code>可以看到镜像中使用的用户和用户组。</strong></p><h3 id="3、创建Broker配置文件"><a href="#3、创建Broker配置文件" class="headerlink" title="3、创建Broker配置文件"></a>3、创建Broker配置文件</h3><p>在六台服务器上，分别创建不同的配置文件broker.conf。</p><p>其中，重点注意：<strong>brokerName每个分片保持一致，dLegerSelfId同一分片内不能相同，dLegerPeers为本分片内的成员。</strong></p><ul><li><p>分片1，服务器1 ，192.168.1.1</p><pre><code class="bash">cat &gt; /usr/local/rocketmq/broker/conf/broker.conf &lt;&lt; EOFbrokerIP1=192.168.1.1listenPort=30911brokerClusterName=RaftClusterbrokerName=broker0namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLegerdLegerSelfId=n0dLegerGroup=broker0enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.1:40911;192.168.1.2:40911;n2-192.168.1.3:40911sendMessageThreadPoolNums=4EOF</code></pre></li><li><p>分片1 ，服务器2，192.168.1.2</p><pre><code class="bash">cat &gt; /usr/local/rocketmq/broker/conf/broker.conf &lt;&lt; EOFbrokerIP1=192.168.1.2listenPort=30911brokerClusterName=RaftClusterbrokerName=broker0namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLegerdLegerSelfId=n1dLegerGroup=broker0enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.1:40911;192.168.1.2:40911;n2-192.168.1.3:40911sendMessageThreadPoolNums=4EOF</code></pre></li><li><p>分片1，服务器3 ，192.168.1.3</p><pre><code class="bas">cat &gt; /usr/local/rocketmq/broker/conf/broker.conf &lt;&lt; EOFbrokerIP1=192.168.1.3listenPort=30911brokerClusterName=RaftClusterbrokerName=broker0namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLegerdLegerSelfId=n2dLegerGroup=broker0enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.1:40911;192.168.1.2:40911;n2-192.168.1.3:40911sendMessageThreadPoolNums=4EOF</code></pre></li><li><p>分片2，服务器4，192.168.1.4</p><pre><code class="bash">cat &gt; /usr/local/rocketmq/broker/conf/broker.conf &lt;&lt; EOFbrokerIP1=192.168.1.4listenPort=30911brokerClusterName=RaftClusterbrokerName=broker1namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLegerdLegerSelfId=n0dLegerGroup=broker1enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.4:40911;192.168.1.5:40911;n2-192.168.1.6:40911sendMessageThreadPoolNums=4EOF</code></pre></li><li><p>分片2，服务器5，192.168.1.5</p><pre><code class="bash">cat &gt; /usr/local/rocketmq/broker/conf/broker.conf &lt;&lt; EOFbrokerIP1=192.168.1.5listenPort=30911brokerClusterName=RaftClusterbrokerName=broker1namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLegerdLegerSelfId=n1dLegerGroup=broker1enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.4:40911;192.168.1.5:40911;n2-192.168.1.6:40911sendMessageThreadPoolNums=4EOF</code></pre></li><li><p>分片2，服务器6，192.168.1.6</p><pre><code class="bash">cat &gt; /usr/local/rocketmq/broker/conf/broker.conf &lt;&lt; EOFbrokerIP1=192.168.1.6listenPort=30911brokerClusterName=RaftClusterbrokerName=broker1namesrvAddr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876storePathRootDir=/home/rocketmq/rmqstore/storePathCommitLog=/home/rocketmq/rmqstore/commitlog## DLegerdLegerSelfId=n2dLegerGroup=broker1enableDLegerCommitLog=true## must be uniquedLegerPeers=n0-192.168.1.4:40911;192.168.1.5:40911;n2-192.168.1.6:40911sendMessageThreadPoolNums=4EOF</code></pre><h3 id="4、下载相关镜像"><a href="#4、下载相关镜像" class="headerlink" title="4、下载相关镜像"></a>4、下载相关镜像</h3><p>按照上面部署服务器安排，在不同的服务器上拉取相应的镜像</p><pre><code class="bash">docker pull apache/rocketmq:4.9.0docker pull apacherocketmq/rocketmq-console:2.0.0</code></pre><h3 id="5、安装NameServer"><a href="#5、安装NameServer" class="headerlink" title="5、安装NameServer"></a>5、安装NameServer</h3><p>在规划好的nameserver机器上，执行start_namesrv.sh脚本</p><pre><code class="bash">#!/bin/bashdocker run -d --name rmqnamesrv --net host \-v /usr/local/rocketmq/server/logs:/home/rocketmq/logs \-e &quot;JAVA_OPT_EXT=-Xms512M -Xmx512M -Xmn128m&quot; \--restart=always \apache/rocketmq:4.9.0 \sh mqnamesrv</code></pre><h3 id="6、安装Broker"><a href="#6、安装Broker" class="headerlink" title="6、安装Broker"></a>6、安装Broker</h3><p>在每台机器上，执行more start_broker.sh脚本</p><pre><code class="bash">#!/bin/bashdocker run -d --name rmqbroker --net host \-e &quot;JAVA_OPT_EXT=-Xmx5120m -Xms5120m -Xmn2048m&quot; \-v /usr/local/rocketmq/broker/logs:/home/rocketmq/logs \-v /usr/local/rocketmq/broker/store:/home/rocketmq/rmqstore \-v /usr/local/rocketmq/broker/conf:/home/rocketmq/conf \--restart=always \apache/rocketmq:4.9.0 \sh mqbroker -c /home/rocketmq/conf/broker.conf</code></pre><h3 id="7、部署控制台Console"><a href="#7、部署控制台Console" class="headerlink" title="7、部署控制台Console"></a>7、部署控制台Console</h3><p>在一台服务器上，执行start_console.sh 脚本</p><pre><code class="bash">#!/bin/bashdocker run -d --name rmqconsole \-p 8080:8080 \--restart=always \-e &quot;JAVA_OPTS=-Xms512M -Xmx512M -Xmn128m -Drocketmq.namesrv.addr=192.168.1.1:9876;192.168.1.4:9876;192.168.1.5:9876  -Dcom.rocketmq.sendMessageWithVIPChannel=false&quot; \apacherocketmq/rocketmq-console:2.0.0</code></pre><p><strong>注意：namesrv地址和上面broker的配置文件保持一致。</strong></p><h3 id="8、访问控制台"><a href="#8、访问控制台" class="headerlink" title="8、访问控制台"></a>8、访问控制台</h3><p>输入<a href="http://192.168.1.2:8080访问额在服务器上部署的RocketMQ控制台，进入到如下界面。">http://192.168.1.2:8080访问额在服务器上部署的RocketMQ控制台，进入到如下界面。</a></p><p><a href="https://imgtu.com/i/fXdYbn"><img src="https://z3.ax1x.com/2021/08/20/fXdYbn.png" alt="fXdYbn.png"></a></p><p>然后我们可以通过该控制台进行发送消息来验证 RocketMQ 是否成功部署，这里就交由大家自行验证了。</p></li></ul><h2 id="六、参考网址"><a href="#六、参考网址" class="headerlink" title="六、参考网址"></a>六、参考网址</h2><ul><li><a href="https://juejin.im/post/6844904008629354504">浅入浅出RocketMQ</a></li><li><a href="https://github.com/apache/rocketmq">RocketMQ Github 地址</a></li><li><a href="https://github.com/apache/rocketmq/blob/master/docs/cn/dledger/deploy_guide.md">RocketMQ Dledger 集群搭建</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、RocketMQ组件介绍&quot;&gt;&lt;a href=&quot;#一、RocketMQ组件介绍&quot; class=&quot;headerlink&quot; title=&quot;一、RocketMQ组件介绍&quot;&gt;&lt;/a&gt;一、RocketMQ组件介绍&lt;/h2&gt;&lt;p&gt;这里介绍下 RocketMQ 相关的组件：&lt;</summary>
      
    
    
    
    <category term="中间件" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="RocketMQ" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"/>
    
    
    <category term="RocketMQ" scheme="https://www.langxw.com/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>Centos系统日常巡检脚本</title>
    <link href="https://www.langxw.com/2021/11/30/Centos%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%B8%B8%E5%B7%A1%E6%A3%80%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.langxw.com/2021/11/30/Centos%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%B8%B8%E5%B7%A1%E6%A3%80%E8%84%9A%E6%9C%AC/</id>
    <published>2021-11-30T09:19:25.000Z</published>
    <updated>2021-11-30T09:24:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h2><p><strong>Centos系统日常巡检脚本，巡检内容包含了，磁盘，内存 cpu 进程 文件更改 用户登录等一系列的操作 直接用就行了。</strong></p><p>报告以邮件发送到邮箱 在log下生成巡检报告。</p><h2 id="二、内容"><a href="#二、内容" class="headerlink" title="二、内容"></a>二、内容</h2><p>创建HostDailyCheck.sh文件，具体内容如下：</p><pre><code class="bash">#!/bin/bash#主机信息每日巡检IPADDR=$(ifconfig eth0|grep &#39;inet addr&#39;|awk -F &#39;[ :]&#39; &#39;&#123;print $13&#125;&#39;)#环境变量PATH没设好，在cron里执行时有很多命令会找不到export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binsource /etc/profile[ $(id -u) -gt 0 ] &amp;&amp; echo &quot;请用root用户执行此脚本！&quot; &amp;&amp; exit 1centosVersion=$(awk &#39;&#123;print $(NF-1)&#125;&#39; /etc/redhat-release)VERSION=&quot;2020-03-16&quot;#日志相关PROGPATH=`echo $0 | sed -e &#39;s,[\\/][^\\/][^\\/]*$,,&#39;`[ -f $PROGPATH ] &amp;&amp; PROGPATH=&quot;.&quot;LOGPATH=&quot;$PROGPATH/log&quot;[ -e $LOGPATH ] || mkdir $LOGPATHRESULTFILE=&quot;$LOGPATH/HostDailyCheck-$IPADDR-`date +%Y%m%d`.txt&quot;#定义报表的全局变量report_DateTime=&quot;&quot; #日期 okreport_Hostname=&quot;&quot; #主机名 okreport_OSRelease=&quot;&quot; #发行版本 okreport_Kernel=&quot;&quot; #内核 okreport_Language=&quot;&quot; #语言/编码 okreport_LastReboot=&quot;&quot; #最近启动时间 okreport_Uptime=&quot;&quot; #运行时间（天） okreport_CPUs=&quot;&quot; #CPU数量 okreport_CPUType=&quot;&quot; #CPU类型 okreport_Arch=&quot;&quot; #CPU架构 okreport_MemTotal=&quot;&quot; #内存总容量(MB) okreport_MemFree=&quot;&quot; #内存剩余(MB) okreport_MemUsedPercent=&quot;&quot; #内存使用率% okreport_DiskTotal=&quot;&quot; #硬盘总容量(GB) okreport_DiskFree=&quot;&quot; #硬盘剩余(GB) okreport_DiskUsedPercent=&quot;&quot; #硬盘使用率% okreport_InodeTotal=&quot;&quot; #Inode总量 okreport_InodeFree=&quot;&quot; #Inode剩余 okreport_InodeUsedPercent=&quot;&quot; #Inode使用率 okreport_IP=&quot;&quot; #IP地址 okreport_MAC=&quot;&quot; #MAC地址 okreport_Gateway=&quot;&quot; #默认网关 okreport_DNS=&quot;&quot; #DNS okreport_Listen=&quot;&quot; #监听 okreport_Selinux=&quot;&quot; #Selinux okreport_Firewall=&quot;&quot; #防火墙 okreport_USERs=&quot;&quot; #用户 okreport_USEREmptyPassword=&quot;&quot; #空密码用户 okreport_USERTheSameUID=&quot;&quot; #相同ID的用户 ok report_PasswordExpiry=&quot;&quot; #密码过期（天） okreport_RootUser=&quot;&quot; #root用户 okreport_Sudoers=&quot;&quot; #sudo授权 okreport_SSHAuthorized=&quot;&quot; #SSH信任主机 okreport_SSHDProtocolVersion=&quot;&quot; #SSH协议版本 okreport_SSHDPermitRootLogin=&quot;&quot; #允许root远程登录 okreport_DefunctProsess=&quot;&quot; #僵尸进程数量 okreport_SelfInitiatedService=&quot;&quot; #自启动服务数量 okreport_SelfInitiatedProgram=&quot;&quot; #自启动程序数量 okreport_RuningService=&quot;&quot; #运行中服务数 okreport_Crontab=&quot;&quot; #计划任务数 okreport_Syslog=&quot;&quot; #日志服务 okreport_SNMP=&quot;&quot; #SNMP OKreport_NTP=&quot;&quot; #NTP okreport_JDK=&quot;&quot; #JDK版本 okfunction version()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;系统巡检脚本：Version $VERSION&quot;&#125;function getCpuStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ CPU检查 #############################&quot;Physical_CPUs=$(grep &quot;physical id&quot; /proc/cpuinfo| sort | uniq | wc -l)Virt_CPUs=$(grep &quot;processor&quot; /proc/cpuinfo | wc -l)CPU_Kernels=$(grep &quot;cores&quot; /proc/cpuinfo|uniq| awk -F &#39;: &#39; &#39;&#123;print $2&#125;&#39;)CPU_Type=$(grep &quot;model name&quot; /proc/cpuinfo | awk -F &#39;: &#39; &#39;&#123;print $2&#125;&#39; | sort | uniq)CPU_Arch=$(uname -m)echo &quot;物理CPU个数:$Physical_CPUs&quot;echo &quot;逻辑CPU个数:$Virt_CPUs&quot;echo &quot;每CPU核心数:$CPU_Kernels&quot;echo &quot; CPU型号:$CPU_Type&quot;echo &quot; CPU架构:$CPU_Arch&quot;#报表信息report_CPUs=$Virt_CPUs #CPU数量report_CPUType=$CPU_Type #CPU类型report_Arch=$CPU_Arch #CPU架构&#125;function getMemStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 内存检查 ############################&quot;if [[ $centosVersion &lt; 7 ]];thenfree -moelsefree -hfi#报表信息MemTotal=$(grep MemTotal /proc/meminfo| awk &#39;&#123;print $2&#125;&#39;) #KBMemFree=$(grep MemFree /proc/meminfo| awk &#39;&#123;print $2&#125;&#39;) #KBlet MemUsed=MemTotal-MemFreeMemPercent=$(awk &quot;BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \&quot;%.2f\&quot;,$MemUsed*100/$MemTotal&#125;&#125;&quot;)report_MemTotal=&quot;$((MemTotal/1024))&quot;&quot;MB&quot; #内存总容量(MB)report_MemFree=&quot;$((MemFree/1024))&quot;&quot;MB&quot; #内存剩余(MB)report_MemUsedPercent=&quot;$(awk &quot;BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \&quot;%.2f\&quot;,$MemUsed*100/$MemTotal&#125;&#125;&quot;)&quot;&quot;%&quot; #内存使用率%&#125;function getDiskStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 磁盘检查 ############################&quot;df -hiP | sed &#39;s/Mounted on/Mounted/&#39;&gt; /tmp/inodedf -hTP | sed &#39;s/Mounted on/Mounted/&#39;&gt; /tmp/disk join /tmp/disk /tmp/inode | awk &#39;&#123;print $1,$2,&quot;|&quot;,$3,$4,$5,$6,&quot;|&quot;,$8,$9,$10,$11,&quot;|&quot;,$12&#125;&#39;| column -t#报表信息diskdata=$(df -TP | sed &#39;1d&#39; | awk &#39;$2!=&quot;tmpfs&quot;&#123;print&#125;&#39;) #KBdisktotal=$(echo &quot;$diskdata&quot; | awk &#39;&#123;total+=$3&#125;END&#123;print total&#125;&#39;) #KBdiskused=$(echo &quot;$diskdata&quot; | awk &#39;&#123;total+=$4&#125;END&#123;print total&#125;&#39;) #KBdiskfree=$((disktotal-diskused)) #KBdiskusedpercent=$(echo $disktotal $diskused | awk &#39;&#123;if($1==0)&#123;printf 100&#125;else&#123;printf &quot;%.2f&quot;,$2*100/$1&#125;&#125;&#39;) inodedata=$(df -iTP | sed &#39;1d&#39; | awk &#39;$2!=&quot;tmpfs&quot;&#123;print&#125;&#39;)inodetotal=$(echo &quot;$inodedata&quot; | awk &#39;&#123;total+=$3&#125;END&#123;print total&#125;&#39;)inodeused=$(echo &quot;$inodedata&quot; | awk &#39;&#123;total+=$4&#125;END&#123;print total&#125;&#39;)inodefree=$((inodetotal-inodeused))inodeusedpercent=$(echo $inodetotal $inodeused | awk &#39;&#123;if($1==0)&#123;printf 100&#125;else&#123;printf &quot;%.2f&quot;,$2*100/$1&#125;&#125;&#39;)report_DiskTotal=$((disktotal/1024/1024))&quot;GB&quot; #硬盘总容量(GB)report_DiskFree=$((diskfree/1024/1024))&quot;GB&quot; #硬盘剩余(GB)report_DiskUsedPercent=&quot;$diskusedpercent&quot;&quot;%&quot; #硬盘使用率%report_InodeTotal=$((inodetotal/1000))&quot;K&quot; #Inode总量report_InodeFree=$((inodefree/1000))&quot;K&quot; #Inode剩余report_InodeUsedPercent=&quot;$inodeusedpercent&quot;&quot;%&quot; #Inode使用率%&#125;function getSystemStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 系统检查 ############################&quot;if [ -e /etc/sysconfig/i18n ];thendefault_LANG=&quot;$(grep &quot;LANG=&quot; /etc/sysconfig/i18n | grep -v &quot;^#&quot; | awk -F &#39;&quot;&#39; &#39;&#123;print $2&#125;&#39;)&quot;elsedefault_LANG=$LANGfiexport LANG=&quot;en_US.UTF-8&quot;Release=$(cat /etc/redhat-release 2&gt;/dev/null)Kernel=$(uname -r)OS=$(uname -o)Hostname=$(uname -n)SELinux=$(/usr/sbin/sestatus | grep &quot;SELinux status: &quot; | awk &#39;&#123;print $3&#125;&#39;)LastReboot=$(who -b | awk &#39;&#123;print $3,$4&#125;&#39;)uptime=$(uptime | sed &#39;s/.*up \([^,]*\), .*/\1/&#39;)echo &quot; 系统：$OS&quot;echo &quot; 发行版本：$Release&quot;echo &quot; 内核：$Kernel&quot;echo &quot; 主机名：$Hostname&quot;echo &quot; SELinux：$SELinux&quot;echo &quot;语言/编码：$default_LANG&quot;echo &quot; 当前时间：$(date +&#39;%F %T&#39;)&quot;echo &quot; 最后启动：$LastReboot&quot;echo &quot; 运行时间：$uptime&quot;#报表信息report_DateTime=$(date +&quot;%F %T&quot;) #日期report_Hostname=&quot;$Hostname&quot; #主机名report_OSRelease=&quot;$Release&quot; #发行版本report_Kernel=&quot;$Kernel&quot; #内核report_Language=&quot;$default_LANG&quot; #语言/编码report_LastReboot=&quot;$LastReboot&quot; #最近启动时间report_Uptime=&quot;$uptime&quot; #运行时间（天）report_Selinux=&quot;$SELinux&quot;export LANG=&quot;$default_LANG&quot;&#125;function getServiceStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 服务检查 ############################&quot;echo &quot;&quot;if [[ $centosVersion &gt; 7 ]];thenconf=$(systemctl list-unit-files --type=service --state=enabled --no-pager | grep &quot;enabled&quot;)process=$(systemctl list-units --type=service --state=running --no-pager | grep &quot;.service&quot;)#报表信息report_SelfInitiatedService=&quot;$(echo &quot;$conf&quot; | wc -l)&quot; #自启动服务数量report_RuningService=&quot;$(echo &quot;$process&quot; | wc -l)&quot; #运行中服务数量elseconf=$(/sbin/chkconfig | grep -E &quot;:on|:启用&quot;)process=$(/sbin/service --status-all 2&gt;/dev/null | grep -E &quot;is running|正在运行&quot;)#报表信息report_SelfInitiatedService=&quot;$(echo &quot;$conf&quot; | wc -l)&quot; #自启动服务数量report_RuningService=&quot;$(echo &quot;$process&quot; | wc -l)&quot; #运行中服务数量fiecho &quot;服务配置&quot;echo &quot;--------&quot;echo &quot;$conf&quot; | column -techo &quot;&quot;echo &quot;正在运行的服务&quot;echo &quot;--------------&quot;echo &quot;$process&quot;&#125;function getAutoStartStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 自启动检查 ##########################&quot;conf=$(grep -v &quot;^#&quot; /etc/rc.d/rc.local| sed &#39;/^$/d&#39;)echo &quot;$conf&quot;#报表信息report_SelfInitiatedProgram=&quot;$(echo $conf | wc -l)&quot; #自启动程序数量&#125;function getLoginStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 登录检查 ############################&quot;last | head&#125;function getNetworkStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 网络检查 ############################&quot;if [[ $centosVersion &lt; 7 ]];then/sbin/ifconfig -a | grep -v packets | grep -v collisions | grep -v inet6else#ip afor i in $(ip link | grep BROADCAST | awk -F: &#39;&#123;print $2&#125;&#39;);do ip add show $i | grep -E &quot;BROADCAST|global&quot;| awk &#39;&#123;print $2&#125;&#39; | tr &#39;\n&#39; &#39; &#39; ;echo &quot;&quot; ;donefiGATEWAY=$(ip route | grep default | awk &#39;&#123;print $3&#125;&#39;)DNS=$(grep nameserver /etc/resolv.conf| grep -v &quot;#&quot; | awk &#39;&#123;print $2&#125;&#39; | tr &#39;\n&#39; &#39;,&#39; | sed &#39;s/,$//&#39;)echo &quot;&quot;echo &quot;网关：$GATEWAY &quot;echo &quot; DNS：$DNS&quot;#报表信息IP=$(ip -f inet addr | grep -v 127.0.0.1 | grep inet | awk &#39;&#123;print $NF,$2&#125;&#39; | tr &#39;\n&#39; &#39;,&#39; | sed &#39;s/,$//&#39;)MAC=$(ip link | grep -v &quot;LOOPBACK\|loopback&quot; | awk &#39;&#123;print $2&#125;&#39; | sed &#39;N;s/\n//&#39; | tr &#39;\n&#39; &#39;,&#39; | sed &#39;s/,$//&#39;)report_IP=&quot;$IP&quot; #IP地址report_MAC=$MAC #MAC地址report_Gateway=&quot;$GATEWAY&quot; #默认网关report_DNS=&quot;$DNS&quot; #DNS&#125;function getListenStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 监听检查 ############################&quot;TCPListen=$(ss -ntul | column -t)echo &quot;$TCPListen&quot;#报表信息report_Listen=&quot;$(echo &quot;$TCPListen&quot;| sed &#39;1d&#39; | awk &#39;/tcp/ &#123;print $5&#125;&#39; | awk -F: &#39;&#123;print $NF&#125;&#39; | sort | uniq | wc -l)&quot;&#125;function getCronStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 计划任务检查 ########################&quot;Crontab=0for shell in $(grep -v &quot;/sbin/nologin&quot; /etc/shells);dofor user in $(grep &quot;$shell&quot; /etc/passwd| awk -F: &#39;&#123;print $1&#125;&#39;);docrontab -l -u $user &gt;/dev/null 2&gt;&amp;1status=$?if [ $status -eq 0 ];thenecho &quot;$user&quot;echo &quot;--------&quot;crontab -l -u $userlet Crontab=Crontab+$(crontab -l -u $user | wc -l)echo &quot;&quot;fidonedone#计划任务find /etc/cron* -type f | xargs -i ls -l &#123;&#125; | column -tlet Crontab=Crontab+$(find /etc/cron* -type f | wc -l)#报表信息report_Crontab=&quot;$Crontab&quot; #计划任务数&#125;function getHowLongAgo()&#123;# 计算一个时间戳离现在有多久了datetime=&quot;$*&quot;[ -z &quot;$datetime&quot; ] &amp;&amp; echo &quot;错误的参数：getHowLongAgo() $*&quot;Timestamp=$(date +%s -d &quot;$datetime&quot;) #转化为时间戳Now_Timestamp=$(date +%s)Difference_Timestamp=$(($Now_Timestamp-$Timestamp))days=0;hours=0;minutes=0;sec_in_day=$((60*60*24));sec_in_hour=$((60*60));sec_in_minute=60while (( $(($Difference_Timestamp-$sec_in_day)) &gt; 1 ))dolet Difference_Timestamp=Difference_Timestamp-sec_in_daylet days++donewhile (( $(($Difference_Timestamp-$sec_in_hour)) &gt; 1 ))dolet Difference_Timestamp=Difference_Timestamp-sec_in_hourlet hours++doneecho &quot;$days 天 $hours 小时前&quot;&#125;function getUserLastLogin()&#123;# 获取用户最近一次登录的时间，含年份# 很遗憾last命令不支持显示年份，只有&quot;last -t YYYYMMDDHHMMSS&quot;表示某个时间之间的登录，我# 们只能用最笨的方法了，对比今天之前和今年元旦之前（或者去年之前和前年之前……）某个用户# 登录次数，如果登录统计次数有变化，则说明最近一次登录是今年。username=$1: $&#123;username:=&quot;`whoami`&quot;&#125;thisYear=$(date +%Y)oldesYear=$(last | tail -n1 | awk &#39;&#123;print $NF&#125;&#39;)while(( $thisYear &gt;= $oldesYear));dologinBeforeToday=$(last $username | grep $username | wc -l)loginBeforeNewYearsDayOfThisYear=$(last $username -t $thisYear&quot;0101000000&quot; | grep $username | wc -l)if [ $loginBeforeToday -eq 0 ];thenecho &quot;从未登录过&quot;breakelif [ $loginBeforeToday -gt $loginBeforeNewYearsDayOfThisYear ];thenlastDateTime=$(last -i $username | head -n1 | awk &#39;&#123;for(i=4;i&lt;(NF-2);i++)printf&quot;%s &quot;,$i&#125;&#39;)&quot; $thisYear&quot; #格式如: Sat Nov 2 20:33 2015lastDateTime=$(date &quot;+%Y-%m-%d %H:%M:%S&quot; -d &quot;$lastDateTime&quot;)echo &quot;$lastDateTime&quot;breakelsethisYear=$((thisYear-1))fidone&#125;function getUserStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 用户检查 ############################&quot;#/etc/passwd 最后修改时间pwdfile=&quot;$(cat /etc/passwd)&quot;Modify=$(stat /etc/passwd | grep Modify | tr &#39;.&#39; &#39; &#39; | awk &#39;&#123;print $2,$3&#125;&#39;)echo &quot;/etc/passwd 最后修改时间：$Modify ($(getHowLongAgo $Modify))&quot;echo &quot;&quot;echo &quot;特权用户&quot;echo &quot;--------&quot;RootUser=&quot;&quot;for user in $(echo &quot;$pwdfile&quot; | awk -F: &#39;&#123;print $1&#125;&#39;);doif [ $(id -u $user) -eq 0 ];thenecho &quot;$user&quot;RootUser=&quot;$RootUser,$user&quot;fidoneecho &quot;&quot;echo &quot;用户列表&quot;echo &quot;--------&quot;USERs=0echo &quot;$(echo &quot;用户名 UID GID HOME SHELL 最后一次登录&quot;for shell in $(grep -v &quot;/sbin/nologin&quot; /etc/shells);dofor username in $(grep &quot;$shell&quot; /etc/passwd| awk -F: &#39;&#123;print $1&#125;&#39;);douserLastLogin=&quot;$(getUserLastLogin $username)&quot;echo &quot;$pwdfile&quot; | grep -w &quot;$username&quot; |grep -w &quot;$shell&quot;| awk -F: -v lastlogin=&quot;$(echo &quot;$userLastLogin&quot; | tr &#39; &#39; &#39;_&#39;)&quot; &#39;&#123;print $1,$3,$4,$6,$7,lastlogin&#125;&#39;donelet USERs=USERs+$(echo &quot;$pwdfile&quot; | grep &quot;$shell&quot;| wc -l)done)&quot; | column -techo &quot;&quot;echo &quot;空密码用户&quot;echo &quot;----------&quot;USEREmptyPassword=&quot;&quot;for shell in $(grep -v &quot;/sbin/nologin&quot; /etc/shells);dofor user in $(echo &quot;$pwdfile&quot; | grep &quot;$shell&quot; | cut -d: -f1);dor=$(awk -F: &#39;$2==&quot;!!&quot;&#123;print $1&#125;&#39; /etc/shadow | grep -w $user)if [ ! -z $r ];thenecho $rUSEREmptyPassword=&quot;$USEREmptyPassword,&quot;$rfidone doneecho &quot;&quot;echo &quot;相同ID的用户&quot;echo &quot;------------&quot;USERTheSameUID=&quot;&quot;UIDs=$(cut -d: -f3 /etc/passwd | sort | uniq -c | awk &#39;$1&gt;1&#123;print $2&#125;&#39;)for uid in $UIDs;doecho -n &quot;$uid&quot;;USERTheSameUID=&quot;$uid&quot;r=$(awk -F: &#39;ORS=&quot;&quot;;$3==&#39;&quot;$uid&quot;&#39;&#123;print &quot;:&quot;,$1&#125;&#39; /etc/passwd)echo &quot;$r&quot;echo &quot;&quot;USERTheSameUID=&quot;$USERTheSameUID $r,&quot;done#报表信息report_USERs=&quot;$USERs&quot; #用户report_USEREmptyPassword=$(echo $USEREmptyPassword | sed &#39;s/^,//&#39;) report_USERTheSameUID=$(echo $USERTheSameUID | sed &#39;s/,$//&#39;) report_RootUser=$(echo $RootUser | sed &#39;s/^,//&#39;) #特权用户&#125;function getPasswordStatus &#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 密码检查 ############################&quot;pwdfile=&quot;$(cat /etc/passwd)&quot;echo &quot;&quot;echo &quot;密码过期检查&quot;echo &quot;------------&quot;result=&quot;&quot;for shell in $(grep -v &quot;/sbin/nologin&quot; /etc/shells);dofor user in $(echo &quot;$pwdfile&quot; | grep &quot;$shell&quot; | cut -d: -f1);doget_expiry_date=$(/usr/bin/chage -l $user | grep &#39;Password expires&#39; | cut -d: -f2)if [[ $get_expiry_date = &#39; never&#39; || $get_expiry_date = &#39;never&#39; ]];thenprintf &quot;%-15s 永不过期\n&quot; $userresult=&quot;$result,$user:never&quot;elsepassword_expiry_date=$(date -d &quot;$get_expiry_date&quot; &quot;+%s&quot;)current_date=$(date &quot;+%s&quot;)diff=$(($password_expiry_date-$current_date))let DAYS=$(($diff/(60*60*24)))printf &quot;%-15s %s天后过期\n&quot; $user $DAYSresult=&quot;$result,$user:$DAYS days&quot;fidonedonereport_PasswordExpiry=$(echo $result | sed &#39;s/^,//&#39;)echo &quot;&quot;echo &quot;密码策略检查&quot;echo &quot;------------&quot;grep -v &quot;#&quot; /etc/login.defs | grep -E &quot;PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_MIN_LEN|PASS_WARN_AGE&quot;&#125;function getSudoersStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ Sudoers检查 #########################&quot;conf=$(grep -v &quot;^#&quot; /etc/sudoers| grep -v &quot;^Defaults&quot; | sed &#39;/^$/d&#39;)echo &quot;$conf&quot;echo &quot;&quot;#报表信息report_Sudoers=&quot;$(echo $conf | wc -l)&quot;&#125;function getInstalledStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 软件检查 ############################&quot;rpm -qa --last | head | column -t &#125;function getProcessStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 进程检查 ############################&quot;if [ $(ps -ef | grep defunct | grep -v grep | wc -l) -ge 1 ];thenecho &quot;&quot;echo &quot;僵尸进程&quot;;echo &quot;--------&quot;ps -ef | head -n1ps -ef | grep defunct | grep -v grepfiecho &quot;&quot;echo &quot;内存占用TOP10&quot;echo &quot;-------------&quot;echo -e &quot;PID %MEM RSS COMMAND$(ps aux | awk &#39;&#123;print $2, $4, $6, $11&#125;&#39; | sort -k3rn | head -n 10 )&quot;| column -t echo &quot;&quot;echo &quot;CPU占用TOP10&quot;echo &quot;------------&quot;top b -n1 | head -17 | tail -11#报表信息report_DefunctProsess=&quot;$(ps -ef | grep defunct | grep -v grep|wc -l)&quot;&#125;function getJDKStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ JDK检查 #############################&quot;java -version 2&gt;/dev/nullif [ $? -eq 0 ];thenjava -version 2&gt;&amp;1fiecho &quot;JAVA_HOME=\&quot;$JAVA_HOME\&quot;&quot;#报表信息report_JDK=&quot;$(java -version 2&gt;&amp;1 | grep version | awk &#39;&#123;print $1,$3&#125;&#39; | tr -d &#39;&quot;&#39;)&quot;&#125;function getSyslogStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ syslog检查 ##########################&quot;echo &quot;服务状态：$(getState rsyslog)&quot;echo &quot;&quot;echo &quot;/etc/rsyslog.conf&quot;echo &quot;-----------------&quot;cat /etc/rsyslog.conf 2&gt;/dev/null | grep -v &quot;^#&quot; | grep -v &quot;^\\$&quot; | sed &#39;/^$/d&#39; | column -t#报表信息report_Syslog=&quot;$(getState rsyslog)&quot;&#125;function getFirewallStatus()&#123;echo &quot;&quot;echo &quot;&quot;echo &quot;############################ 防火墙检查 ##########################&quot;#防火墙状态，策略等if [[ $centosVersion &lt; 7 ]];then/etc/init.d/iptables status &gt;/dev/null 2&gt;&amp;1status=$?if [ $status -eq 0 ];thens=&quot;active&quot;elif [ $status -eq 3 ];thens=&quot;inactive&quot;elif [ $status -eq 4 ];thens=&quot;permission denied&quot;elses=&quot;unknown&quot;fielses=&quot;$(getState iptables)&quot;fiecho &quot;iptables: $s&quot;echo &quot;&quot;echo &quot;/etc/sysconfig/iptables&quot;echo &quot;-----------------------&quot;cat /etc/sysconfig/iptables 2&gt;/dev/null#报表信息report_Firewall=&quot;$s&quot;&#125;function getSNMPStatus()&#123;#SNMP服务状态，配置等echo &quot;&quot;echo &quot;&quot;echo &quot;############################ SNMP检查 ############################&quot;status=&quot;$(getState snmpd)&quot;echo &quot;服务状态：$status&quot;echo &quot;&quot;if [ -e /etc/snmp/snmpd.conf ];thenecho &quot;/etc/snmp/snmpd.conf&quot;echo &quot;--------------------&quot;cat /etc/snmp/snmpd.conf 2&gt;/dev/null | grep -v &quot;^#&quot; | sed &#39;/^$/d&#39;fi#报表信息report_SNMP=&quot;$(getState snmpd)&quot;&#125;function getState()&#123;if [[ $centosVersion &lt; 7 ]];thenif [ -e &quot;/etc/init.d/$1&quot; ];thenif [ `/etc/init.d/$1 status 2&gt;/dev/null | grep -E &quot;is running|正在运行&quot; | wc -l` -ge 1 ];thenr=&quot;active&quot;elser=&quot;inactive&quot;fielser=&quot;unknown&quot;fielse#CentOS 7+r=&quot;$(systemctl is-active $1 2&gt;&amp;1)&quot;fiecho &quot;$r&quot;&#125;function getSSHStatus()&#123;#SSHD服务状态，配置,受信任主机等echo &quot;&quot;echo &quot;&quot;echo &quot;############################ SSH检查 #############################&quot;#检查受信任主机pwdfile=&quot;$(cat /etc/passwd)&quot;echo &quot;服务状态：$(getState sshd)&quot;Protocol_Version=$(cat /etc/ssh/sshd_config | grep Protocol | awk &#39;&#123;print $2&#125;&#39;)echo &quot;SSH协议版本：$Protocol_Version&quot;echo &quot;&quot;echo &quot;信任主机&quot;echo &quot;--------&quot;authorized=0for user in $(echo &quot;$pwdfile&quot; | grep /bin/bash | awk -F: &#39;&#123;print $1&#125;&#39;);doauthorize_file=$(echo &quot;$pwdfile&quot; | grep -w $user | awk -F: &#39;&#123;printf $6&quot;/.ssh/authorized_keys&quot;&#125;&#39;)authorized_host=$(cat $authorize_file 2&gt;/dev/null | awk &#39;&#123;print $3&#125;&#39; | tr &#39;\n&#39; &#39;,&#39; | sed &#39;s/,$//&#39;)if [ ! -z $authorized_host ];thenecho &quot;$user 授权 \&quot;$authorized_host\&quot; 无密码访问&quot;filet authorized=authorized+$(cat $authorize_file 2&gt;/dev/null | awk &#39;&#123;print $3&#125;&#39;|wc -l)doneecho &quot;&quot;echo &quot;是否允许ROOT远程登录&quot;echo &quot;--------------------&quot;config=$(cat /etc/ssh/sshd_config | grep PermitRootLogin)firstChar=$&#123;config:0:1&#125;if [ $firstChar == &quot;#&quot; ];thenPermitRootLogin=&quot;yes&quot; #默认是允许ROOT远程登录的elsePermitRootLogin=$(echo $config | awk &#39;&#123;print $2&#125;&#39;)fiecho &quot;PermitRootLogin $PermitRootLogin&quot;echo &quot;&quot;echo &quot;/etc/ssh/sshd_config&quot;echo &quot;--------------------&quot;cat /etc/ssh/sshd_config | grep -v &quot;^#&quot; | sed &#39;/^$/d&#39;#报表信息report_SSHAuthorized=&quot;$authorized&quot; #SSH信任主机report_SSHDProtocolVersion=&quot;$Protocol_Version&quot; #SSH协议版本report_SSHDPermitRootLogin=&quot;$PermitRootLogin&quot; #允许root远程登录&#125;function getNTPStatus()&#123;#NTP服务状态，当前时间，配置等echo &quot;&quot;echo &quot;&quot;echo &quot;############################ NTP检查 #############################&quot;if [ -e /etc/ntp.conf ];thenecho &quot;服务状态：$(getState ntpd)&quot;echo &quot;&quot;echo &quot;/etc/ntp.conf&quot;echo &quot;-------------&quot;cat /etc/ntp.conf 2&gt;/dev/null | grep -v &quot;^#&quot; | sed &#39;/^$/d&#39;fi#报表信息report_NTP=&quot;$(getState ntpd)&quot;&#125;function uploadHostDailyCheckReport()&#123;json=&quot;&#123;\&quot;DateTime\&quot;:\&quot;$report_DateTime\&quot;,\&quot;Hostname\&quot;:\&quot;$report_Hostname\&quot;,\&quot;OSRelease\&quot;:\&quot;$report_OSRelease\&quot;,\&quot;Kernel\&quot;:\&quot;$report_Kernel\&quot;,\&quot;Language\&quot;:\&quot;$report_Language\&quot;,\&quot;LastReboot\&quot;:\&quot;$report_LastReboot\&quot;,\&quot;Uptime\&quot;:\&quot;$report_Uptime\&quot;,\&quot;CPUs\&quot;:\&quot;$report_CPUs\&quot;,\&quot;CPUType\&quot;:\&quot;$report_CPUType\&quot;,\&quot;Arch\&quot;:\&quot;$report_Arch\&quot;,\&quot;MemTotal\&quot;:\&quot;$report_MemTotal\&quot;,\&quot;MemFree\&quot;:\&quot;$report_MemFree\&quot;,\&quot;MemUsedPercent\&quot;:\&quot;$report_MemUsedPercent\&quot;,\&quot;DiskTotal\&quot;:\&quot;$report_DiskTotal\&quot;,\&quot;DiskFree\&quot;:\&quot;$report_DiskFree\&quot;,\&quot;DiskUsedPercent\&quot;:\&quot;$report_DiskUsedPercent\&quot;,\&quot;InodeTotal\&quot;:\&quot;$report_InodeTotal\&quot;,\&quot;InodeFree\&quot;:\&quot;$report_InodeFree\&quot;,\&quot;InodeUsedPercent\&quot;:\&quot;$report_InodeUsedPercent\&quot;,\&quot;IP\&quot;:\&quot;$report_IP\&quot;,\&quot;MAC\&quot;:\&quot;$report_MAC\&quot;,\&quot;Gateway\&quot;:\&quot;$report_Gateway\&quot;,\&quot;DNS\&quot;:\&quot;$report_DNS\&quot;,\&quot;Listen\&quot;:\&quot;$report_Listen\&quot;,\&quot;Selinux\&quot;:\&quot;$report_Selinux\&quot;,\&quot;Firewall\&quot;:\&quot;$report_Firewall\&quot;,\&quot;USERs\&quot;:\&quot;$report_USERs\&quot;,\&quot;USEREmptyPassword\&quot;:\&quot;$report_USEREmptyPassword\&quot;,\&quot;USERTheSameUID\&quot;:\&quot;$report_USERTheSameUID\&quot;,\&quot;PasswordExpiry\&quot;:\&quot;$report_PasswordExpiry\&quot;,\&quot;RootUser\&quot;:\&quot;$report_RootUser\&quot;,\&quot;Sudoers\&quot;:\&quot;$report_Sudoers\&quot;,\&quot;SSHAuthorized\&quot;:\&quot;$report_SSHAuthorized\&quot;,\&quot;SSHDProtocolVersion\&quot;:\&quot;$report_SSHDProtocolVersion\&quot;,\&quot;SSHDPermitRootLogin\&quot;:\&quot;$report_SSHDPermitRootLogin\&quot;,\&quot;DefunctProsess\&quot;:\&quot;$report_DefunctProsess\&quot;,\&quot;SelfInitiatedService\&quot;:\&quot;$report_SelfInitiatedService\&quot;,\&quot;SelfInitiatedProgram\&quot;:\&quot;$report_SelfInitiatedProgram\&quot;,\&quot;RuningService\&quot;:\&quot;$report_RuningService\&quot;,\&quot;Crontab\&quot;:\&quot;$report_Crontab\&quot;,\&quot;Syslog\&quot;:\&quot;$report_Syslog\&quot;,\&quot;SNMP\&quot;:\&quot;$report_SNMP\&quot;,\&quot;NTP\&quot;:\&quot;$report_NTP\&quot;,\&quot;JDK\&quot;:\&quot;$report_JDK\&quot;&#125;&quot;#echo &quot;$json&quot; curl -l -H &quot;Content-type: application/json&quot; -X POST -d &quot;$json&quot; &quot;$uploadHostDailyCheckReportApi&quot; 2&gt;/dev/null&#125;function getchage_file_24h()&#123;echo &quot;############################ 文件检查 #############################&quot;    check2=$(find / -name &#39;*.sh&#39; -mtime -1)check21=$(find / -name &#39;*.asp&#39; -mtime -1)check22=$(find / -name &#39;*.php&#39; -mtime -1)check23=$(find / -name &#39;*.aspx&#39; -mtime -1)check24=$(find / -name &#39;*.jsp&#39; -mtime -1)check25=$(find / -name &#39;*.html&#39; -mtime -1)check26=$(find / -name &#39;*.htm&#39; -mtime -1)check9=$(find / -name core -exec ls -l &#123;&#125; \;)check10=$(cat /etc/crontab)check12=$(ls -alt /usr/bin | head -10)cat &lt;&lt;EOF############################查看所有被修改过的文件返回最近24小时内的############################$&#123;check2&#125;$&#123;check21&#125;$&#123;check22&#125;$&#123;check23&#125;$&#123;check24&#125;$&#123;check25&#125;$&#123;check26&#125;$&#123;line&#125;############################检查定时文件的完整性############################$&#123;check10&#125;$&#123;line&#125;############################查看系统命令是否被替换############################$&#123;check12&#125;$&#123;line&#125;EOF&#125;function check()&#123;versiongetSystemStatusgetCpuStatusgetMemStatusgetDiskStatusgetNetworkStatusgetListenStatusgetProcessStatusgetServiceStatusgetAutoStartStatusgetLoginStatusgetCronStatusgetUserStatusgetPasswordStatusgetSudoersStatusgetJDKStatusgetFirewallStatusgetSSHStatusgetSyslogStatusgetSNMPStatusgetNTPStatusgetInstalledStatusgetchage_file_24h&#125;#执行检查并保存检查结果check &gt; $RESULTFILEecho &quot;检查结果：$RESULTFILE&quot;echo -e &quot;`date &quot;+%Y-%m-%d %H:%M:%S&quot;` 阿里云PHP企业平台巡检报告&quot;  | mail -a $RESULTFILE -s &quot;阿里云PHP企业平台巡检报告&quot; lxwno.1@163.com</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、说明&quot;&gt;&lt;a href=&quot;#一、说明&quot; class=&quot;headerlink&quot; title=&quot;一、说明&quot;&gt;&lt;/a&gt;一、说明&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Centos系统日常巡检脚本，巡检内容包含了，磁盘，内存 cpu 进程 文件更改 用户登录等一系列的操作 直</summary>
      
    
    
    
    <category term="脚本" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/"/>
    
    <category term="Shell" scheme="https://www.langxw.com/categories/%E8%84%9A%E6%9C%AC/Shell/"/>
    
    
    <category term="shell" scheme="https://www.langxw.com/tags/shell/"/>
    
    <category term="linux" scheme="https://www.langxw.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Docker添加http代理</title>
    <link href="https://www.langxw.com/2021/06/04/Docker%E6%B7%BB%E5%8A%A0http%E4%BB%A3%E7%90%86/"/>
    <id>https://www.langxw.com/2021/06/04/Docker%E6%B7%BB%E5%8A%A0http%E4%BB%A3%E7%90%86/</id>
    <published>2021-06-04T11:32:02.000Z</published>
    <updated>2021-06-04T11:33:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由"><a href="#一、缘由" class="headerlink" title="一、缘由"></a>一、缘由</h2><p>当docker在拉取国外的镜像，并且没有国内加速源的资源，速度很慢，甚至访问不到，比如安装k8s的时候。这时候就需要添加http、https代理，来进行下载加速。</p><h2 id="二、环境"><a href="#二、环境" class="headerlink" title="二、环境"></a>二、环境</h2><ul><li>**Ubuntu16.04 + Docker 20.10.6 **</li><li><strong>适用于Debian/Ubuntu，RedHat/CentOS系统。修改配置后，会持续生效，其中的设置将覆盖docker.service中的选项</strong></li></ul><h2 id="三、步骤"><a href="#三、步骤" class="headerlink" title="三、步骤"></a>三、步骤</h2><h3 id="1、创建目录"><a href="#1、创建目录" class="headerlink" title="1、创建目录"></a>1、创建目录</h3><pre><code class="bash">mkdir -p /etc/systemd/system/docker.service.d</code></pre><h3 id="2、添加网络代理配置文件"><a href="#2、添加网络代理配置文件" class="headerlink" title="2、添加网络代理配置文件"></a>2、添加网络代理配置文件</h3><pre><code class="bash">cat &gt;&gt; a &lt;&lt; EOF[Service]Environment=&quot;HTTP_PROXY=http://proxy-addr:proxy-port/&quot; &quot;HTTPS_PROXY=http://proxy-addr:proxy-port/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker.io,yanzhe919.mirror.aliyuncs.com,99nkhzdo.mirror.aliyuncs.com,*.aliyuncs.com,*.mirror.aliyuncs.com,registry.docker-cn.com,hub.c.163.com,hub-auth.c.163.com,&quot;EOF</code></pre><p>proxy-addr为代理IP或域名；proxy-port为代理端口；NO_PROXY后面接不需要代理的仓库的域名或者IP，以英文逗号结尾。</p><p><strong>注意：如果使用privoxy将http代理转换为socks5代理，这里porxy-addr和port就要写privoxy的IP和端口，比如127.0.0.1:8118</strong></p><h3 id="3、重载配置并重启docker服务"><a href="#3、重载配置并重启docker服务" class="headerlink" title="3、重载配置并重启docker服务"></a>3、重载配置并重启docker服务</h3><pre><code class="bash">systemctl daemon-reloadsystemctl restart docker</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由&quot;&gt;&lt;a href=&quot;#一、缘由&quot; class=&quot;headerlink&quot; title=&quot;一、缘由&quot;&gt;&lt;/a&gt;一、缘由&lt;/h2&gt;&lt;p&gt;当docker在拉取国外的镜像，并且没有国内加速源的资源，速度很慢，甚至访问不到，比如安装k8s的时候。这时候就需要添加ht</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="http代理" scheme="https://www.langxw.com/tags/http%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
</feed>
